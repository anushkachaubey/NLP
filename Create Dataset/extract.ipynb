{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 206 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /Users/anushkachaubey/Library/Python/3.9/lib/python/site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 694 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pdfminer.six==20231228\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 731 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /Users/anushkachaubey/Library/Python/3.9/lib/python/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 877 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /Users/anushkachaubey/Library/Python/3.9/lib/python/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
      "Requirement already satisfied: pycparser in /Users/anushkachaubey/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Installing collected packages: cryptography, pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed cryptography-44.0.1 pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = \"book1.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "# Save extracted text for further processing\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Load extracted text\n",
    "with open(\"extracted_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Define pattern to extract \"Problem Set\" sections\n",
    "problem_set_pattern = r\"Problem Set.*?(?=\\n\\nChapter|\\n\\nProblem Set|\\Z)\"  # Captures until next \"Chapter\" or another \"Problem Set\"\n",
    "\n",
    "problem_sets = re.findall(problem_set_pattern, text, re.DOTALL)\n",
    "\n",
    "# Save extracted problem sets\n",
    "with open(\"problem_sets.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(problem_sets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define question patterns\n",
    "question_patterns = [\n",
    "    r\"\\d+\\..*?(?=\\n\\d+\\.|\\n\\n|\\nProblem Set|\\Z)\",  # Matches \"1. Question\" until next number\n",
    "    r\"(Find|Solve|Prove|Compute|Evaluate).*?(?=\\n\\n|\\n[A-Z])\",  # Matches standalone problems\n",
    "]\n",
    "\n",
    "questions = []\n",
    "for problem_set in problem_sets:\n",
    "    for pattern in question_patterns:\n",
    "        matches = re.findall(pattern, problem_set, re.DOTALL)\n",
    "        questions.extend(matches)\n",
    "\n",
    "# Save extracted questions\n",
    "with open(\"questions_extracted.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define patterns\n",
    "page_header_pattern = r\"Chapter\\d+\\s+[A-Za-z]+\"  # Matches \"Chapter1 Matrices\"\n",
    "problem_set_pattern = r\"Problem Set\\s*\\d+\"  # Matches \"Problem Set 1\"\n",
    "question_pattern = r\"\\d+\\..*\"  # Matches a question starting with a number (e.g., \"1. What is...\")\n",
    "\n",
    "# Storage\n",
    "questions_with_chapters = []\n",
    "current_chapter = \"Unknown\"\n",
    "inside_problem_set = False\n",
    "current_question = \"\"\n",
    "\n",
    "# Load extracted text\n",
    "with open(\"extracted_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "lines = text.split(\"\\n\")  # Process text line by line\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.strip()\n",
    "\n",
    "    # Check for chapter header\n",
    "    match = re.search(page_header_pattern, line)  # Search for pattern anywhere in the line\n",
    "    if match:\n",
    "        current_chapter = match.group()  # Get the exact matched string\n",
    "\n",
    "    # If \"Problem Set\" is found, mark that we are inside a problem set\n",
    "    elif re.match(problem_set_pattern, line):\n",
    "        inside_problem_set = True  # Start collecting questions\n",
    "        current_question = \"\"  # Reset the current question\n",
    "\n",
    "    # If we encounter an empty line or next \"Chapter\", reset problem set flag\n",
    "    elif inside_problem_set and (line == \"\" or re.match(page_header_pattern, line)):\n",
    "        if current_question:\n",
    "            # Add the current question to the list when an empty line or chapter is found\n",
    "            questions_with_chapters.append((current_chapter, current_question.strip()))\n",
    "        inside_problem_set = False\n",
    "        current_question = \"\"  # Reset current question\n",
    "\n",
    "    # Collect question content if inside a problem set and a question is detected\n",
    "    elif inside_problem_set and re.match(question_pattern, line):\n",
    "        if current_question:\n",
    "            # If a previous question is collected, save it before starting a new one\n",
    "            questions_with_chapters.append((current_chapter, current_question.strip()))\n",
    "        current_question = line  # Start a new question\n",
    "\n",
    "    # If we're inside a problem set and the line doesn't match a new question,\n",
    "    # add the line to the current question (for multi-line questions).\n",
    "    elif inside_problem_set and current_question:\n",
    "        current_question += \" \" + line  # Append the line to the current question\n",
    "\n",
    "# Save the extracted questions with chapters\n",
    "with open(\"questions_with_chapters.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chapter, question in questions_with_chapters:\n",
    "        f.write(f\"{chapter}\\n{question}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_latex(question):\n",
    "    question = question.replace(\"≤\", r\"\\leq\")  # Example replacements\n",
    "    question = question.replace(\"≥\", r\"\\geq\")\n",
    "    question = question.replace(\"^\", r\"^{}\")   # Handling exponents\n",
    "    question = re.sub(r\"(\\d+)/(\\d+)\", r\"\\\\frac{\\1}{\\2}\", question)  # Convert fractions\n",
    "    return f\"\\\\textbf{{{question}}}\"\n",
    "\n",
    "# Save in LaTeX format\n",
    "with open(\"questions_latex.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chapter, question in questions_with_chapters:\n",
    "        f.write(f\"\\\\section*{{{chapter}}}\\n\")\n",
    "        f.write(f\"\\\\begin{{itemize}}\\n\")\n",
    "        f.write(f\"    \\\\item {convert_to_latex(question)}\\n\")\n",
    "        f.write(f\"\\\\end{{itemize}}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the extracted questions with chapters to JSON\n",
    "questions_with_chapters_dict = [\n",
    "    {\"chapter\": chapter[9:], \"question\": question} for chapter, question in questions_with_chapters\n",
    "]\n",
    "\n",
    "with open(\"questions_with_chapters.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(questions_with_chapters_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save questions in LaTeX format\n",
    "with open(\"questions_latex.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in questions_with_chapters_dict:\n",
    "        chapter = entry[\"chapter\"]\n",
    "        question = entry[\"question\"]\n",
    "        f.write(f\"\\\\section*{{{chapter}}}\\n\")\n",
    "        f.write(f\"\\\\begin{{itemize}}\\n\")\n",
    "        f.write(f\"    \\\\item {convert_to_latex(question)}\\n\")\n",
    "        f.write(f\"\\\\end{{itemize}}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chapters: {'Orthogonality', 'EigenvaluesandEigenvectors', 'ComputationswithMatrices', 'VectorSpaces', 'LinearProgrammingandGameTheory', 'PositiveDefiniteMatrices', 'MatricesandGaussianElimination', 'Determinants'}\n",
      "Number of unique chapters: 8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file containing the questions and chapters\n",
    "with open(\"questions_with_chapters.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions_with_chapters_dict = json.load(f)\n",
    "\n",
    "# Extract unique chapter names\n",
    "unique_chapters = set(entry[\"chapter\"] for entry in questions_with_chapters_dict)\n",
    "\n",
    "# Count the number of unique chapters\n",
    "num_unique_chapters = len(unique_chapters)\n",
    "\n",
    "# Print the unique chapters and their count\n",
    "print(\"Unique Chapters:\", unique_chapters)\n",
    "print(\"Number of unique chapters:\", num_unique_chapters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
