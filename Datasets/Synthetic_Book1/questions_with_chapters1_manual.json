[
    {
        "chapter": "Computations with Matrices",
        "question": "For an orthogonal matrix \\( Q \\), show that \\( \\|Q\\| = 1 \\) and also \\( c(Q) = 1 \\). Orthogonal matrices (and their multiples \\( \\alpha Q \\)) are the only perfectly conditioned matrices."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Which \u201cfamous\u201d inequality gives \\( \\| (A+B)x \\| \\leq \\|A\\| \\|x\\| + \\|B\\| \\|x\\| \\), and why does it follow from equation (5) that \\( \\|A+B\\| \\leq \\|A\\| + \\|B\\| \\)?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain why \\( \\|ABx\\| \\leq \\|A\\| \\|B\\| \\|x\\| \\), and deduce from equation (5) that \\( \\|AB\\| \\leq \\|A\\| \\|B\\| \\). Show that this also implies \\( c(AB) \\leq c(A) c(B) \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For the positive definite matrix \\( A = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\), compute \\( \\|A^{-1}\\| = \\frac{1}{\\lambda_1} \\), \\( \\|A\\| = \\lambda_2 \\), and \\( c(A) = \\frac{\\lambda_2}{\\lambda_1} \\). Find a right-hand side \\( b \\) and a perturbation \\( \\delta b \\) so that the error is the worst possible, \\( \\frac{\\|\\delta x\\|}{\\|x\\|} = c \\frac{\\|\\delta b\\|}{\\|b\\|} \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that if \\( \\lambda \\) is any eigenvalue of \\( A \\), \\( Ax = \\lambda x \\), then \\( |\\lambda| \\leq \\|A\\| \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The matrices in equation (4) have norms between 100 and 101. Why?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Comparing the eigenvalues of \\( A^T A \\) and \\( A A^T \\), prove that \\( \\|A\\| = \\|A^T\\| \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For a positive definite matrix \\( A \\), the Cholesky decomposition is \\( A = LDL^T = R^T R \\), where \\( R = \\sqrt{D} L^T \\). Show directly from equation (12) that the condition number of \\( R \\) is the square root of \\( c(A) \\). Elimination without row exchanges cannot hurt a positive definite matrix, since \\( c(A) = c(R^T) c(R) \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that \\( \\max |\\lambda| \\) is not a true norm, by finding 2 by 2 counterexamples to \\( \\lambda_{\\max}(A+B) \\leq \\lambda_{\\max}(A) + \\lambda_{\\max}(B) \\) and \\( \\lambda_{\\max}(AB) \\leq \\lambda_{\\max}(A) \\lambda_{\\max}(B) \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that the eigenvalues of \\( B = \\begin{pmatrix} 0 & A \\\\ A^T & 0 \\end{pmatrix} \\) are \\( \\pm \\sigma_i \\), the singular values of \\( A \\). Hint: Try \\( B^2 \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "(a) Do \\( A \\) and \\( A^{-1} \\) have the same condition number \\( c \\)? \\\\\n    (b) In parallel with the upper bound (8) on the error, prove a lower bound: \\( \\frac{\\|\\delta x\\|}{\\|x\\|} \\geq \\frac{1}{c} \\frac{\\|\\delta b\\|}{\\|b\\|} \\). (Consider \\( A^{-1} b = x \\) instead of \\( Ax = b \\).)"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Find the norms \\( \\lambda_{\\max} \\) and condition numbers \\( \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} \\) of these positive definite matrices:\n    \\[\n    \\begin{pmatrix} 100 & 0 \\\\ 0 & 2 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 3 & 1 \\\\ 1 & 1 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Orthogonal matrices have norm \\( \\|Q\\| = 1 \\). If \\( A = QR \\), show that \\( \\|A\\| \\leq \\|R\\| \\) and also \\( \\|R\\| \\leq \\|A\\| \\). Then \\( \\|A\\| = \\|Q\\| \\|R\\| \\). Find an example of \\( A = LU \\) with \\( \\|A\\| < \\|L\\| \\|U\\| \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "(Suggested by Moler and Van Loan) Compute \\( b - Ay \\) and \\( b - Az \\) when\n    \\[\n    b = \\begin{pmatrix} 0.217 \\\\ 0.254 \\end{pmatrix}, \\quad\n    A = \\begin{pmatrix} 0.780 & 0.563 \\\\ 0.913 & 0.659 \\end{pmatrix}, \\quad\n    y = \\begin{pmatrix} 0.341 \\\\ -0.087 \\end{pmatrix}, \\quad\n    z = \\begin{pmatrix} 0.999 \\\\ -1.0 \\end{pmatrix}.\n    \\]\n    Is \\( y \\) closer than \\( z \\) to solving \\( Ax = b \\)? Answer in two ways: Compare the residuals \\( b - Ay \\) and \\( b - Az \\). Then compare \\( y \\) and \\( z \\) to the true \\( x = (1, -1) \\). Sometimes we want a small residual, sometimes a small \\( \\delta x \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The \u201c\\( \\ell_1 \\) norm\u201d is \\( \\|x\\|_1 = |x_1| + \\cdots + |x_n| \\). The \u201c\\( \\ell_\\infty \\) norm\u201d is \\( \\|x\\|_\\infty = \\max |x_i| \\). Compute \\( \\|x\\|_2 \\), \\( \\|x\\|_1 \\), and \\( \\|x\\|_\\infty \\) for the vectors\n    \\[\n    x = (1, 1, 1, 1, 1) \\quad \\text{and} \\quad x = (0.1, 0.7, 0.3, 0.4, 0.5).\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that \\( \\|x\\|_\\infty \\leq \\|x\\|_2 \\leq \\|x\\|_1 \\). Show from the Cauchy-Schwarz inequality that the ratios \\( \\|x\\|_2 / \\|x\\|_\\infty \\) and \\( \\|x\\|_1 / \\|x\\|_2 \\) are never larger than \\( \\sqrt{n} \\). Which vector \\( (x_1, \\dots, x_n) \\) gives ratios equal to \\( \\sqrt{n} \\)?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "All vector norms must satisfy the triangle inequality. Prove that\n    \\[\n    \\|x + y\\|_\\infty \\leq \\|x\\|_\\infty + \\|y\\|_\\infty \\quad \\text{and} \\quad \\|x + y\\|_1 \\leq \\|x\\|_1 + \\|y\\|_1.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute the exact inverse of the Hilbert matrix \\( A \\) by elimination. Then compute \\( A^{-1} \\) again by rounding all numbers to three significant figures:\n    \\[\n    A = \\begin{pmatrix}\n    1 & 1/2 & 1/3 \\\\\n    1/2 & 1/3 & 1/4 \\\\\n    1/3 & 1/4 & 1/5\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For the same \\( A \\), compute \\( b = Ax \\) for \\( x = (1, 1, 1) \\) and \\( x = (0.6, -3.6, 0) \\). A small change \\( \\Delta b \\) produces a large change \\( \\Delta x \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute \\( \\lambda_{\\max} \\) and \\( \\lambda_{\\min} \\) for the 8 by 8 Hilbert matrix \\( a_{ij} = \\frac{1}{i + j - 1} \\). If \\( Ax = b \\) with \\( \\|b\\| = 1 \\), how large can \\( \\|x\\| \\) be? If \\( b \\) has roundoff error less than \\( 10^{-16} \\), how large an error can this cause in \\( x \\)?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "If you know \\( L \\), \\( U \\), \\( Q \\), and \\( R \\), is it faster to solve \\( LUx = b \\) or \\( QRx = b \\)?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Choosing the largest available pivot in each column (partial pivoting), factor each \\( A \\) into \\( PA = LU \\):\n    \\[\n    A = \\begin{pmatrix} 1 & 0 \\\\ 2 & 2 \\end{pmatrix} \\quad \\text{and} \\quad\n    A = \\begin{pmatrix} 1 & 0 & 1 \\\\ 2 & 2 & 0 \\\\ 0 & 2 & 0 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Find the LU factorization of \\( A = \\begin{pmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{pmatrix} \\). On your computer, solve by elimination when \\( \\epsilon = 10^{-3}, 10^{-6}, 10^{-9}, 10^{-12}, 10^{-15} \\):\n    \\[\n    \\begin{pmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{pmatrix}\n    \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n    =\n    \\begin{pmatrix} 1 + \\epsilon \\\\ 2 \\end{pmatrix}.\n    \\]\n    The true solution is \\( (1, 1) \\). Make a table to show the error for each \\( \\epsilon \\). Exchange the two equations and solve again\u2014the errors should almost disappear."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that starting from \\( A_0 = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\), the unshifted QR algorithm produces only the modest improvement\n    \\[\n    A_1 = \\frac{1}{5} \\begin{pmatrix} 14 & -3 \\\\ -3 & 6 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Apply to the following matrix \\( A \\) a single QR step with the shift \\( \\alpha = a_{22} \\)\u2014which in this case means without shift, since \\( a_{22} = 0 \\). Show that the off-diagonal entries go from \\( \\sin \\theta \\) to \\( -\\sin 3\\theta \\), which is cubic convergence.\n    \\[\n    A = \\begin{pmatrix} \\cos \\theta & \\sin \\theta \\\\ \\sin \\theta & 0 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Check that the tridiagonal matrix \\( A = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\) is left unchanged by the QR algorithm. It is one of the (rare) counterexamples to convergence (so we shift)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show by induction that, without shifts, \\( (Q_0 Q_1 \\cdots Q_k)(R_k \\cdots R_1 R_0) \\) is exactly the QR factorization of \\( A_{k+1} \\). This identity connects QR to the power method and leads to an explanation of its convergence. If \\( |\\lambda_1| > |\\lambda_2| > \\cdots > |\\lambda_n| \\), these eigenvalues will gradually appear on the main diagonal."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Choose \\( \\sin \\theta \\) and \\( \\cos \\theta \\) in the rotation \\( P_{21} \\) to triangularize \\( A \\), and find \\( R \\):\n    \\[\n    P_{21} A = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix} \\begin{pmatrix} 1 & -1 \\\\ 3 & 5 \\end{pmatrix} = \\begin{pmatrix} * & * \\\\ 0 & * \\end{pmatrix} = R.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Choose \\( \\sin \\theta \\) and \\( \\cos \\theta \\) to make \\( P_{21} A P_{21}^{-1} \\) triangular (same \\( A \\)). What are the eigenvalues?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "When \\( A \\) is multiplied by \\( P_{ij} \\) (plane rotation), which entries are changed? When \\( P_{ij} A \\) is multiplied on the right by \\( P_{ij}^{-1} \\), which entries are changed now?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How many multiplications and how many additions are used to compute \\( PA \\)? (A careful organization of all the rotations gives \\( 2^3 n^3 \\) multiplications and additions, the same as for QR by reflectors and twice as many as for LU.)"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "(Turning a robot hand) A robot produces any 3 by 3 rotation \\( A \\) from plane rotations around the \\( x \\), \\( y \\), and \\( z \\) axes. If \\( P_{32} P_{31} P_{21} A = I \\), the three robot turns are in \\( A = P_{21}^{-1} P_{31}^{-1} P_{32}^{-1} \\). The three angles are Euler angles. Choose the first \\( \\theta \\) so that\n    \\[\n    P_{21} A = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta & 0 \\\\ \\sin \\theta & \\cos \\theta & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\frac{1}{2} \\begin{pmatrix} -1 & 2 & 2 \\\\ 2 & -1 & 2 \\\\ 2 & 2 & -1 \\end{pmatrix}\n    \\]\n    is zero in the \\( (2,1) \\) position."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "This matrix has eigenvalues \\( 2 - \\sqrt{2} \\), \\( 2 \\), and \\( 2 + \\sqrt{2} \\):\n    \\[\n    A = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix}.\n    \\]\n    Find the Jacobi matrix \\( D^{-1}(-L - U) \\) and the Gauss-Seidel matrix \\( (D + L)^{-1}(-U) \\), and their eigenvalues, and the numbers \\( \\omega_{\\text{opt}} \\) and \\( \\lambda_{\\text{max}} \\) for SOR."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For this \\( n \\times n \\) matrix, describe the Jacobi matrix \\( J = D^{-1}(-L - U) \\):\n    \\[\n    A = \\begin{pmatrix} 2 & -1 & \\cdots & 0 \\\\ -1 & \\ddots & \\ddots & \\vdots \\\\ \\vdots & \\ddots & \\ddots & -1 \\\\ 0 & \\cdots & -1 & 2 \\end{pmatrix}.\n    \\]\n    Show that the vector \n    \\[\n    x_1 = (\\sin \\pi h, \\sin 2 \\pi h, \\dots, \\sin n \\pi h)\n    \\]\n    is an eigenvector of \\( J \\) with eigenvalue \\( \\lambda_1 = \\cos \\pi h = \\cos \\frac{\\pi}{n+1} \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In Problem 2, show that \n    \\[\n    x_k = (\\sin k \\pi h, \\sin 2k \\pi h, \\dots, \\sin nk \\pi h)\n    \\]\n    is an eigenvector of \\( A \\). Multiply \\( x_k \\) by \\( A \\) to find the corresponding eigenvalue \\( \\alpha_k \\). Verify that in the \\( 3 \\times 3 \\) case these eigenvalues are \\( 2 - \\sqrt{2} \\), \\( 2 \\), and \\( 2 + \\sqrt{2} \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Note: The eigenvalues of the Jacobi matrix \n    \\[\n    J = \\frac{1}{2}(-L - U) = I - \\frac{1}{2}A\n    \\]\n    are \n    \\[\n    \\lambda_k = 1 - \\frac{1}{2} \\alpha_k = \\cos k \\pi h.\n    \\]\n    They occur in plus-minus pairs, and \\( \\lambda_{\\text{max}} \\) is \\( \\cos \\pi h \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Problems 4\u20135 require Gershgorin's \"circle theorem\": Every eigenvalue of \\( A \\) lies in at least one of the circles \\( C_1, \\dots, C_n \\), where \\( C_i \\) has its center at the diagonal entry \\( a_{ii} \\). Its radius \\( r_i = \\sum_{j \\neq i} |a_{ij}| \\) is equal to the absolute sum along the rest of the row. Proof: Suppose \\( x_i \\) is the largest component of \\( x \\). Then \\( Ax = \\lambda x \\) leads to\n    \\[\n    (\\lambda - a_{ii}) x_i = \\sum_{j \\neq i} a_{ij} x_j,\n    \\]\n    or\n    \\[\n    |\\lambda - a_{ii}| \\leq \\sum_{j \\neq i} |a_{ij}| \\frac{|x_j|}{|x_i|} \\leq \\sum_{j \\neq i} |a_{ij}| = r_i.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The matrix \n    \\[\n    A = \\begin{pmatrix}\n    3 & 1 & 1 \\\\\n    0 & 4 & 1 \\\\\n    2 & 2 & 5\n    \\end{pmatrix}\n    \\]\n    is called \\emph{diagonally dominant} because every \\( |a_{ii}| > r_i \\) (where \\( r_i = \\sum_{j \\neq i} |a_{ij}| \\)). Show that zero cannot lie in any of the Gershgorin circles and conclude that \\( A \\) is nonsingular."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Write the Jacobi matrix \\( J \\) for the diagonally dominant \\( A \\) of Problem 4, and find the three Gershgorin circles for \\( J \\). Show that all the radii satisfy \\( r_i < 1 \\), and that the Jacobi iteration converges."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The true solution to \\( Ax = b \\) is slightly different from the elimination solution to \\( LUx_0 = b \\); \\( A - LU \\) misses zero because of roundoff. One strategy is to do everything in double precision, but a better and faster way is iterative refinement: Compute only one vector\n    \\[\n    r = b - Ax_0\n    \\]\n    in double precision, solve \\( LUy = r \\), and add the correction \\( y \\) to \\( x_0 \\). \\\\\n    \\textbf{Problem:} Multiply \\( x_1 = x_0 + y \\) by \\( LU \\), write the result as a splitting\n    \\[\n    Sx_1 = Tx_0 + b,\n    \\]\n    and explain why \\( T \\) is extremely small. This single step brings us almost exactly to \\( x \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For a general \\( 2 \\times 2 \\) matrix\n    \\[\n    A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix},\n    \\]\n    find the Jacobi iteration matrix\n    \\[\n    S^{-1}T = -D^{-1}(L + U)\n    \\]\n    and its eigenvalues \\( \\mu_i \\). Find also the Gauss-Seidel matrix\n    \\[\n    -(D + L)^{-1}U\n    \\]\n    and its eigenvalues \\( \\lambda_i \\), and decide whether \\( \\lambda_{\\max} = \\mu_{\\max}^2 \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Change \\( Ax = b \\) to\n    \\[\n    x = (I-A)x + b.\n    \\]\n    What are \\( S \\) and \\( T \\) for this splitting? What matrix \\( S^{-1}T \\) controls the convergence of the iteration\n    \\[\n    x_{k+1} = (I-A)x_k + b \\, ?\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "If \\( \\lambda \\) is an eigenvalue of \\( A \\), then \\( \\mu = 1 - \\lambda \\) is an eigenvalue of \\( B = I - A \\). The real eigenvalues of \\( B \\) have absolute value less than 1 if the real eigenvalues of \\( A \\) lie between two numbers. (Assume in this context that the real eigenvalues of \\( A \\) lie between 0 and 2.)"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show why the iteration\n    \\[\n    x_{k+1} = (I-A)x_k + b\n    \\]\n    does not converge for \n    \\[\n    A = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Why is the norm of \\(B^k\\) never larger than \\(\\|B\\|^k\\)? Then \\(\\|B\\| < 1\\) guarantees that the powers \\(B^k\\) approach zero (convergence). This is no surprise, since \\(|\\lambda|_{\\max}\\) is below \\(\\|B\\|\\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "If \\(A\\) is singular, then all splittings \\(A = S - T\\) must fail. From \\(Ax = 0\\), show that\n    \\[\n    S^{-1}T x = x.\n    \\]\n    Thus, the matrix \\(B = S^{-1}T\\) has an eigenvalue \\(\\lambda = 1\\) and fails."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Change the 2s to 3s and find the eigenvalues of \\(S^{-1}T\\) for both methods:\n    \\begin{itemize}"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "\\textbf{Jacobi (J):} \n        \\[\n        \\begin{pmatrix} 3 & 0 \\\\ 0 & 3 \\end{pmatrix} x_{k+1} = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} x_k + b.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "\\textbf{Gauss-Seidel (GS):} \n        \\[\n        \\begin{pmatrix} 3 & 0 \\\\ -1 & 3 \\end{pmatrix} x_{k+1} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} x_k + b.\n        \\]\n    \\end{itemize}\n    Does \\(|\\lambda|_{\\max}\\) for Gauss-Seidel equal \\(|\\lambda|_{\\max}^2\\) for Jacobi?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Write a computer code (MATLAB or other) for Gauss-Seidel. You can define \\(S\\) and \\(T\\) from \\(A\\), or set up the iteration loop directly from the entries \\(a_{ij}\\). Test it on the \\(-1,\\,2,\\,-1\\) matrices \\(A\\) of order 10, 20, and 50, with \\(b = (1,0,\\dots,0)\\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The SOR splitting matrix \\(S\\) is the same as for Gauss-Seidel except that the diagonal is divided by \\(\\omega\\). Write a program for SOR on an \\(n \\times n\\) matrix. Apply it with \\(\\omega = 1,\\;1.4,\\;1.8,\\;2.2\\) when \\(A\\) is the \\(-1,\\,2,\\,-1\\) matrix of order 10."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "When \\(A = A^T\\), the Arnoldi-Lanczos method finds orthonormal vectors \\(q_j\\) such that\n    \\[\n    Aq_j = b_{j-1}q_{j-1} + a_jq_j + b_jq_{j+1} \\quad (q_0 = 0).\n    \\]\n    Multiply by \\(q_j^T\\) to derive a formula for \\(a_j\\). This equation indicates that \\(AQ = Q^T T\\), where \\(T\\) is a tridiagonal matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "What bound on \\(|\\lambda|_{\\max}\\) does Gershgorin's circle theorem give for the following matrices? What are the three Gershgorin circles that contain all the eigenvalues?\n    \\[\n    A_1 = \\begin{pmatrix} 0.3 & 0.3 & 0.2 \\\\ 0.3 & 0.2 & 0.4 \\\\ 0.2 & 0.4 & 0.1 \\end{pmatrix}, \\quad\n    A_2 = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix}.\n    \\]\n    The key point for large matrices is that matrix-vector multiplication is much faster than matrix-matrix multiplication. A crucial construction starts with a vector \\(b\\) and computes \\(Ab,\\, A^2b,\\, \\dots\\) (but never \\(A^2\\)!); the first \\(N\\) vectors span the \\(N\\)th Krylov subspace. They are the columns of the Krylov matrix\n    \\[\n    K_N = \\begin{bmatrix} b & Ab & A^2b & \\cdots & A^{N-1}b \\end{bmatrix}.\n    \\]\n    The Arnoldi-Lanczos iteration orthogonalizes the columns of \\(K_N\\), and the conjugate gradient iteration solves \\(Ax = b\\) when \\(A\\) is symmetric positive definite."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "\\textbf{Arnoldi Iteration \\quad Conjugate Gradient Iteration}\n\n    \\medskip\n    \\textbf{Arnoldi Iteration:} \\\\\n    Set \n    \\[\n    q_1 = \\frac{b}{\\|b\\|}.\n    \\]\n    For \\( n = 1 \\) to \\( N-1 \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute \\( v = Aq_n \\)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "For \\( j = 1 \\) to \\( n \\), compute\n        \\[\n        h_{j,n} = q_j^T v.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Update\n        \\[\n        v \\leftarrow v - \\sum_{j=1}^{n} h_{j,n} q_j.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Set\n        \\[\n        q_{n+1} = \\frac{v}{\\|v\\|}.\n        \\]\n    \\end{itemize}\n    \n    \\medskip\n    \\textbf{Conjugate Gradient Iteration:} \\\\\n    Initialize \n    \\[\n    x_0 = 0,\\quad r_0 = b,\\quad p_0 = r_0.\n    \\]\n    For \\( n = 1 \\) to \\( N \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute the step length\n        \\[\n        \\alpha_n = \\frac{r_{n-1}^T r_{n-1}}{p_{n-1}^T A p_{n-1}}.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Update the approximate solution:\n        \\[\n        x_n = x_{n-1} + \\alpha_n\\, p_{n-1}.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute the new residual:\n        \\[\n        r_n = r_{n-1} - \\alpha_n\\, A p_{n-1}.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compute the improvement factor:\n        \\[\n        \\beta_n = \\frac{r_n^T r_n}{r_{n-1}^T r_{n-1}}.\n        \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Update the search direction:\n        \\[\n        p_n = r_n + \\beta_n\\, p_{n-1}.\n        \\]\n    \\end{itemize}\n    \n    \\noindent\n    \\textbf{Note:} Only one matrix-vector multiplication with \\( A \\) (applied to \\( q_n \\) or \\( p_{n-1} \\)) is required in each iteration."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In Arnoldi, show that \\( q_2 \\) is orthogonal to \\( q_1 \\). (Hint: The Arnoldi method is simply Gram--Schmidt orthogonalization applied to the Krylov matrix \n    \\[\n    K_N = \\begin{bmatrix} b & Ab & A^2b & \\cdots & A^{N-1}b \\end{bmatrix}\n    \\]\n    with \\( K_N = Q_N R_N \\). Moreover, the eigenvalues of \\( Q_N^T A Q_N \\) are often very close to those of \\( A \\), even for \\( N > n \\). Note that the Lanczos iteration is just Arnoldi specialized for symmetric matrices, and all of these methods are implemented in ARPACK.)"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In conjugate gradients, show that the residual \\( r_1 \\) is orthogonal to \\( r_0 \\) (i.e. the residuals are orthogonal), and that the search directions satisfy\n    \\[\n    p_0^T A p_0 = 0.\n    \\]\n    Explain why the iteration solves \\( Ax = b \\) by minimizing the error \\( e^T A e \\) in the Krylov subspace. (This is one of the remarkable properties of the conjugate gradient method.)"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a $10000 \\times 10000$ dense matrix stored in row-major order. Assuming each entry is a double-precision floating-point number (8 bytes), determine the memory required to store the matrix. If the matrix is instead stored in a sparse format with only $0.01\\%$ nonzero entries, estimate the memory usage for the Compressed Sparse Row (CSR) format."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the trade-offs between dense and sparse matrix storage formats in terms of memory efficiency, computational complexity, and ease of implementation. Provide examples where one format significantly outperforms the other."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a block storage representation of a matrix where each block is stored separately, analyze the benefits and drawbacks of such a structure in terms of memory fragmentation, cache efficiency, and parallel computation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose you have a large-scale linear system $Ax = b$ where $A$ is sparse with a banded structure. Discuss the optimal memory storage technique for $A$ and its impact on the efficiency of solving the system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the advantages of using Hierarchical Matrices ($H$-matrices) for storing large dense matrices in scientific computing. How do these structures reduce memory usage while preserving computational efficiency?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Derive the memory complexity of storing a symmetric positive definite matrix using the Cholesky decomposition in dense and sparse formats. Compare the savings achieved when using sparse representations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a large sparse matrix arising from the discretization of a Partial Differential Equation (PDE). Explain how domain decomposition techniques can be leveraged for memory-efficient storage and parallel computation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In the context of large matrix operations, explain how out-of-core memory management techniques, such as paging and buffering, help handle matrices that exceed available RAM. Illustrate with an example."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose a high-performance computing (HPC) application requires efficient memory allocation for storing and manipulating large adjacency matrices of graphs. Compare the use of adjacency lists, CSR, and adjacency matrices in terms of memory footprint and retrieval efficiency."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Analyze the impact of cache locality on the performance of matrix-vector multiplications for large matrices stored in row-major and column-major formats. Provide empirical evidence or theoretical justification for your claims."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the structure and memory benefits of using the Block Compressed Row Storage (BCRS) format for large sparse matrices with a block-diagonal structure. When is BCRS preferable to CSR?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a $n \\times n$ matrix with only $O(n)$ nonzero entries per row. Derive the memory complexity of storing such a matrix in CSR format and compare it with naive dense storage."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the significance of floating-point precision in matrix storage. How does using single-precision versus double-precision arithmetic affect memory consumption and computational stability?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose a machine learning model requires storing an extremely large covariance matrix. How can low-rank approximations (e.g., Singular Value Decomposition, CUR decomposition) help in reducing memory consumption?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the impact of memory bandwidth on large-scale matrix computations and suggest techniques to minimize memory bottlenecks in modern computing architectures."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how Tensor decomposition techniques (e.g., Tucker decomposition, CP decomposition) can be used to store and manipulate large-scale data efficiently. Provide a concrete example where such a method is beneficial."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a large sparse matrix with $n^2$ elements but only $O(n)$ nonzero values, discuss efficient memory allocation strategies to avoid overallocation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How does handling overflow and underflow in matrix computations impact numerical stability? Provide real-world examples where such issues arise and discuss mitigation strategies."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the role of compressed storage formats such as Run-Length Encoding (RLE) in reducing the memory footprint of structured matrices. What are the limitations of RLE for general sparse matrices?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose an iterative solver like Conjugate Gradient (CG) is used for solving large sparse linear systems. Explain how memory-efficient preconditioning techniques, such as Incomplete LU (ILU) and Jacobi preconditioning, can optimize storage requirements."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compare the memory efficiency of storing a matrix using coordinate (COO) format versus CSR format. Derive conditions under which one format is preferable to the other."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the trade-offs between explicit and implicit storage of large permutation matrices in numerical linear algebra applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a Markov transition matrix that is both large and sparse. What memory-efficient storage schemes would you recommend, and why?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In large-scale simulations involving finite element methods (FEM), how can sparsity patterns be exploited to optimize memory usage?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the impact of matrix sparsity on the performance of iterative solvers versus direct solvers. How does memory access pattern influence computational efficiency?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How do modern parallel computing architectures (e.g., GPUs) handle large matrix storage and memory bandwidth constraints? Discuss techniques such as shared memory, tiling, and memory coalescing."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a Toeplitz matrix stored in memory. How can its special structure be used to optimize storage and computation for matrix-vector multiplication?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose you need to store and manipulate a sequence of time-dependent sparse matrices. What strategies would you use to minimize memory overhead while ensuring efficient access to historical data?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the role of low-memory algorithms such as Stochastic Gradient Descent (SGD) in handling extremely large data matrices in machine learning applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a quantum computing simulation that involves exponentially large matrices. How can tensor networks (e.g., Matrix Product States) be used to efficiently store and manipulate such matrices?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a large $n \\times n$ matrix $A$ that needs to be multiplied with another matrix $B$ of the same dimension. Describe in detail how the Strassen algorithm can be parallelized for multi-core processors. Discuss the advantages and limitations of this approach in terms of computational complexity and memory usage."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In a distributed computing environment, the matrix-vector multiplication $Ax = b$ is performed using row-wise partitioning across $p$ processors. Derive the communication cost and computational complexity of this approach and discuss the trade-offs between communication and computation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe how matrix inversion can be efficiently implemented using parallel computing techniques. Compare the performance of LU decomposition, Gauss-Jordan elimination, and block matrix inversion in a multi-core system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of load balancing in parallel matrix computations. Given a heterogeneous computing environment with processors of varying speeds, formulate an optimization problem to achieve optimal load balancing when computing $C = AB$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a sparse matrix $A$ distributed across multiple GPUs. How can the sparse matrix-vector product (SpMV) be optimized to achieve high performance? Discuss trade-offs between memory access patterns and computational throughput."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define and analyze the impact of Amdahl\u2019s Law in parallel matrix operations. For a given matrix multiplication problem where 80\\% of the execution time can be parallelized, determine the theoretical speedup achievable with 16 processors."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In a distributed cloud computing environment, discuss how matrix factorization techniques (such as QR or SVD) can be efficiently implemented. Explain the challenges of data communication and how they can be mitigated."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of GPU-accelerated matrix computations. Compare the advantages and disadvantages of using a GPU versus a CPU for computing eigenvalues and eigenvectors of a large symmetric matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a block matrix $A$ that is partitioned into submatrices for parallel processing. Explain how an optimal block size can be chosen to balance computation and communication overhead in a distributed memory system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the synchronization challenges faced in parallel Cholesky decomposition. What strategies can be employed to minimize synchronization overhead?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss how pipelining techniques can be applied to improve the performance of matrix-matrix multiplication in a distributed computing system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In the context of large-scale machine learning, explain how distributed matrix computations are used for training deep neural networks. Discuss how GPUs and TPUs are leveraged for optimizing matrix operations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given an $n \\times n$ dense matrix $A$, describe how a MapReduce framework can be used to compute its matrix-vector product efficiently. Explain the role of mappers and reducers in this computation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Derive an efficient parallel algorithm for computing the determinant of a large sparse matrix. Analyze its computational complexity and discuss how it can be implemented on a shared-memory system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In the context of matrix operations on a cloud computing platform, explain the trade-offs between latency, bandwidth, and computational efficiency when processing a large matrix dataset."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a system of linear equations $Ax = b$ where $A$ is a large distributed matrix. Discuss iterative methods such as Jacobi and Gauss-Seidel that can be parallelized. Compare their convergence properties."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of matrix tiling and discuss its effectiveness in improving cache efficiency in multi-threaded matrix computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a highly parallelized matrix multiplication operation, explain the impact of memory latency and bandwidth on the overall performance. Propose strategies to mitigate these bottlenecks."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How can matrix transpose be performed efficiently in a parallel computing environment? Discuss various algorithms and their trade-offs in terms of performance and memory access."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Analyze the role of CUDA and OpenCL in parallel matrix computations. Compare their programming models and performance characteristics for matrix multiplication."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss fault tolerance mechanisms in distributed matrix computations. What strategies can be employed to ensure reliability in the event of node failures?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compare different load balancing strategies (e.g., static vs dynamic) for parallelizing large-scale matrix operations. Provide examples where each strategy would be most beneficial."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of communication-avoiding algorithms in matrix computations. How do they improve performance in distributed systems?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a $10^6 \\times 10^6$ matrix stored across a distributed system, analyze the impact of network bandwidth and memory constraints on performing LU decomposition."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the parallelization of the power iteration method for computing the dominant eigenvalue of a large sparse matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how the concept of divide-and-conquer can be applied to matrix operations such as inversion and decomposition in a parallel computing setup."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a distributed computing cluster with $p$ nodes, formulate an optimal scheduling strategy to minimize the total execution time for computing $C = A^TB$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss how hybrid parallelism (combining shared and distributed memory models) can be used to optimize large-scale matrix computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compare the efficiency of matrix operations in single-node multi-threading environments versus distributed multi-node environments. What are the key factors affecting performance?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a high-performance computing system executing parallel matrix computations. Discuss strategies for optimizing energy efficiency while maintaining computational throughput."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a large sparse matrix $A$ of size $n \\times n$ with sparsity $s$. Describe the computational complexity of performing matrix-vector multiplication $Ax = b$ using a naive dense representation versus a compressed sparse row (CSR) format. Discuss under what conditions the CSR format provides a computational advantage."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the key differences between compressed sparse row (CSR), compressed sparse column (CSC), and coordinate (COO) storage formats for sparse matrices. Derive the memory requirements for storing an $n \\times n$ sparse matrix with $k$ nonzero elements in each of these formats."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss how the structure of a sparse matrix affects the performance of sparse matrix-matrix multiplication (SpMM). Provide examples where different sparsity patterns (e.g., banded, block diagonal, unstructured) lead to different computational complexities."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The efficiency of sparse Cholesky factorization heavily depends on the matrix's sparsity pattern. Given a sparse symmetric positive definite matrix, describe how reordering strategies such as Approximate Minimum Degree (AMD) and Nested Dissection can improve performance."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Derive an optimal algorithm for computing the product of two sparse matrices $C = AB$, where $A$ and $B$ are stored in compressed sparse row (CSR) format. Discuss how to minimize computational overhead and memory usage."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the role of fill-in during LU factorization of a sparse matrix. Given a specific sparsity pattern, describe how fill-in can be minimized through reordering techniques such as Cuthill-McKee."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given an $n \\times n$ sparse matrix $A$ with only $O(n)$ nonzero elements, discuss efficient iterative methods (e.g., Jacobi, Gauss-Seidel, Conjugate Gradient) for solving $Ax = b$. Compare their convergence rates and computational complexities."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the memory access patterns involved in sparse matrix-vector multiplication (SpMV) when using the CSR format. How can cache blocking and prefetching improve computational performance?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how Graph Theory can be used to analyze sparsity patterns in matrices. Given a matrix $A$, define its adjacency graph and describe how graph partitioning techniques help in optimizing parallel sparse computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the trade-offs between direct solvers (e.g., sparse LU, Cholesky) and iterative solvers (e.g., GMRES, BiCGSTAB) for solving large sparse linear systems. When is each method preferable?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider the sparse eigenvalue problem $Ax = \\lambda x$, where $A$ is a large sparse symmetric matrix. Describe how Krylov subspace methods such as the Lanczos algorithm efficiently compute a few dominant eigenvalues."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How does the sparsity pattern of a matrix affect the numerical stability of sparse direct solvers? Provide examples where poor conditioning arises due to sparsity structure."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the role of preconditioning in solving sparse linear systems. Compare different preconditioners (e.g., Jacobi, Incomplete LU, Multigrid) in terms of effectiveness and computational cost."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a sparse matrix $A$ stored in CSR format, analyze the impact of parallelizing the sparse matrix-vector multiplication operation. Discuss load balancing and data locality challenges."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe an efficient method for transposing a sparse matrix stored in CSR format. How does the complexity compare to transposing a dense matrix?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Analyze the impact of different sparse matrix formats on performance when performing SpMV on GPU architectures. Which format is generally preferable for CUDA-based implementations?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a scientific computing application where a large sparse Jacobian matrix must be computed and stored. Discuss strategies for efficiently handling sparsity when computing derivatives using automatic differentiation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Derive a method to efficiently compute the inverse of a large sparse triangular matrix stored in CSR format. Discuss when explicit inversion is necessary and when it should be avoided."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of blocking in sparse matrix computations. How does it improve performance in modern CPU and GPU architectures?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Conjugate Gradient method is often preferred for solving large sparse positive-definite systems. Prove its convergence properties and derive its complexity for an $n \\times n$ sparse matrix with $O(n)$ nonzeros."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the impact of sparsity patterns on parallel sparse matrix algorithms. Given a block-diagonal matrix structure, how can thread synchronization be minimized?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the role of matrix reordering in reducing computational complexity of sparse triangular solves. Compare the Reverse Cuthill-McKee and Minimum Degree algorithms."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the computational challenges of performing LU decomposition on highly sparse matrices. How does the Supernodal approach improve performance in sparse LU factorizations?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a real-world application such as Finite Element Analysis (FEA), describe how sparsity in the system matrix is leveraged to optimize computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the impact of matrix sparsity on iterative solvers such as GMRES and BiCGSTAB. How does the condition number of a sparse matrix influence convergence?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss hybrid approaches that combine direct and iterative methods for solving sparse linear systems. Provide examples where hybridization leads to significant performance gains."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a symmetric sparse matrix with bandwidth $b$, analyze the computational complexity of performing Cholesky factorization. Compare the complexity with that of a full dense matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the impact of matrix compression techniques such as Hierarchical Matrices (H-Matrices) and Tensor Train decomposition on optimizing sparse computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "How do adaptive sparse matrix storage formats (e.g., Adaptive CSR, Adaptive Blocking) dynamically switch between different storage formats based on sparsity patterns? Discuss their advantages in high-performance computing."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In deep learning, sparse weight matrices are often used to reduce computational cost. Describe how pruning techniques affect sparse matrix computations and propose an efficient algorithm for performing sparse-dense matrix multiplications in neural network training."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider an $n \\times n$ invertible matrix $A$. Discuss the computational complexity of computing its inverse using Gaussian elimination versus LU decomposition. Under what conditions is LU decomposition more efficient?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the role of pivoting in Gaussian elimination for matrix inversion. Explain how partial pivoting and complete pivoting improve numerical stability, and analyze their impact on the computational complexity."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compare the efficiency of LU decomposition, QR decomposition, and Singular Value Decomposition (SVD) for solving linear systems $Ax = b$. Under what circumstances is each method preferable?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a symmetric positive definite matrix $A$, explain why Cholesky decomposition $A = LL^T$ is preferred over LU decomposition. Provide a proof of existence and discuss computational advantages."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the concept of matrix condition number $\\kappa(A) = \\|A\\| \\|A^{-1}\\|$ in the context of numerical stability in matrix inversion. How does $\\kappa(A)$ affect the accuracy of computed solutions?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that for any invertible matrix $A$, the inverse can be computed using the Cayley-Hamilton theorem and the characteristic equation of $A$. Under what conditions is this method practical?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Moore-Penrose pseudoinverse $A^+$ is used for inverting singular or non-square matrices. Derive $A^+$ using Singular Value Decomposition (SVD) and explain its applications in least-squares problems."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss Strassen\u2019s algorithm for matrix inversion and analyze its computational complexity. How does it compare to the standard Gaussian elimination method?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the concept of a stable algorithm in matrix decomposition. Provide examples of numerically stable and unstable algorithms for computing matrix inverses."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose $A$ is an $n \\times n$ matrix that is nearly singular. Describe techniques for handling its inversion numerically, including regularization methods such as Tikhonov regularization."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a large sparse matrix $A$ stored in compressed sparse row (CSR) format, analyze the computational trade-offs between direct inversion and iterative solvers for solving $Ax = b$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the difference between full QR decomposition and reduced QR decomposition. When solving $Ax = b$ for an overdetermined system, why is the reduced form of QR preferred?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe how the Sherman-Morrison formula can be used to efficiently compute the inverse of a matrix when a rank-one update is applied. Derive the formula and discuss its applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Woodbury matrix identity provides an efficient way to compute the inverse of a perturbed matrix. Derive the identity and explain its use in large-scale systems."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that if $A$ is an orthogonal matrix, then $A^{-1} = A^T$. Discuss the implications of this property for numerical computation and stability in solving linear systems."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the role of Householder reflections in QR decomposition. Compare them to the Gram-Schmidt process in terms of numerical stability and computational efficiency."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the computational cost of performing an LU decomposition on a dense $n \\times n$ matrix. Compare this cost with the computational cost of direct matrix inversion."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a diagonalizable matrix $A = PDP^{-1}$. Explain how this decomposition can be used to efficiently compute $A^{-1}$. Under what conditions does this method become unstable?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the role of the condition number $\\kappa(A)$ in Cholesky decomposition. How does ill-conditioning affect the computed factors in $A = LL^T$?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Jacobi and Gauss-Seidel iterative methods are often used as alternatives to direct inversion. Analyze the convergence criteria for these methods and discuss when they outperform direct methods."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose $A$ is a symmetric matrix with eigenvalues $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$. Show that the inverse $A^{-1}$ exists if and only if all $\\lambda_i \\neq 0$, and express $A^{-1}$ in terms of its eigenvalues and eigenvectors."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the impact of parallelization on matrix decomposition algorithms. Compare CPU-based and GPU-based implementations of LU, QR, and SVD."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a block matrix\n          \\[\n          A =\n          \\begin{bmatrix}\n              B & C \\\\\n              D & E\n          \\end{bmatrix}\n          \\]\n          where $B, C, D, E$ are submatrices, derive the formula for computing $A^{-1}$ using the Schur complement."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the difference between the LDL decomposition and Cholesky decomposition for symmetric matrices. When is LDL preferred, and how does it affect numerical stability?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a low-rank matrix $A$, explain how rank-revealing QR decomposition can be used to efficiently approximate $A^{-1}$. Discuss its applications in data compression."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose we need to solve $Ax = b$ multiple times for different vectors $b$. Explain why LU decomposition with forward and backward substitution is more efficient than computing $A^{-1}$ explicitly."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a rectangular matrix $A$ of rank $r$, explain how SVD provides an optimal low-rank approximation of $A$. How is this property used in practical applications such as image compression?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss how iterative refinement can be used to improve the accuracy of a computed inverse $A^{-1}$. Derive an expression for the error reduction per iteration."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose a large, dense matrix $A$ is ill-conditioned. Compare the effectiveness of QR decomposition versus SVD in computing solutions to the linear system $Ax = b$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Bunch-Kaufman decomposition is an alternative to LU decomposition for symmetric indefinite matrices. Explain how it works and analyze its computational complexity."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the fundamental trade-offs between computational efficiency and numerical accuracy in solving large-scale linear systems $Ax = b$. Compare direct methods such as Gaussian elimination with iterative solvers like the Conjugate Gradient method."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a matrix $A$ with condition number $\\kappa(A)$. Explain how $\\kappa(A)$ influences numerical errors in computed solutions when using floating-point arithmetic. Provide examples illustrating how small perturbations in input data affect the solution."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In practical applications, matrix factorizations such as LU and QR are used instead of directly computing $A^{-1}$. Explain why this approach improves both accuracy and efficiency. Discuss scenarios where explicit inversion might still be useful."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given an ill-conditioned matrix $A$, describe strategies to minimize numerical errors when solving $Ax = b$. Compare the effects of using QR decomposition, regularization methods, and iterative refinement."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Floating-point precision can introduce rounding errors in matrix computations. Derive an upper bound on the rounding error when performing matrix-matrix multiplication $C = AB$ using standard IEEE 754 floating-point arithmetic."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The trade-off between storage and accuracy is particularly important for large matrices. Compare dense matrix representations with compressed sparse formats in terms of numerical stability and memory efficiency."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the role of machine precision $\\epsilon$ in numerical linear algebra. How does it impact the accuracy of matrix computations involving inversion, eigenvalue computation, and least-squares solutions?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a system $Ax = b$ where $A$ is nearly singular. Discuss why iterative solvers like GMRES or BiCGSTAB are preferred over direct solvers. Analyze their convergence behavior and numerical accuracy."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Approximate matrix computations, such as low-rank approximations, trade accuracy for efficiency. Discuss how the Singular Value Decomposition (SVD) can be used to approximate large matrices efficiently while minimizing reconstruction error."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the impact of finite precision arithmetic on matrix factorizations such as LU and Cholesky decomposition. How do numerical stability and rounding errors propagate in these methods?"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In parallel computing environments, matrix computations must balance load efficiency with numerical stability. Discuss the trade-offs in distributing computations across multiple processors and the impact on rounding error accumulation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "When solving least-squares problems, normal equations ($A^TAx = A^Tb$) and QR decomposition ($Ax = b$ using $A = QR$) are two approaches. Compare their numerical accuracy and computational efficiency, particularly in cases where $A$ is ill-conditioned."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Iterative refinement is a technique used to improve the accuracy of solutions to linear systems. Derive the iterative refinement formula and analyze how it compensates for floating-point errors."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Many matrix computations use iterative methods (e.g., Jacobi, Gauss-Seidel) instead of direct solvers. Analyze their convergence properties and discuss the trade-offs in terms of speed, memory usage, and accuracy."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider the problem of computing eigenvalues of a large matrix. Compare the efficiency and numerical stability of the Power Method, QR Algorithm, and Krylov subspace methods (e.g., Arnoldi iteration)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how the choice of basis in a vector space can affect numerical accuracy in matrix computations. Provide examples where changing the basis improves the numerical conditioning of a problem."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Many real-world problems involve computing the inverse of a nearly singular matrix. Compare Tikhonov regularization and truncated SVD as methods to handle this situation, discussing accuracy versus efficiency."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Floating-point underflow and overflow pose challenges in large-scale matrix computations. Analyze how these issues arise in recursive matrix computations and suggest strategies to mitigate their effects."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Sparse matrix solvers often use preconditioners to improve convergence rates in iterative methods. Explain the role of preconditioning in the Conjugate Gradient method and discuss the trade-offs between computational cost and numerical accuracy."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Compare the efficiency and accuracy of explicit matrix exponentiation versus Krylov subspace methods (e.g., Lanczos algorithm) for computing $e^A$ in large-scale applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the effects of round-off errors in Gram-Schmidt orthogonalization and explain why the Modified Gram-Schmidt (MGS) method is numerically more stable than the Classical Gram-Schmidt (CGS) algorithm."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "A low-rank approximation of a matrix is often used in machine learning and data science. Compare the computational complexity and accuracy trade-offs of using the Truncated SVD versus randomized algorithms for approximating a matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Woodbury matrix identity allows efficient computation of the inverse of a rank-$k$ update to a matrix. Derive this identity and discuss its practical applications in reducing computational cost."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a block matrix \n          \\[\n          A =\n          \\begin{bmatrix}\n              B & C \\\\\n              D & E\n          \\end{bmatrix}\n          \\]\n          where $B$ and $E$ are square matrices. Discuss the accuracy and efficiency trade-offs in computing $A^{-1}$ using the Schur complement."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Many iterative algorithms for matrix computations rely on stopping criteria. Compare the impact of absolute versus relative error tolerances in determining algorithm termination."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Chebyshev polynomial approximation is used in matrix function computations. Explain how this method balances computational efficiency with accuracy, and discuss its application in computing $f(A) = A^{-1}$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Many real-world problems require solving large systems of linear equations repeatedly with different right-hand sides. Explain why using LU factorization is more efficient than computing the inverse directly."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider the computation of eigenvalues of a symmetric matrix using the QR algorithm. Explain how Wilkinson\u2019s shift improves numerical accuracy while maintaining computational efficiency."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "When performing high-dimensional matrix computations, distributed computing frameworks like Apache Spark and MPI-based libraries are often used. Discuss the trade-offs between accuracy and parallel efficiency in distributed matrix computations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Approximate solutions to linear systems are often preferred over exact solutions when computational resources are limited. Compare the trade-offs between Krylov subspace methods and direct factorizations in solving large-scale sparse systems."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a linear transformation $T: \\mathbb{R}^2 \\to \\mathbb{R}^2$ represented by a matrix $A$. Discuss how the action of $A$ on any vector $\\mathbf{v}$ can be understood geometrically in terms of basis transformations. Provide examples where $A$ represents a reflection, rotation, or shear."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given the transformation matrix \n    \\[\n    A = \\begin{bmatrix} 3 & 4 \\\\ 0 & 2 \\end{bmatrix},\n    \\]\n    describe its geometric effect on the unit square in $\\mathbb{R}^2$. Compute the transformed coordinates of the square's vertices and determine whether the transformation preserves orientation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "A reflection transformation in $\\mathbb{R}^2$ is given by a matrix $R$. Show that $R^2 = I$ and explain geometrically why applying the transformation twice results in the identity transformation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The matrix \n    \\[\n    R_{\\theta} = \\begin{bmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{bmatrix}\n    \\]\n    represents a rotation in $\\mathbb{R}^2$. Derive its eigenvalues and eigenvectors and interpret them geometrically."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a transformation matrix $A$ such that $\\det(A) = -1$. Explain why such a transformation must involve a reflection or a combination of transformations that reverse orientation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In 3D space, a reflection about a plane passing through the origin can be represented by a matrix. Derive the general form of such a matrix when reflecting about the plane $ax + by + cz = 0$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider the transformation matrix\n    \\[\n    S = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix}.\n    \\]\n    Show that $S$ represents a shear transformation and analyze its effect on an arbitrary vector in $\\mathbb{R}^2$. Determine whether the transformation preserves angles and distances."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the concept of eigenvectors as invariant directions under a linear transformation. Provide an example of a transformation in $\\mathbb{R}^3$ with exactly one eigenvector and interpret its geometric meaning."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The standard projection onto the plane $z = 0$ in $\\mathbb{R}^3$ is given by the matrix\n    \\[\n    P = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}.\n    \\]\n    Find its eigenvalues and eigenvectors and explain their geometric significance."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In $\\mathbb{R}^3$, the matrix\n    \\[\n    A = \\begin{bmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\n    \\]\n    represents a rotation about the $z$-axis. Compute the angle of rotation and find the eigenvectors of $A$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the geometric significance of the singular value decomposition (SVD) of a matrix $A$. Interpret the left and right singular vectors as directions of transformation and scaling."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The composition of two linear transformations $T_1$ and $T_2$ corresponds to matrix multiplication. Show how the order of multiplication affects the geometric interpretation of transformations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that every 2D linear transformation with an orthogonal matrix either preserves or reverses orientation. Provide examples illustrating each case."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a 3D transformation matrix that represents a rotation followed by a reflection. Discuss how the determinant of the resulting matrix helps determine whether the transformation preserves or reverses orientation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a linear transformation $T$ that scales all vectors by a factor $\\lambda$, show that $T$ has $\\lambda$ as its only eigenvalue. Provide examples where this occurs."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss why a matrix with linearly dependent columns collapses the dimensionality of the space. Provide examples where a $3 \\times 3$ matrix maps $\\mathbb{R}^3$ onto a plane."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how the rank of a transformation matrix affects its geometric interpretation. Give examples of rank-deficient matrices and their effects on space."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The determinant of a matrix provides information about volume scaling under a transformation. Derive the geometric interpretation of the determinant for transformations in $\\mathbb{R}^2$ and $\\mathbb{R}^3$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a transformation matrix $A$ with eigenvalues $\\lambda_1, \\lambda_2, \\lambda_3$, explain how the determinant and trace of $A$ relate to its geometric properties."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Find the eigenvectors and eigenvalues of the following matrix and interpret their geometric significance:\n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In computer graphics, homogeneous coordinates are used to represent transformations. Explain how translation, scaling, and rotation are implemented using $3 \\times 3$ transformation matrices in $\\mathbb{R}^2$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider the linear transformation $T: \\mathbb{R}^3 \\to \\mathbb{R}^3$ given by a rotation about an arbitrary axis. Show that the eigenvector corresponding to eigenvalue 1 is the direction of the axis of rotation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how a non-diagonalizable matrix corresponds to a transformation that does not have a complete set of linearly independent eigenvectors. Provide a geometric interpretation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that any symmetric matrix represents a transformation that preserves orthogonality of eigenvectors and discuss its implications in geometry."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Jordan form of a matrix provides insight into its geometric properties. Explain the geometric meaning of Jordan blocks and discuss their significance in repeated transformations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that any transformation in $\\mathbb{R}^2$ that preserves the dot product must be a rotation or reflection. Prove that such transformations correspond to orthogonal matrices."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given two transformations represented by matrices $A$ and $B$, discuss under what conditions $AB = BA$ holds and provide a geometric interpretation of commuting matrices."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The polar decomposition of a matrix expresses it as a product of a unitary matrix and a symmetric positive semi-definite matrix. Explain its geometric significance and applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider an affine transformation in $\\mathbb{R}^2$ represented by a matrix and a translation vector. Explain how this differs from a purely linear transformation and discuss the role of augmented matrices."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the concept of isotropic scaling, anisotropic scaling, and shear transformations in $\\mathbb{R}^3$. Discuss the geometric interpretation of each using suitable transformation matrices."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In computer graphics, a transformation matrix is used to rotate a 3D object about an arbitrary axis. Derive the general rotation matrix for a rotation by angle $\\theta$ about an axis defined by the unit vector $\\mathbf{u} = (u_x, u_y, u_z)$. Discuss its properties and geometric interpretation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Homogeneous coordinates are commonly used in computer graphics to represent affine transformations. Explain why an extra dimension is introduced and derive the homogeneous transformation matrix for translation in $\\mathbb{R}^3$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a 3D transformation matrix that combines scaling, rotation, and translation, explain how these operations can be decomposed into individual transformation matrices. Discuss how the order of transformations affects the final result."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In image processing, convolution operations are performed using matrices. Given a 3x3 kernel matrix $K$, show how applying convolution to an image matrix $I$ can be formulated as matrix multiplication."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The shear transformation in 2D graphics is used to distort an image along the x or y axis. Derive the matrix representation of a shear transformation and analyze its effect on a square grid."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain how the Singular Value Decomposition (SVD) is used in image compression. Given an image matrix, describe the process of rank-k approximation and its effect on storage efficiency and quality."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In computer graphics, perspective projection is used to create realistic 3D renderings. Derive the perspective projection transformation matrix and explain how it maps 3D points to a 2D plane."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given an image transformation matrix that rotates an image by 45 degrees, determine how the bounding box of the image changes. Discuss the implications for image cropping and resizing."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the role of eigenvalues and eigenvectors in Principal Component Analysis (PCA) for dimensionality reduction in image processing. Explain how PCA can be applied to face recognition."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In 3D graphics, reflection across an arbitrary plane can be achieved using matrix transformations. Derive the matrix representation of a reflection about the plane $ax + by + cz = d$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "A common problem in graphics is aliasing, which occurs when a high-resolution image is downsampled. Explain how matrix-based filtering techniques (e.g., Gaussian blur) can be used to reduce aliasing effects."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The affine transformation matrix is a general form that includes rotation, scaling, translation, and shear. Show how the determinant of an affine transformation matrix affects the area or volume of transformed objects."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Discrete Cosine Transform (DCT) is widely used in JPEG image compression. Explain the role of DCT as a matrix operation and how it relates to energy compaction in image representation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "A 3D scene can be transformed using a sequence of matrices for rotation, translation, and scaling. Explain how these matrices are combined in the rendering pipeline and discuss their computational complexity."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a transformation matrix that scales an image non-uniformly, analyze its effect on image aspect ratio and explain how to compensate for distortions using inverse transformations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In texture mapping, an image (texture) is mapped onto a 3D object using UV coordinates. Describe how this process is implemented using transformation matrices and discuss interpolation techniques for smooth rendering."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Fast Fourier Transform (FFT) is often used in image processing for filtering operations. Explain how FFT can be expressed in terms of matrix-vector multiplication and discuss its computational advantages."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Harris corner detection algorithm relies on the eigenvalues of a structure tensor matrix. Explain how eigenvalues are used to identify corners and edges in an image."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given an image transformation pipeline consisting of rotation, scaling, and shearing, explain how the combined transformation matrix is obtained and how it affects the image properties."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In augmented reality applications, homography matrices are used to warp images onto surfaces. Derive the homography matrix for mapping a quadrilateral to another quadrilateral and discuss its applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that the composition of two orthogonal transformation matrices (e.g., rotations and reflections) results in another orthogonal matrix. Explain the geometric interpretation in the context of 3D transformations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In image enhancement, edge detection techniques such as Sobel filtering use convolution matrices. Explain the mathematical principles behind edge detection and the role of matrix derivatives."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The 3D viewing transformation in graphics involves converting world coordinates to camera coordinates. Explain the role of the view matrix in this process and derive its general form."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Non-rigid transformations, such as morphing, involve continuous deformations of an image. Explain how matrix interpolation techniques can be used to generate smooth transitions between two images."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The rank of a transformation matrix determines the dimensionality of the transformed space. Provide examples of matrices used in graphics that reduce dimension and discuss their significance."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a 2D image transformation matrix that rotates by $\\theta$ and scales by a factor of $s$, derive the inverse transformation and discuss its use in correcting distortions."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In animation, linear transformations are used to manipulate character models. Explain how skeletal animation uses transformation matrices and how blending multiple transformations creates smooth motion."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The eigenfaces method for face recognition relies on matrix decomposition. Explain how eigenvectors of a covariance matrix are used to represent facial features and discuss the advantages of this approach."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the numerical stability of transformation matrices in graphics. Explain how floating-point errors can accumulate during successive transformations and propose techniques to mitigate these issues."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The Laplacian matrix is used in image sharpening and edge detection. Explain how the second derivative of an image can be approximated using matrix operations and provide examples of its applications."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Let $P$ be an $n \\times n$ stochastic matrix representing a discrete-time Markov chain. Show that the sum of each row in $P$ is 1 and explain the significance of this property in modeling probabilistic transitions."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a Markov chain with transition matrix $P$, define a stationary distribution $\\pi$ and derive the equation $\\pi P = \\pi$. Discuss the conditions under which a stationary distribution is unique."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that for any finite, irreducible, and aperiodic Markov chain, the transition matrix $P$ has a unique stationary distribution. Provide a numerical example to illustrate the concept."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "The fundamental matrix $Z$ for an absorbing Markov chain is defined as $Z = (I - Q)^{-1}$, where $Q$ is the submatrix of transient states. Derive the expected number of steps before absorption using $Z$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a Markov chain with a transition matrix $P$. Show that the eigenvalue 1 is always present in $P$ and explain how the corresponding eigenvector relates to the steady-state distribution."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "A Markov chain is said to be ergodic if it is irreducible and aperiodic. Prove that for an ergodic Markov chain, the power of the transition matrix $P^k$ converges to a rank-one matrix as $k \\to \\infty$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In a birth-death process represented by a tridiagonal stochastic matrix, derive the conditions under which the Markov chain is irreducible and has a unique limiting distribution."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a Markov chain modeling web page ranking, where the transition matrix represents hyperlink transitions. Describe how Google's PageRank algorithm uses eigenvectors of a modified stochastic matrix to rank web pages."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a finite-state Markov chain with transition matrix $P$, define the mean recurrence time of a state and show how it is related to the stationary distribution."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the concept of detailed balance in a reversible Markov chain. Prove that if a stationary distribution $\\pi$ satisfies the detailed balance equation $\\pi_i P_{ij} = \\pi_j P_{ji}$, then the chain is time-reversible."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that for any finite-state Markov chain with transition matrix $P$, all eigenvalues satisfy $|\\lambda| \\leq 1$. Discuss the conditions under which $\\lambda = 1$ is the unique dominant eigenvalue."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Suppose a Markov chain models a queueing system, where the state represents the number of customers in a queue. Derive the steady-state probabilities for an M/M/1 queue using the balance equations."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Let $P$ be the transition matrix of a finite irreducible Markov chain. Show that as $k \\to \\infty$, the probability distribution vector $\\mathbf{v}P^k$ converges to the stationary distribution, regardless of the initial distribution $\\mathbf{v}$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In a Markov Decision Process (MDP), transition probabilities depend on chosen actions. Describe how stochastic matrices are extended in MDPs and explain the role of the Bellman equation in computing optimal policies."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Show that for a doubly stochastic transition matrix, the uniform distribution is always a stationary distribution. Provide an example of a Markov chain with a doubly stochastic transition matrix and analyze its steady-state behavior."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a reducible Markov chain with a block diagonal transition matrix, explain how the system decomposes into smaller independent Markov chains. Discuss implications for long-term behavior."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the notion of mixing time for a Markov chain, which measures how fast a chain converges to its stationary distribution. Derive an upper bound on the mixing time in terms of the spectral gap."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a Markov chain with transition matrix $P$. Prove that if $P$ is symmetric, then all its eigenvalues are real. Discuss the implications of this property in terms of convergence to equilibrium."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the first passage time $T_{ij}$ as the expected number of steps for a Markov chain to move from state $i$ to state $j$. Derive the system of equations satisfied by $T_{ij}$ and solve for a simple example."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe an application of Markov chains in financial modeling, such as credit rating transitions or stock price movements. Formulate a Markov model for the chosen application and analyze its long-term behavior."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the relationship between an undirected graph\u2019s adjacency matrix and its eigenvalues. Provide a detailed proof of the spectral theorem for an undirected graph, showing how the eigenvalues of the adjacency matrix are related to the graph\u2019s connectivity and its properties like the number of components, cliques, and paths. Illustrate with examples involving simple connected graphs."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a graph $G$ with adjacency matrix $A$, prove the Perron-Frobenius theorem for the largest eigenvalue of the adjacency matrix in the case where $G$ is strongly connected and irreducible. Show the implications of this theorem for the degree centrality of nodes in the graph and provide an algorithmic approach to calculate this centrality using eigenvectors of $A$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the Laplacian matrix of a graph and derive the relationships between the spectrum of the Laplacian matrix and various graph properties such as connectivity, number of spanning trees, and the number of connected components. Provide a detailed example with a graph and calculate the eigenvalues of the Laplacian matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the notion of graph connectivity in terms of the Laplacian matrix. Prove that the multiplicity of the eigenvalue zero in the Laplacian matrix corresponds to the number of connected components in the graph. Illustrate this with a graph and demonstrate how to compute the number of connected components using the Laplacian matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of spectral clustering using the Laplacian matrix of a graph. Discuss the steps involved in performing spectral clustering, including how the eigenvectors of the Laplacian matrix are used to partition the graph into clusters. Provide a concrete example of spectral clustering on a small graph, and explain the role of the second smallest eigenvalue (the Fiedler value)."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "In a network represented by a directed graph, the adjacency matrix is often non-symmetric. Investigate the relationship between the eigenvalues of the adjacency matrix and the graph\u2019s structure in the case of a directed graph. Discuss how the in-degree and out-degree centralities of nodes are related to the eigenvectors of the adjacency matrix, and provide an example calculation."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a graph with $n$ nodes and an associated adjacency matrix $A$. Prove that the diagonal entries of the Laplacian matrix of the graph are equal to the degree of the corresponding vertex, and show how this fact influences the properties of the Laplacian eigenvectors. Provide examples with several types of graphs, such as complete graphs, bipartite graphs, and trees."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Investigate the relationship between the graph's adjacency matrix and its centrality measures. Define and compute the degree centrality, closeness centrality, and betweenness centrality of a node in terms of the eigenvalues and eigenvectors of the adjacency matrix and Laplacian matrix. Provide an example where these centralities are computed for a real-world network."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that the adjacency matrix of a bipartite graph is a block matrix, where the blocks correspond to the partitions of the bipartite graph. Discuss how this block structure can simplify the computation of the spectral properties of the graph, and provide a detailed example of a bipartite graph where the eigenvalues are calculated."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the concept of the graph\u2019s spectral radius in terms of the adjacency matrix. Discuss its implications for the network's stability, and prove a relationship between the spectral radius and the largest eigenvalue of the graph\u2019s Laplacian matrix. Use an example to illustrate the concept of the spectral radius in the context of a strongly connected graph."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the use of the adjacency matrix in modeling the spread of a virus in a network. Derive the relationship between the adjacency matrix and the rate of spread, using eigenvalue analysis to discuss the long-term behavior of the epidemic in terms of graph structure. Provide a case study of a small network and analyze the epidemic's behavior using the spectral properties of the graph."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Describe the power method for finding the dominant eigenvalue of a graph\u2019s adjacency matrix. Discuss the convergence criteria and the implications of this method for large-scale graph analysis, particularly in network analysis. Provide a numerical example of applying the power method to find the largest eigenvalue of an adjacency matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Investigate the use of the Laplacian matrix in network flow analysis. Derive the conditions under which the flow in a network can be modeled by the eigenvectors of the Laplacian matrix. Discuss the applications of this result in optimizing network flows and computing minimum cuts. Provide an example of a flow network and demonstrate the use of the Laplacian eigenvectors."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Examine the concept of random walks on graphs in terms of the graph\u2019s Laplacian and adjacency matrices. Derive the relationship between the transition matrix of a random walk and the eigenvalues of the adjacency matrix. Discuss how the eigenvectors of the Laplacian matrix can be used to study the mixing time of a random walk and provide a concrete example with a simple graph."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a graph with the adjacency matrix $A$ and the Laplacian matrix $L$. Prove that the graph is connected if and only if the algebraic multiplicity of the eigenvalue zero of $L$ is 1. Discuss the practical implications of this result in network design, particularly in the context of ensuring network connectivity. Illustrate this with an example of a disconnected graph and compute its Laplacian eigenvalues."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given a linear time-invariant (LTI) system with the state-space representation \n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t),\n    \\]\n    where $A$, $B$, $C$, and $D$ are matrices of appropriate dimensions, discuss the conditions under which this system is controllable. Provide a detailed derivation of the controllability matrix and explain how to use the matrix rank condition to determine whether the system is controllable. Include an example of an LTI system and perform a controllability analysis using the controllability matrix."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a state-space model of a system where the system matrix $A$ is diagonalizable. Show that the solution to the differential equation $\\dot{x}(t) = Ax(t) + Bu(t)$ can be expressed as a matrix exponential. Provide the explicit form of the solution, including the influence of the control input $u(t)$ on the state evolution. Illustrate this with an example involving specific values for $A$ and $B$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Derive the necessary and sufficient conditions for the observability of a system with the state-space representation\n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t).\n    \\]\n    Define the observability matrix and show that the rank of this matrix determines the observability of the system. Use a practical example of an LTI system and compute the observability matrix to verify if the system is observable."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Using the Lyapunov stability criterion, prove that a linear system is asymptotically stable if and only if the real parts of all the eigenvalues of the system matrix $A$ are negative. Discuss the implications of this result for the stability analysis of systems in control theory and provide an example of a system where the stability of the system is determined using the eigenvalues of the matrix $A$."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Define the controllability and observability grammian matrices for a linear system and derive the conditions under which these matrices are positive definite. Explain the role of these grammian matrices in the design of optimal controllers and observers, and provide examples where these grammian matrices are used to determine the controllability and observability of specific systems."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Explain the concept of pole placement in the context of state-space systems. Derive the necessary conditions for pole placement in terms of the system\u2019s controllability matrix. Discuss how to use the controllability matrix to design state feedback controllers that place the poles of the closed-loop system in desired locations. Provide a detailed example of pole placement in a simple second-order system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a system with state-space representation\n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t).\n    \\]\n    Discuss the use of matrix methods to solve the system\u2019s state equations, particularly focusing on solving for the state vector $x(t)$ given initial conditions. Derive the general solution using the matrix exponential and discuss the role of the system matrix $A$ and input matrix $B$ in shaping the solution. Illustrate with a numerical example of solving the state equations for a given system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Given the state-space system \n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t),\n    \\]\n    explain the process of converting this system into its transfer function representation using matrix algebra. Discuss how the transfer function captures the behavior of the system in the frequency domain and derive the transfer function for a second-order system as an example."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the use of the Kalman controllability and observability conditions in the context of real-time control systems. Derive the Kalman controllability and observability matrices and explain how they are used to determine whether a system is controllable or observable from the perspective of both state feedback and measurement feedback. Provide a case study where these conditions are applied to assess the controllability and observability of a physical system."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Prove that the controllability matrix $W_c = [B, AB, A^2B, \\dots, A^{n-1}B]$ for a state-space representation is full rank if and only if the system is controllable. Discuss how the rank condition can be used to design controllers and identify the controllability properties of a system. Include an example of a system and demonstrate the calculation of the controllability matrix and its rank."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Consider a state-space representation of a system \n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t),\n    \\]\n    and derive the conditions under which the system is asymptotically stable. Using matrix methods, discuss the relation between the system matrix $A$ and the eigenvalues of the system. Discuss the design of controllers to ensure stability, focusing on the feedback matrix and its impact on the eigenvalues."
    },
    {
        "chapter": "Computations with Matrices",
        "question": "Discuss the design of an observer for an LTI system in state-space form. Explain how the observer matrix $L$ is chosen to ensure that the estimation error converges to zero. Provide a detailed derivation of the observer\u2019s dynamics and the observer gain matrix $L$, including conditions under which the observer converges. Provide an example of designing an observer for a simple system and verify the stability of the observer."
    },
    {
        "chapter": "Determinants",
        "question": "If a 4 by 4 matrix has $\\det(A) = \\frac{1}{2}$, find $\\det(2A)$, $\\det(-A)$, $\\det(A^2)$, and $\\det(A^{-1})$."
    },
    {
        "chapter": "Determinants",
        "question": "If a 3 by 3 matrix has $\\det(A) = -1$, find $\\det\\left(\\frac{1}{2}A\\right)$, $\\det(-A)$, $\\det(A^2)$, and $\\det(A^{-1})$."
    },
    {
        "chapter": "Determinants",
        "question": "Row exchange: Add row 1 of $A$ to row 2, then subtract row 2 from row 1. Then add row 1 to row 2 and multiply row 1 by $-1$ to reach $B$. Which rules show the following?\n    \\[\n    \\det(B) = \\begin{vmatrix} c & d \\\\ a & b \\end{vmatrix} = -\\det(A) = -\\begin{vmatrix} a & b \\\\ c & d \\end{vmatrix}.\n    \\]\n    Those rules could replace Rule 2 in the definition of the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "By applying row operations to produce an upper triangular $U$, compute:\n    \\[\n    \\det \\begin{bmatrix}\n    1 & 2 & -2 & 0 \\\\\n    2 & 3 & -4 & 1 \\\\\n    -1 & -2 & 0 & 2 \\\\\n    0 & 2 & 5 & 3\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\det \\begin{bmatrix}\n    2 & -1 & 0 & 0 \\\\\n    -1 & 2 & -1 & 0 \\\\\n    0 & -1 & 2 & -1 \\\\\n    0 & 0 & -1 & -2\n    \\end{bmatrix}.\n    \\]\n    Exchange rows 3 and 4 of the second matrix and recompute the pivots and determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Count row exchanges to find these determinants:\n    \\[\n    \\det \\begin{bmatrix}\n    0 & 0 & 0 & 1 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1 & 0 & 0 & 0\n    \\end{bmatrix} = \\pm 1\n    \\]\n    and\n    \\[\n    \\det \\begin{bmatrix}\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \\\\\n    1 & 0 & 0 & 0\n    \\end{bmatrix} = -1.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "For each $n$, how many exchanges will put (row $n$, row $n - 1$, ..., row 1) into the normal order (row 1, ..., row $n$)? Find $\\det P$ for the $n \\times n$ permutation matrix with 1s on the reverse diagonal. Problem 5 had $n = 4$."
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinants of:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "a rank one matrix\n        \\[\n        A = \\begin{bmatrix}\n        1 \\\\\n        4 \\\\\n        2\n        \\end{bmatrix}\n        \\begin{bmatrix}\n        2 & -1 & 2\n        \\end{bmatrix};\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "the upper triangular matrix\n        \\[\n        U = \\begin{bmatrix}\n        4 & 4 & 8 & 8 \\\\\n        0 & 1 & 2 & 2 \\\\\n        0 & 0 & 2 & 6 \\\\\n        0 & 0 & 0 & 2\n        \\end{bmatrix};\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "the lower triangular matrix $U^T$;"
    },
    {
        "chapter": "Determinants",
        "question": "the inverse matrix $U^{-1}$;"
    },
    {
        "chapter": "Determinants",
        "question": "the \u201creverse-triangular\u201d matrix that results from row exchanges,\n        \\[\n        M = \\begin{bmatrix}\n        0 & 0 & 0 & 2 \\\\\n        0 & 0 & 2 & 6 \\\\\n        0 & 1 & 2 & 2 \\\\\n        4 & 4 & 8 & 8\n        \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Show how rule 6 (det = 0 if a row is zero) comes directly from rules 2 and 3."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose you do two row operations at once, going from\n    \\[\n    \\begin{bmatrix}\n    a & b \\\\\n    c & d\n    \\end{bmatrix}\n    \\]\n    to\n    \\[\n    \\begin{bmatrix}\n    a - mc & b - md \\\\\n    c - \\ell a & d - \\ell b\n    \\end{bmatrix}.\n    \\]\n    Find the determinant of the new matrix, by rule 3 or by direct calculation."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( Q \\) is an orthogonal matrix, so that \\( Q^T Q = I \\), prove that \\( \\det Q \\) equals \\( +1 \\) or \\( -1 \\). What kind of box is formed from the rows (or columns) of \\( Q \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Prove again that \\( \\det Q = 1 \\) or \\( -1 \\) using only the Product rule. If \\( |\\det Q| > 1 \\) then \\( \\det Q^n \\) blows up. How do you know this can\u2019t happen to \\( Q^n \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Use row operations to verify that the 3 by 3 \u201cVandermonde determinant\u201d is\n    \\[\n    \\det \\begin{bmatrix}\n    1 & a & a^2 \\\\\n    1 & b & b^2 \\\\\n    1 & c & c^2\n    \\end{bmatrix} = (b - a)(c - a)(c - b).\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "(a) A skew-symmetric matrix satisfies \\( K^T = -K \\), as in\n    \\[\n    K = \\begin{bmatrix}\n    0 & a & b \\\\\n    -a & 0 & c \\\\\n    -b & -c & 0\n    \\end{bmatrix}.\n    \\]\n    In the 3 by 3 case, why is \\( \\det(-K) = (-1)^3 \\det K \\)? On the other hand \\( \\det K^T = \\det K \\) (always). Deduce that the determinant must be zero.\n\n    (b) Write down a 4 by 4 skew-symmetric matrix with \\( \\det K \\) not zero."
    },
    {
        "chapter": "Determinants",
        "question": "True or false, with reason if true and counterexample if false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "If \\( A \\) and \\( B \\) are identical except that \\( b_{11} = 2a_{11} \\), then \\( \\det B = 2 \\det A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "The determinant is the product of the pivots."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( A \\) is invertible and \\( B \\) is singular, then \\( A + B \\) is invertible."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( A \\) is invertible and \\( B \\) is singular, then \\( AB \\) is singular."
    },
    {
        "chapter": "Determinants",
        "question": "The determinant of \\( AB - BA \\) is zero."
    },
    {
        "chapter": "Determinants",
        "question": "If every row of \\( A \\) adds to zero, prove that \\( \\det A = 0 \\). If every row adds to 1, prove that \\( \\det(A - I) = 0 \\). Show by example that this does not imply \\( \\det A = 1 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Find these 4 by 4 determinants by Gaussian elimination:\n    \\[\n    \\det\n    \\begin{bmatrix}\n    11 & 12 & 13 & 14 \\\\\n    21 & 22 & 23 & 24 \\\\\n    31 & 32 & 33 & 34 \\\\\n    41 & 42 & 43 & 44\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\det\n    \\begin{bmatrix}\n    1 & t & t^2 & t^3 \\\\\n    t & 1 & t & t^2 \\\\\n    t^2 & t & 1 & t \\\\\n    t^3 & t^2 & t & 1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinants of\n    \\[\n    A =\n    \\begin{bmatrix}\n    4 & 2 \\\\\n    1 & 3\n    \\end{bmatrix}\n    \\]\n    \\[\n    A^{-1} =\n    \\frac{1}{10}\n    \\begin{bmatrix}\n    3 & -2 \\\\\n    -1 & 4\n    \\end{bmatrix}\n    \\]\n    \\[\n    A - \\lambda I =\n    \\begin{bmatrix}\n    4 - \\lambda & 2 \\\\\n    1 & 3 - \\lambda\n    \\end{bmatrix}\n    \\]\n    For which values of \\( \\lambda \\) is \\( A - \\lambda I \\) a singular matrix?"
    },
    {
        "chapter": "Determinants",
        "question": "Evaluate \\( \\det A \\) by reducing the matrix to triangular form (rules 5 and 7).\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 1 & 3 \\\\\n    0 & 4 & 6 \\\\\n    1 & 5 & 8\n    \\end{bmatrix}\n    \\]\n    \\[\n    B =\n    \\begin{bmatrix}\n    1 & 1 & 3 \\\\\n    0 & 4 & 6 \\\\\n    0 & 0 & 1\n    \\end{bmatrix}\n    \\]\n    \\[\n    C =\n    \\begin{bmatrix}\n    1 & 1 & 3 \\\\\n    0 & 4 & 6 \\\\\n    1 & 5 & 9\n    \\end{bmatrix}\n    \\]\n    What are the determinants of \\( B \\), \\( C \\), \\( AB \\), \\( A^T A \\), and \\( C^T \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose that \\( CD = -DC \\), and find the flaw in the following argument: Taking determinants gives \\( (\\det C)(\\det D) = -(\\det D)(\\det C) \\), so either \\( \\det C = 0 \\) or \\( \\det D = 0 \\). Thus \\( CD = -DC \\) is only possible if \\( C \\) or \\( D \\) is singular."
    },
    {
        "chapter": "Determinants",
        "question": "Do these matrices have determinant 0, 1, 2, or 3?\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & 0 & 1 \\\\\n    1 & 0 & 0 \\\\\n    0 & 1 & 0\n    \\end{bmatrix}\n    \\]\n    \\[\n    B =\n    \\begin{bmatrix}\n    0 & 1 & 1 \\\\\n    1 & 0 & 1 \\\\\n    1 & 1 & 0\n    \\end{bmatrix}\n    \\]\n    \\[\n    C =\n    \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "The inverse of a 2 by 2 matrix seems to have determinant = 1:\n    \\[\n    \\det A^{-1} = \\det \\left( \\frac{1}{ad - bc}\n    \\begin{bmatrix}\n    d & -b \\\\\n    -c & a\n    \\end{bmatrix} \\right)\n    =\n    \\frac{1}{ad - bc} \\cdot (ad - bc)\n    = 1\n    \\]\n    What is wrong with this calculation? What is the correct \\( \\det A^{-1} \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Reduce \\( A \\) to \\( U \\) and find \\( \\det A = \\) product of the pivots:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 2 & 2 \\\\\n    1 & 2 & 3\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    2 & 2 & 3 \\\\\n    3 & 3 & 3\n    \\end{bmatrix}\n    \\]\n    \\setcounter{enumi}{22} % Start enumeration at 23"
    },
    {
        "chapter": "Determinants",
        "question": "By applying row operations to produce an upper triangular \\( U \\), compute:\n    \\[\n    \\det\n    \\begin{bmatrix}\n    1 & 2 & 3 & 0 \\\\\n    2 & 6 & 6 & 1 \\\\\n    -1 & 0 & 0 & 3 \\\\\n    0 & 2 & 0 & 7\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\det\n    \\begin{bmatrix}\n    2 & 1 & 1 & 1 \\\\\n    1 & 2 & 1 & 1 \\\\\n    1 & 1 & 2 & 1 \\\\\n    1 & 1 & 1 & 2\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Use row operations to simplify and compute these determinants:\n    \\[\n    \\det\n    \\begin{bmatrix}\n    101 & 201 & 301 \\\\\n    102 & 202 & 302 \\\\\n    103 & 203 & 303\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\det\n    \\begin{bmatrix}\n    1 & t & t^2 \\\\\n    t & 1 & t \\\\\n    t^2 & t & 1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Elimination reduces \\( A \\) to \\( U \\). Then \\( A = LU \\):\n    \\[\n    A =\n    \\begin{bmatrix}\n    3 & 3 & 4 \\\\\n    6 & 8 & 7 \\\\\n    -3 & 5 & -9\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    2 & 1 & 0 \\\\\n    -1 & 4 & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    3 & 3 & 4 \\\\\n    0 & 2 & -1 \\\\\n    0 & 0 & -1\n    \\end{bmatrix}\n    = LU.\n    \\]\n    Find the determinants of \\( L \\), \\( U \\), \\( A \\), \\( U^{-1}L^{-1} \\), and \\( U^{-1}L^{-1}A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( a_{ij} \\) is \\( i \\) times \\( j \\), show that \\( \\det A = 0 \\). (Exception when \\( A = [1] \\).)"
    },
    {
        "chapter": "Determinants",
        "question": "If \\( a_{ij} \\) is \\( i + j \\), show that \\( \\det A = 0 \\). (Exception when \\( n = 1 \\) or \\( 2 \\).)"
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of these matrices by row operations:\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & a & 0 \\\\\n    0 & 0 & b \\\\\n    c & 0 & 0\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    0 & a & 0 & 0 \\\\\n    0 & 0 & b & 0 \\\\\n    0 & 0 & 0 & c \\\\\n    d & 0 & 0 & 0\n    \\end{bmatrix},\n    \\quad\n    C =\n    \\begin{bmatrix}\n    a & a & a \\\\\n    a & b & b \\\\\n    a & b & c\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "What is wrong with this proof that projection matrices have \\( \\det P = 1 \\)?\n    \\[\n    P = A(A^T A)^{-1}A^T \\quad \\text{so} \\quad |P| = |A| \\frac{1}{|A^T| |A|} |A^T| = 1.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "(Calculus question) Show that the partial derivatives of \\( \\ln(\\det A) \\) give \\( A^{-1} \\):\n    \\[\n    f(a, b, c, d) = \\ln(ad - bc) \\quad \\text{leads to} \\quad\n    \\begin{bmatrix}\n    \\partial f / \\partial a & \\partial f / \\partial c \\\\\n    \\partial f / \\partial b & \\partial f / \\partial d\n    \\end{bmatrix}\n    = A^{-1}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "(MATLAB) The Hilbert matrix \\texttt{hilb(n)} has \\( i, j \\) entry equal to \\( 1/(i + j - 1) \\). Print the determinants of \\texttt{hilb(1)}, \\texttt{hilb(2)}, ..., \\texttt{hilb(10)}. Hilbert matrices are hard to work with! What are the pivots?"
    },
    {
        "chapter": "Determinants",
        "question": "(MATLAB) What is a typical determinant (experimentally) of \\texttt{rand(n)} and \\texttt{randn(n)} for \\( n = 50, 100, 200, 400 \\)? (And what does \"Inf\" mean in MATLAB?)\n    \\setcounter{enumi}{32} % Start enumeration at 33"
    },
    {
        "chapter": "Determinants",
        "question": "Using MATLAB, find the largest determinant of a 4 by 4 matrix of 0s and 1s."
    },
    {
        "chapter": "Determinants",
        "question": "If you know that \\( \\det A = 6 \\), what is the determinant of \\( B \\)?\n    \\[\n    \\det A =\n    \\begin{vmatrix}\n    \\text{row 1} \\\\\n    \\text{row 2} \\\\\n    \\text{row 3}\n    \\end{vmatrix}\n    = 6\n    \\]\n    \\[\n    \\det B =\n    \\begin{vmatrix}\n    \\text{row 1} + \\text{row 2} \\\\\n    \\text{row 2} + \\text{row 3} \\\\\n    \\text{row 3} + \\text{row 1}\n    \\end{vmatrix}\n    = ?\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose the 4 by 4 matrix \\( M \\) has four equal rows all containing \\( a, b, c, d \\). We know that \\( \\det(M) = 0 \\). The problem is to find \\( \\det(I + M) \\) by any method:\n    \\[\n    \\det(I + M) =\n    \\begin{vmatrix}\n    1 + a & b & c & d \\\\\n    a & 1 + b & c & d \\\\\n    a & b & 1 + c & d \\\\\n    a & b & c & 1 + d\n    \\end{vmatrix}\n    \\]\n    Partial credit if you find this determinant when \\( a = b = c = d = 1 \\). Sudden death if you say that \\( \\det(I + M) = \\det I + \\det M \\)."
    },
    {
        "chapter": "Determinants",
        "question": "For these matrices, find the only nonzero term in the big formula (6):\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & 1 & 0 & 0 \\\\\n    1 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 1 \\\\\n    0 & 0 & 1 & 0\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B =\n    \\begin{bmatrix}\n    0 & 0 & 1 & 2 \\\\\n    0 & 3 & 4 & 5 \\\\\n    6 & 7 & 8 & 9 \\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}.\n    \\]\n    There is only one way of choosing four nonzero entries from different rows and different columns. By deciding even or odd, compute \\( \\det A \\) and \\( \\det B \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Expand those determinants in cofactors of the first row. Find the cofactors (they include the signs \\( (-1)^{i+j} \\)) and the determinants of \\( A \\) and \\( B \\)."
    },
    {
        "chapter": "Determinants",
        "question": "True or false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "The determinant of \\( S^{-1} A S \\) equals the determinant of \\( A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( \\det A = 0 \\), then at least one of the cofactors must be zero."
    },
    {
        "chapter": "Determinants",
        "question": "A matrix whose entries are 0s and 1s has determinant 1, 0, or \\( -1 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Find the LU factorization, the pivots, and the determinant of the 4 by 4 matrix whose entries are \\( a_{ij} = \\min(i, j) \\). (Write out the matrix.)"
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinant if \\( a_{ij} = \\min(n_i, n_j) \\), where \\( n_1 = 2 \\), \\( n_2 = 6 \\), \\( n_3 = 8 \\), \\( n_4 = 10 \\). Can you give a general rule for any \\( n_1 \\leq n_2 \\leq n_3 \\leq n_4 \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( F_n \\) be the determinant of the \\( 1, 1, -1 \\) tridiagonal matrix (n by n):\n    \\[\n    F_n = \\det\n    \\begin{bmatrix}\n    1 & -1 & 0 & \\cdots & 0 \\\\\n    1 & 1 & -1 & \\cdots & 0 \\\\\n    0 & 1 & 1 & \\ddots & 0 \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & -1 \\\\\n    0 & \\cdots & 0 & 1 & 1\n    \\end{bmatrix}.\n    \\]\n    By expanding in cofactors along row 1, show that \\( F_n = F_{n-1} + F_{n-2} \\). This yields the Fibonacci sequence \\( 1, 2, 3, 5, 8, 13, \\ldots \\) for the determinants."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose \\( A_n \\) is the \\( n \\times n \\) tridiagonal matrix with 1s on the three diagonals:\n    \\[\n    A_1 = [1], \\quad\n    A_2 =\n    \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 1\n    \\end{bmatrix}, \\quad\n    A_3 =\n    \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    1 & 1 & 1 \\\\\n    0 & 1 & 1\n    \\end{bmatrix}, \\ldots\n    \\]\n    Let \\( D_n \\) be the determinant of \\( A_n \\); we want to find it.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Expand in cofactors along the first row to show that \\( D_n = D_{n-1} - D_{n-2} \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Starting from \\( D_1 = 1 \\) and \\( D_2 = 0 \\), find \\( D_3, D_4, \\ldots, D_8 \\). By noticing how these numbers cycle around (with what period?) find \\( D_{1000} \\)."
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Evaluate this determinant by cofactors of row 1:\n        \\[\n        \\begin{vmatrix}\n        4 & 4 & 4 & 4 \\\\\n        1 & 2 & 0 & 1 \\\\\n        2 & 0 & 1 & 2 \\\\\n        1 & 1 & 0 & 2\n        \\end{vmatrix}.\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Check by subtracting column 1 from the other columns and recomputing."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of \\( A_2, A_3, A_4 \\). Can you predict \\( A_n \\)?\n    \\[\n    A_2 =\n    \\begin{bmatrix}\n    0 & 1 \\\\\n    1 & 0\n    \\end{bmatrix}, \\quad\n    A_3 =\n    \\begin{bmatrix}\n    0 & 1 & 1 \\\\\n    1 & 0 & 1 \\\\\n    1 & 1 & 0\n    \\end{bmatrix}, \\quad\n    A_4 =\n    \\begin{bmatrix}\n    0 & 1 & 1 & 1 \\\\\n    1 & 0 & 1 & 1 \\\\\n    1 & 1 & 0 & 1 \\\\\n    1 & 1 & 1 & 0\n    \\end{bmatrix}.\n    \\]\n    Use row operations to produce zeros, or use cofactors of row 1."
    },
    {
        "chapter": "Determinants",
        "question": "How many multiplications are required to find an \\( n \\times n \\) determinant from:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "the big formula (6)?"
    },
    {
        "chapter": "Determinants",
        "question": "the cofactor formula (10), building from the count for \\( n-1 \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "the product of pivots formula (including the elimination steps)?"
    },
    {
        "chapter": "Determinants",
        "question": "In a \\( 5 \\times 5 \\) matrix, does a \\( + \\) sign or \\( - \\) sign go with \\( a_{15}a_{24}a_{33}a_{42}a_{51} \\) down the reverse diagonal? In other words, is \\( P = (5,4,3,2,1) \\) even or odd? The checkerboard pattern of \\( \\pm \\) signs for cofactors does not give \\( \\det P \\)."
    },
    {
        "chapter": "Determinants",
        "question": "If \\( A \\) is \\( m \\times n \\) and \\( B \\) is \\( n \\times m \\), explain why\n    \\[\n    \\det\n    \\begin{bmatrix}\n    0 & A \\\\\n    -B & I\n    \\end{bmatrix}\n    = \\det(AB).\n    \\]\n    \\textit{Hint:} Postmultiply by\n    \\[\n    \\begin{bmatrix}\n    I & 0 \\\\\n    B & I\n    \\end{bmatrix}.\n    \\]\n    Do an example with \\( m < n \\) and an example with \\( m > n \\). Why does your second example automatically have \\( \\det(AB) = 0 \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose the matrix \\( A \\) is fixed, except that \\( a_{11} \\) varies from \\( -\\infty \\) to \\( +\\infty \\). Give examples in which \\( \\det A \\) is always zero or never zero. Then show from the cofactor expansion (8) that otherwise \\( \\det A = 0 \\) for exactly one value of \\( a_{11} \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of \\( A \\), \\( B \\), and \\( C \\) from six terms. Are the rows independent?\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    3 & 1 & 2 \\\\\n    3 & 2 & 1\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 4 & 4 \\\\\n    5 & 6 & 7\n    \\end{bmatrix},\n    \\quad\n    C =\n    \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 0 \\\\\n    1 & 0 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of \\( A \\), \\( B \\), and \\( C \\). Are their columns independent?\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    1 & 0 & 1 \\\\\n    0 & 1 & 1\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6 \\\\\n    7 & 8 & 9\n    \\end{bmatrix},\n    \\quad\n    C =\n    \\begin{bmatrix}\n    A & 0 \\\\\n    0 & B\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Show that \\( \\det A = 0 \\), regardless of the five nonzeros marked by \\( x \\)'s:\n    \\[\n    A =\n    \\begin{bmatrix}\n    x & x & x \\\\\n    0 & 0 & x \\\\\n    0 & 0 & x\n    \\end{bmatrix}.\n    \\]\n    (What is the rank of \\( A \\)?)"
    },
    {
        "chapter": "Determinants",
        "question": "This problem shows in two ways that $\\det A = 0$ (the $x$'s are any numbers):\n    \\[\n    A =\n    \\begin{bmatrix}\n    x & x & x & x & x \\\\\n    x & x & x & x & x \\\\\n    0 & 0 & 0 & x & x \\\\\n    0 & 0 & 0 & x & x \\\\\n    0 & 0 & 0 & x & x\n    \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "How do you know that the rows are linearly dependent?"
    },
    {
        "chapter": "Determinants",
        "question": "Explain why all 120 terms are zero in the big formula for $\\det A$."
    },
    {
        "chapter": "Determinants",
        "question": "Find two ways to choose nonzeros from four different rows and columns:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 1 \\\\\n    0 & 1 & 1 & 1 \\\\\n    1 & 1 & 0 & 1 \\\\\n    1 & 0 & 0 & 1\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 2 \\\\\n    0 & 3 & 4 & 5 \\\\\n    5 & 4 & 0 & 3 \\\\\n    2 & 0 & 0 & 1\n    \\end{bmatrix}.\n    \\]\n    (B has the same zeros as A.) Is $\\det A$ equal to $1+1$, $1-1$, or $-1-1$? What is $\\det B$?"
    },
    {
        "chapter": "Determinants",
        "question": "Place the smallest number of zeros in a $4 \\times 4$ matrix that will guarantee $\\det A = 0$. Place as many zeros as possible while still allowing $\\det A \\neq 0$."
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "If $a_{11} = a_{22} = a_{33} = 0$, how many of the six terms in $\\det A$ will be zero?"
    },
    {
        "chapter": "Determinants",
        "question": "If $a_{11} = a_{22} = a_{33} = a_{44} = 0$, how many of the 24 products $a_{1j}a_{2k}a_{3\\ell}a_{4m}$ are sure to be zero?"
    },
    {
        "chapter": "Determinants",
        "question": "How many $5 \\times 5$ permutation matrices have $\\det P = +1$? Those are even permutations. Find one that needs four exchanges to reach the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "If $\\det A \\neq 0$, at least one of the $n!$ terms in the big formula (6) is not zero. Deduce that some ordering of the rows of $A$ leaves no zeros on the diagonal. (Don\u2019t use $P$ from elimination; that $PA$ can have zeros on the diagonal.)"
    },
    {
        "chapter": "Determinants",
        "question": "Prove that 4 is the largest determinant for a $3 \\times 3$ matrix of 1s and $-1$s."
    },
    {
        "chapter": "Determinants",
        "question": "How many permutations of $(1,2,3,4)$ are even and what are they? Extra credit: What are all the possible $4 \\times 4$ determinants of $I + P_{\\text{even}}$?"
    },
    {
        "chapter": "Determinants",
        "question": "Problems 24\u201333 use cofactors $C_{ij} = (-1)^{i+j} \\det M_{ij}$. Delete row $i$, column $j$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Find cofactors and then transpose. Multiply $C^T A$ and $C^T B$ by $A$ and $B$!\n        \\[\n        A =\n        \\begin{bmatrix}\n        2 & 1 \\\\\n        3 & 6\n        \\end{bmatrix},\n        \\quad\n        B =\n        \\begin{bmatrix}\n        1 & 2 & 3 \\\\\n        4 & 5 & 6 \\\\\n        7 & 0 & 0\n        \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Find the cofactor matrix $C$ and compare $AC^T$ with $A^{-1}$:\n    \\[\n    A =\n    \\begin{bmatrix}\n    2 & -1 & 0 \\\\\n    -1 & 2 & -1 \\\\\n    0 & -1 & 2\n    \\end{bmatrix},\n    \\quad\n    A^{-1} =\n    \\frac{1}{4}\n    \\begin{bmatrix}\n    3 & 2 & 1 \\\\\n    2 & 4 & 2 \\\\\n    1 & 2 & 3\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "This problem shows in two ways that $\\det A = 0$ (the $x$'s are any numbers):\n\\[\nA =\n\\begin{bmatrix}\nx & x & x & x & x \\\\\nx & x & x & x & x \\\\\n0 & 0 & 0 & x & x \\\\\n0 & 0 & 0 & x & x \\\\\n0 & 0 & 0 & x & x\n\\end{bmatrix}\n\\]\n\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Find two ways to choose nonzeros from four different rows and columns:\n\\[\nA =\n\\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 1 & 1 \\\\\n1 & 1 & 0 & 1 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}\n\\quad\nB =\n\\begin{bmatrix}\n1 & 0 & 0 & 2 \\\\\n0 & 3 & 4 & 5 \\\\\n5 & 4 & 0 & 3 \\\\\n2 & 0 & 0 & 1\n\\end{bmatrix}\n\\]\nIs $\\det A$ equal to $1+1$ or $1-1$ or $-1-1$? What is $\\det B$?"
    },
    {
        "chapter": "Determinants",
        "question": "Place the smallest number of zeros in a $4 \\times 4$ matrix that will guarantee $\\det A = 0$. Place as many zeros as possible while still allowing $\\det A \\neq 0$."
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "How many $5 \\times 5$ permutation matrices have $\\det P = +1$? Those are even permutations. Find one that needs four exchanges to reach the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "If $\\det A \\neq 0$, at least one of the $n!$ terms in the big formula is not zero. Deduce that some ordering of the rows of $A$ leaves no zeros on the diagonal. (Don't use $P$ from elimination; that $PA$ can have zeros on the diagonal.)"
    },
    {
        "chapter": "Determinants",
        "question": "Prove that 4 is the largest determinant for a $3 \\times 3$ matrix of 1s and $-1$s."
    },
    {
        "chapter": "Determinants",
        "question": "How many permutations of $(1,2,3,4)$ are even and what are they? Extra credit: What are all the possible $4 \\times 4$ determinants of $I + P_{\\text{even}}$?"
    },
    {
        "chapter": "Determinants",
        "question": "Problems 24\u201333 use cofactors $C_{ij} = (-1)^{i+j} \\det M_{ij}$. Delete row $i$, column $j$.\n\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Find the cofactor matrix $C$ and compare $AC^T$ with $A^{-1}$:\n\\[\nA =\n\\begin{bmatrix}\n2 & -1 & 0 \\\\\n-1 & 2 & -1 \\\\\n0 & -1 & 2\n\\end{bmatrix}\n\\]\n\\[\nA^{-1} =\n\\frac{1}{4}\n\\begin{bmatrix}\n3 & 2 & 1 \\\\\n2 & 4 & 2 \\\\\n1 & 2 & 3\n\\end{bmatrix}\n\\]"
    },
    {
        "chapter": "Determinants",
        "question": "For these matrices, find the only nonzero term in the big formula (6):\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "\\( A = \\begin{pmatrix}\n            0 & 1 & 0 & 0 \\\\\n            1 & 0 & 1 & 0 \\\\\n            0 & 1 & 0 & 1 \\\\\n            0 & 0 & 1 & 0\n        \\end{pmatrix} \\)"
    },
    {
        "chapter": "Determinants",
        "question": "\\( B = \\begin{pmatrix}\n            0 & 0 & 1 & 2 \\\\\n            0 & 3 & 4 & 5 \\\\\n            6 & 7 & 8 & 9 \\\\\n            0 & 0 & 0 & 1\n        \\end{pmatrix} \\)\n    \\end{itemize}\n    There is only one way of choosing four nonzero entries from different rows and different columns. By deciding even or odd, compute \\( \\det A \\) and \\( \\det B \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Expand those determinants in cofactors of the first row. Find the cofactors (they include the signs \\( (-1)^{i+j} \\)) and the determinants of \\( A \\) and \\( B \\)."
    },
    {
        "chapter": "Determinants",
        "question": "True or false?\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( F_n \\) be the determinant of the 1, 1, -1 tridiagonal matrix (n by n):\n    \\[\n    F_n = \\det \\begin{pmatrix}\n        1 & -1 & 0 & \\cdots & 0 \\\\\n        1 & 1 & -1 & \\cdots & 0 \\\\\n        0 & 1 & 1 & \\ddots & \\vdots \\\\\n        \\vdots & \\ddots & \\ddots & \\ddots & -1 \\\\\n        0 & \\cdots & 0 & 1 & 1\n    \\end{pmatrix}.\n    \\]\n    By expanding in cofactors along row 1, show that \\( F_n = F_{n-1} + F_{n-2} \\). This yields the Fibonacci sequence 1, 2, 3, 5, 8, 13, ... for the determinants."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose \\( A_n \\) is the n by n tridiagonal matrix with 1s on the three diagonals:\n    \\[\n    A_1 = \\begin{pmatrix} 1 \\end{pmatrix}, \\quad\n    A_2 = \\begin{pmatrix}\n        1 & 1 \\\\\n        1 & 1\n    \\end{pmatrix}, \\quad\n    A_3 = \\begin{pmatrix}\n        1 & 1 & 0 \\\\\n        1 & 1 & 1 \\\\\n        0 & 1 & 1\n    \\end{pmatrix}, \\ldots\n    \\]\n    Let \\( D_n \\) be the determinant of \\( A_n \\); we want to find it.\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of \\( A_2, A_3, A_4 \\). Can you predict \\( A_n \\)?\n    \\[\n    A_2 = \\begin{pmatrix}\n        0 & 1 \\\\\n        1 & 0\n    \\end{pmatrix}, \\quad\n    A_3 = \\begin{pmatrix}\n        0 & 1 & 1 \\\\\n        1 & 0 & 1 \\\\\n        1 & 1 & 0\n    \\end{pmatrix}, \\quad\n    A_4 = \\begin{pmatrix}\n        0 & 1 & 1 & 1 \\\\\n        1 & 0 & 1 & 1 \\\\\n        1 & 1 & 0 & 1 \\\\\n        1 & 1 & 1 & 0\n    \\end{pmatrix}.\n    \\]\n    Use row operations to produce zeros, or use cofactors of row 1."
    },
    {
        "chapter": "Determinants",
        "question": "How many multiplications to find an n by n determinant from\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "In a 5 by 5 matrix, does a + sign or - sign go with \\( a_{15} a_{24} a_{33} a_{42} a_{51} \\) down the reverse diagonal? In other words,\n::contentReference[oaicite:0]{index=0}"
    },
    {
        "chapter": "Determinants",
        "question": "For these matrices, find the only nonzero term in the big formula (6):\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & 1 & 0 & 0 \\\\\n    1 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 1 \\\\\n    0 & 0 & 1 & 0\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B =\n    \\begin{bmatrix}\n    0 & 0 & 1 & 2 \\\\\n    0 & 3 & 4 & 5 \\\\\n    6 & 7 & 8 & 9 \\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}.\n    \\]\n    There is only one way of choosing four nonzero entries from different rows and different columns. By deciding even or odd, compute $\\det A$ and $\\det B$."
    },
    {
        "chapter": "Determinants",
        "question": "Expand those determinants in cofactors of the first row. Find the cofactors (they include the signs $(-1)^{i+j}$) and the determinants of $A$ and $B$."
    },
    {
        "chapter": "Determinants",
        "question": "True or false?\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Let $F_n$ be the determinant of the $1, 1, -1$ tridiagonal matrix (n by n):\n    \\[\n    F_n = \\det\n    \\begin{bmatrix}\n    1 & -1 \\\\\n    1 & 1 & -1 \\\\\n    & 1 & 1 & -1 \\\\\n    & & \\ddots & \\ddots & \\ddots \\\\\n    & & & 1 & 1\n    \\end{bmatrix}.\n    \\]\n    By expanding in cofactors along row 1, show that $F_n = F_{n-1} + F_{n-2}$. This yields the Fibonacci sequence $1, 2, 3, 5, 8, 13, \\ldots$ for the determinants."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose $A_n$ is the $n$ by $n$ tridiagonal matrix with 1s on the three diagonals:\n    \\[\n    A_1 =\n    \\begin{bmatrix}\n    1\n    \\end{bmatrix},\n    \\quad\n    A_2 =\n    \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 1\n    \\end{bmatrix},\n    \\quad\n    A_3 =\n    \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    1 & 1 & 1 \\\\\n    0 & 1 & 1\n    \\end{bmatrix},\n    \\quad \\ldots\n    \\]\n    Let $D_n$ be the determinant of $A_n$; we want to find it.\n    \\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinants of $A_2$, $A_3$, $A_4$. Can you predict $A_n$?\n    \\[\n    A_2 =\n    \\begin{bmatrix}\n    0 & 1 \\\\\n    1 & 0\n    \\end{bmatrix},\n    \\quad\n    A_3 =\n    \\begin{bmatrix}\n    0 & 1 & 1 \\\\\n    1 & 0 & 1 \\\\\n    1 & 1 & 0\n    \\end{bmatrix},\n    \\quad\n    A_4 =\n    \\begin{bmatrix}\n    0 & 1 & 1 & 1 \\\\\n    1 & 0 & 1 & 1 \\\\\n    1 & 1 & 0 & 1 \\\\\n    1 & 1 & 1 & 0\n    \\end{bmatrix}.\n    \\]\n    Use row operations to produce zeros, or use cofactors of row 1."
    },
    {
        "chapter": "Determinants",
        "question": "Using MATLAB, find the largest determinant of a $4 \\times 4$ matrix of 0s and 1s."
    },
    {
        "chapter": "Determinants",
        "question": "If you know that $\\det A = 6$, what is the determinant of $B$?\n    \\[\n    A =\n    \\begin{vmatrix}\n    & & & \\\\\n    & & & \\\\\n    & & & \\\\\n    & & & \\\\\n    \\end{vmatrix}\n    = 6\n    \\]\n    \\[\n    B =\n    \\begin{vmatrix}\n    \\text{row 1} + \\text{row 2} \\\\\n    \\text{row 2} + \\text{row 3} \\\\\n    \\text{row 3} + \\text{row 1} \\\\\n    \\end{vmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose the $4 \\times 4$ matrix $M$ has four equal rows all containing $a, b, c, d$. We know that $\\det(M) = 0$. The problem is to find $\\det(I + M)$ by any method:\n    \\[\n    I + M =\n    \\begin{vmatrix}\n    1 + a & b & c & d \\\\\n    a & 1 + b & c & d \\\\\n    a & b & 1 + c & d \\\\\n    a & b & c & 1 + d \\\\\n    \\end{vmatrix}\n    \\]\n    Partial credit if you find this determinant when $a = b = c = d = 1$. Sudden death if you say that $\\det(I + M) = \\det I + \\det M$."
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinant and all nine cofactors $C_{ij}$ of this triangular matrix:\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    0 & 4 & 0 \\\\\n    0 & 0 & 5\n    \\end{bmatrix}\n    \\]\n    Form $C^T$ and verify that $A C^T = (\\det A) I$. What is $A^{-1}$?"
    },
    {
        "chapter": "Determinants",
        "question": "Use the cofactor matrix $C$ to invert these symmetric matrices:\n    \\[\n    A = \\begin{bmatrix}\n    2 & -1 & 0 \\\\\n    -1 & 2 & -1 \\\\\n    0 & -1 & 2\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 2 & 2 \\\\\n    1 & 2 & 3\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Find $x$, $y$, and $z$ by Cramer's Rule in equation (4):\n    \\[\n    ax + by = 1 \\quad \\text{and} \\quad cx + dy = 0\n    \\]\n    \\[\n    x + 4y - z = 1 \\quad \\text{and} \\quad x + y + z = 0 \\quad \\text{and} \\quad 2x + 3z = 0.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinant when a vector $x$ replaces column $j$ of the identity (consider $x_j = 0$ as a separate case):\n        \\[\n        M = \\begin{bmatrix}\n        1 & x_1 \\\\\n        1 & \\cdot \\\\\n        x_j & \\cdot \\\\\n        1 & x_n \\\\\n        1\n        \\end{bmatrix}\n        \\]\n        then $\\det M = \\ldots$."
    },
    {
        "chapter": "Determinants",
        "question": "If $Ax = b$, show that $AM$ is the matrix $B_j$ in equation (4), with $b$ in column $j$."
    },
    {
        "chapter": "Determinants",
        "question": "Derive Cramer's rule by taking determinants in $AM = B_j$."
    },
    {
        "chapter": "Determinants",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Draw the triangle with vertices $A = (2,2)$, $B = (-1,3)$, and $C = (0,0)$. By regarding it as half of a parallelogram, explain why its area equals\n        \\[\n        \\text{area}(ABC) = \\frac{1}{2} \\det \\begin{bmatrix}\n        2 & 2 \\\\\n        -1 & 3\n        \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Move the third vertex to $C = (1,-4)$ and justify the formula\n        \\[\n        \\text{area}(ABC) = \\frac{1}{2} \\det \\begin{bmatrix}\n        x_1 & y_1 & 1 \\\\\n        x_2 & y_2 & 1 \\\\\n        x_3 & y_3 & 1\n        \\end{bmatrix} = \\frac{1}{2} \\det \\begin{bmatrix}\n        2 & 2 & 1 \\\\\n        -1 & 3 & 1 \\\\\n        1 & -4 & 1\n        \\end{bmatrix}.\n        \\]\n        Hint: Subtracting the last row from each of the others leaves\n        \\[\n        \\det \\begin{bmatrix}\n        2 & 2 & 1 \\\\\n        -1 & 3 & 1 \\\\\n        1 & -4 & 1\n        \\end{bmatrix} = \\det \\begin{bmatrix}\n        1 & 6 & 0 \\\\\n        -2 & 7 & 0 \\\\\n        1 & -4 & 1\n        \\end{bmatrix} = \\det \\begin{bmatrix}\n        1 & 6 \\\\\n        -2 & 7\n        \\end{bmatrix}.\n        \\]\n        Sketch $A_0 = (1,6)$, $B_0 = (-2,7)$, $C_0 = (0,0)$ and their relation to $A$, $B$, $C$."
    },
    {
        "chapter": "Determinants",
        "question": "Explain in terms of volumes why $\\det(3A) = 3^n \\det(A)$ for an $n \\times n$ matrix $A$."
    },
    {
        "chapter": "Determinants",
        "question": "Predict in advance, and confirm by elimination, the pivot entries of\n    \\[\n    A = \\begin{bmatrix}\n    2 & 1 & 2 \\\\\n    4 & 5 & 0 \\\\\n    2 & 7 & 0\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B = \\begin{bmatrix}\n    2 & 1 & 2 \\\\\n    4 & 5 & 3 \\\\\n    2 & 7 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Find all the odd permutations of the numbers $\\{1,2,3,4\\}$. They come from an odd number of exchanges and lead to $\\det(P) = -1$."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose the permutation $P$ takes $(1,2,3,4,5)$ to $(5,4,1,2,3)$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "What does $P^2$ do to $(1,2,3,4,5)$?"
    },
    {
        "chapter": "Determinants",
        "question": "What does $P^{-1}$ do to $(1,2,3,4,5)$?"
    },
    {
        "chapter": "Determinants",
        "question": "If $P$ is an odd permutation, explain why $P^2$ is even but $P^{-1}$ is odd."
    },
    {
        "chapter": "Determinants",
        "question": "Prove that if you keep multiplying $A$ by the same permutation matrix $P$, the first row eventually comes back to its original place."
    },
    {
        "chapter": "Determinants",
        "question": "If $A$ is a $5 \\times 5$ matrix with all $|a_{ij}| \\leq 1$, then $\\det(A) \\leq \\ldots$. Volumes or the big formula or pivots should give some upper bound on the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Solve these linear equations by Cramer's Rule $x_j = \\frac{\\det(B_j)}{\\det(A)}$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "$2x_1 + 5x_2 = 1$ \\quad and \\quad $x_1 + 4x_2 = 2$."
    },
    {
        "chapter": "Determinants",
        "question": "$2x_1 + x_2 = 1$ \\quad and \\quad $x_1 + 2x_2 + x_3 = 70$ \\quad and \\quad $x_2 + 2x_3 = 0$."
    },
    {
        "chapter": "Determinants",
        "question": "Use Cramer's Rule to solve for $y$ (only). Call the $3 \\times 3$ determinant $D$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "$ax + by = 1$ \\quad and \\quad $cx + dy = 0$."
    },
    {
        "chapter": "Determinants",
        "question": "$ax + by + cz = 1$ \\quad and \\quad $dx + ey - fz = 0$ \\quad and \\quad $gx + hy + iz = 0$."
    },
    {
        "chapter": "Determinants",
        "question": "Cramer's Rule breaks down when $\\det(A) = 0$. Example (a) has no solution, whereas (b) has infinitely many. What are the ratios $x_j = \\frac{\\det(B_j)}{\\det(A)}$?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "$2x_1 + 3x_2 = 1$ \\quad and \\quad $4x_1 + 6x_2 = 1$. (parallel lines)"
    },
    {
        "chapter": "Determinants",
        "question": "$2x_1 + 3x_2 = 1$ \\quad and \\quad $4x_1 + 6x_2 = 2$. (same line)"
    },
    {
        "chapter": "Determinants",
        "question": "Quick proof of Cramer's rule. The determinant is a linear function of column 1. It is zero if two columns are equal. When $b = A x = x_1 a_1 + x_2 a_2 + x_3 a_3$ goes into column 1 to produce $B_1$, the determinant is\n    \\[\n    \\left| \\begin{array}{ccc} \n    b & a_2 & a_3\n    \\end{array} \\right| = \\left| \\begin{array}{ccc} \n    x_1 a_1 + x_2 a_2 + x_3 a_3 & a_2 & a_3\n    \\end{array} \\right| = x_1 \\left| \\begin{array}{ccc} \n    a_1 & a_2 & a_3\n    \\end{array} \\right| = x_1 \\det(A).\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "What formula for $x_1$ comes from left side = right side?"
    },
    {
        "chapter": "Determinants",
        "question": "What steps lead to the middle equation?"
    },
    {
        "chapter": "Determinants",
        "question": "If the right side $b$ is the last column of $A$, solve the $3 \\times 3$ system $A x = b$. Explain how each determinant in Cramer's Rule leads to your solution $x$."
    },
    {
        "chapter": "Determinants",
        "question": "Find $A^{-1}$ from the cofactor formula $C^T/\\det(A)$. Use symmetry in part (b):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "$A = \\begin{bmatrix} \n        1 & 2 & 0 \\\\\n        0 & 3 & 0 \\\\\n        0 & 4 & 1\n        \\end{bmatrix}$"
    },
    {
        "chapter": "Determinants",
        "question": "$A = \\begin{bmatrix} \n        2 & -1 & 0 \\\\\n        -1 & 2 & -1 \\\\\n        0 & -1 & 2\n        \\end{bmatrix}$"
    },
    {
        "chapter": "Determinants",
        "question": "If all the cofactors are zero, how do you know that $A$ has no inverse? If none of the cofactors are zero, is $A$ sure to be invertible?"
    },
    {
        "chapter": "Determinants",
        "question": "Find the cofactors of $A$ and multiply $A C^T$ to find $\\det(A)$:\n    \\[\n    A = \\begin{bmatrix} \n    1 & 1 & 4 \\\\\n    1 & 2 & 2 \\\\\n    1 & 2 & 5\n    \\end{bmatrix}, \\quad C = \\begin{bmatrix} \n    6 & -3 & 0 \\\\\n    \\cdots & \\cdots & \\cdots\n    \\end{bmatrix}, \\quad A C^T = \\dots\n    \\]\n    If you change that corner entry from 4 to 100, why is $\\det(A)$ unchanged?"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose $\\det(A) = 1$ and you know all the cofactors. How can you find $A$?"
    },
    {
        "chapter": "Determinants",
        "question": "From the formula $A C^T = (\\det(A)) I$, show that $\\det(C) = (\\det(A))^{n-1}$."
    },
    {
        "chapter": "Determinants",
        "question": "(For professors only) If you know all 16 cofactors of a $4 \\times 4$ invertible matrix $A$, how would you find $A$?"
    },
    {
        "chapter": "Determinants",
        "question": "If all entries of $A$ are integers, and $\\det(A) = 1$ or $-1$, prove that all entries of $A^{-1}$ are integers. Give a $2 \\times 2$ example."
    },
    {
        "chapter": "Determinants",
        "question": "L is lower triangular and S is symmetric. Assume they are invertible:\n    \\[\n    L = \\begin{bmatrix} \n    a & 0 & 0 \\\\\n    b & c & 0 \\\\\n    d & e & f\n    \\end{bmatrix}, \\quad S = \\begin{bmatrix} \n    a & b & d \\\\\n    b & c & e \\\\\n    d & e & f\n    \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Which three cofactors of $L$ are zero? Then $L^{-1}$ is lower triangular."
    },
    {
        "chapter": "Determinants",
        "question": "Which three pairs of cofactors of $S$ are equal? Then $S^{-1}$ is symmetric."
    },
    {
        "chapter": "Determinants",
        "question": "For $n = 5$, the matrix $C$ contains cofactors, and each $4 \\times 4$ cofactor contains terms, and each term needs multiplications. Compare with $5^3 = 125$ for the Gauss-Jordan computation of $A^{-1}$."
    },
    {
        "chapter": "Determinants",
        "question": "Problems 27\u201336 are about area and volume by determinants:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Find the area of the parallelogram with edges $\\mathbf{v} = (3,2)$ and $\\mathbf{w} = (1,4)$."
    },
    {
        "chapter": "Determinants",
        "question": "Find the area of the triangle with sides $\\mathbf{v}$, $\\mathbf{w}$, and $\\mathbf{v} + \\mathbf{w}$. Draw it."
    },
    {
        "chapter": "Determinants",
        "question": "Find the area of the triangle with sides $\\mathbf{v}$, $\\mathbf{w}$, and $\\mathbf{w} - \\mathbf{v}$. Draw it."
    },
    {
        "chapter": "Determinants",
        "question": "A box has edges from $(0,0,0)$ to $(3,1,1)$, $(1,3,1)$, and $(1,1,3)$. Find its volume and also find the area of each parallelogram face."
    },
    {
        "chapter": "Determinants",
        "question": "The corners of a triangle are $(2,1)$, $(3,4)$, and $(0,5)$. What is the area?"
    },
    {
        "chapter": "Determinants",
        "question": "A new corner at $(-1,0)$ makes it lopsided (four sides). Find the area."
    },
    {
        "chapter": "Determinants",
        "question": "The parallelogram with sides $(2,1)$ and $(2,3)$ has the same area as the parallelogram with sides $(2,2)$ and $(1,3)$. Find those areas from $2 \\times 2$ determinants and say why they must be equal. (I can't see why from a picture. Please write to me if you do.)"
    },
    {
        "chapter": "Determinants",
        "question": "The Hadamard matrix $H$ has orthogonal rows. The box is a hypercube! What is\n    \\[\n    \\det(H) = \\left| \\begin{array}{cccc} \n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & -1 & -1 \\\\\n    1 & -1 & -1 & 1 \\\\\n    1 & -1 & 1 & -1\n    \\end{array} \\right|\n    \\]\n    (volume of a hypercube in $\\mathbb{R}^4$)?"
    },
    {
        "chapter": "Determinants",
        "question": "If the columns of a $4 \\times 4$ matrix have lengths $L_1$, $L_2$, $L_3$, $L_4$, what is the largest possible value for the determinant (based on volume)? If all entries are 1 or -1, what are those lengths and the maximum determinant?"
    },
    {
        "chapter": "Determinants",
        "question": "Show by a picture how a rectangle with area $x_1 y_2$ minus a rectangle with area $x_2 y_1$ produces the area $x_1 y_2 - x_2 y_1$ of a parallelogram."
    },
    {
        "chapter": "Determinants",
        "question": "When the edge vectors $\\mathbf{a}$, $\\mathbf{b}$, $\\mathbf{c}$ are perpendicular, the volume of the box is $|\\mathbf{a}| \\times |\\mathbf{b}| \\times |\\mathbf{c}|$. The matrix $A^T A$ is \\dots. Find $\\det(A^T A)$ and $\\det(A)$."
    },
    {
        "chapter": "Determinants",
        "question": "An $n$-dimensional cube has how many corners? How many edges? How many $(n-1)$-dimensional faces? The $n$-cube whose edges are the rows of $2I$ has volume \\dots. A hypercube computer has parallel processors at the corners with connections along the edges."
    },
    {
        "chapter": "Determinants",
        "question": "The triangle with corners $(0,0)$, $(1,0)$, $(0,1)$ has area $\\frac{1}{2}$. The pyramid with four corners $(0,0,0)$, $(1,0,0)$, $(0,1,0)$, $(0,0,1)$ has volume \\dots. The pyramid in $\\mathbb{R}^4$ with five corners at $(0,0,0,0)$ and the rows of $I$ has what volume?"
    },
    {
        "chapter": "Determinants",
        "question": "Problems 37\u201340 are about areas $dA$ and volumes $dV$ in calculus:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Polar coordinates satisfy $x = r \\cos \\theta$ and $y = r \\sin \\theta$. Polar area $J dr d\\theta$ includes $J$:\n        \\[\n        J = \\left| \\begin{matrix} \n        \\frac{\\partial x}{\\partial r} & \\frac{\\partial x}{\\partial \\theta} \\\\\n        \\frac{\\partial y}{\\partial r} & \\frac{\\partial y}{\\partial \\theta}\n        \\end{matrix} \\right|\n        = \\left| \\begin{matrix} \n        \\cos \\theta & -r \\sin \\theta \\\\\n        \\sin \\theta & r \\cos \\theta\n        \\end{matrix} \\right|\n        = r.\n        \\]\n        The two columns are orthogonal. Their lengths are \\dots. Thus $J = r$."
    },
    {
        "chapter": "Determinants",
        "question": "Spherical coordinates $\\rho$, $\\phi$, $\\theta$ give $x = \\rho \\sin \\phi \\cos \\theta$, $y = \\rho \\sin \\phi \\sin \\theta$, $z = \\rho \\cos \\phi$. Find the Jacobian matrix of 9 partial derivatives: $\\frac{\\partial x}{\\partial \\rho}$, $\\frac{\\partial x}{\\partial \\phi}$, $\\frac{\\partial x}{\\partial \\theta}$ are in row 1. Simplify its determinant to $J = \\rho^2 \\sin \\phi$. Then $dV = \\rho^2 \\sin \\phi \\, d\\rho \\, d\\phi \\, d\\theta$."
    },
    {
        "chapter": "Determinants",
        "question": "The matrix that connects $r$, $\\theta$ to $x$, $y$ is in Problem 37. Invert that matrix:\n        \\[\n        J^{-1} = \\left| \\begin{matrix}\n        \\frac{\\partial r}{\\partial x} & \\frac{\\partial r}{\\partial y} \\\\\n        \\frac{\\partial \\theta}{\\partial x} & \\frac{\\partial \\theta}{\\partial y}\n        \\end{matrix} \\right| = \\left| \\begin{matrix}\n        \\cos \\theta & ? \\\\\n        ? & ?\n        \\end{matrix} \\right| = ?\n        \\]\n        It is surprising that $\\frac{\\partial r}{\\partial x} = \\frac{\\partial x}{\\partial r}$. The product $JJ^{-1} = I$ gives the chain rule:\n        \\[\n        \\frac{\\partial x}{\\partial x} = \\frac{\\partial x}{\\partial r} \\frac{\\partial r}{\\partial x} + \\frac{\\partial x}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial x} = 1.\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "The triangle with corners $(0,0)$, $(6,0)$, and $(1,4)$ has area \\dots. When you rotate it by $\\theta = 60^\\circ$ the area is \\dots. The rotation matrix has determinant:\n        \\[\n        \\left| \\begin{matrix} \n        \\cos \\theta & -\\sin \\theta \\\\\n        \\sin \\theta & \\cos \\theta\n        \\end{matrix} \\right|\n        = \\left| \\begin{matrix} \n        \\frac{1}{2} & ? \\\\\n        ? & ?\n        \\end{matrix} \\right| = ?\n        \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let $P = (1,0,-1)$, $Q = (1,1,1)$, and $R = (2,2,1)$. Choose $S$ so that $PQRS$ is a parallelogram, and compute its area. Choose $T$, $U$, $V$ so that $OPQRSTUV$ is a tilted box, and compute its volume."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose $(x,y,z)$, $(1,1,0)$, and $(1,2,1)$ lie on a plane through the origin. What determinant is zero? What equation does this give for the plane?"
    },
    {
        "chapter": "Determinants",
        "question": "Suppose $(x,y,z)$ is a linear combination of $(2,3,1)$ and $(1,2,3)$. What determinant is zero? What equation does this give for the plane of all combinations?"
    },
    {
        "chapter": "Determinants",
        "question": "If $Ax = (1, 0, \\dots, 0)$, show how Cramer's Rule gives $x = \\text{first column of } A^{-1}$."
    },
    {
        "chapter": "Determinants",
        "question": "(VISA to AVIS) This takes an odd number of exchanges (IVSA, AVSI, AVIS). Count the pairs of letters in VISA and AVIS that are reversed from alphabetical order. The difference should be odd."
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinants of:\n    \\[\n    \\left[ \\begin{array}{cccc}\n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & 1 & 2 \\\\\n    1 & 1 & 3 & 1 \\\\\n    1 & 4 & 1 & 1 \\\\\n    \\end{array} \\right]\n    \\quad \\text{and} \\quad\n    \\left[ \\begin{array}{cccc}\n    2 & -1 & 0 & -1 \\\\\n    -1 & 2 & -1 & 0 \\\\\n    0 & -1 & 2 & -1 \\\\\n    -1 & 0 & -1 & 2 \\\\\n    \\end{array} \\right]\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "If $B = M^{-1} A M$, why is $\\det B = \\det A$? Show also that $\\det A^{-1} B = 1$."
    },
    {
        "chapter": "Determinants",
        "question": "Starting with $A$, multiply its first row by 3 to produce $B$, and subtract the first row of $B$ from the second to produce $C$. How is $\\det C$ related to $\\det A$?"
    },
    {
        "chapter": "Determinants",
        "question": "Solve $3u + 2v = 7$, $4u + 3v = 11$ by Cramer's rule."
    },
    {
        "chapter": "Determinants",
        "question": "If the entries of $A$ and $A^{-1}$ are all integers, how do you know that both determinants are 1 or -1? Hint: What is $\\det A$ times $\\det A^{-1}$?"
    },
    {
        "chapter": "Determinants",
        "question": "Find all the cofactors, and the inverse or the nullspace, of:\n    \\[\n    \\left[ \\begin{array}{cc}\n    3 & 5 \\\\\n    6 & 9 \\\\\n    \\end{array} \\right],\n    \\quad\n    \\left[ \\begin{array}{cc}\n    \\cos \\theta & -\\sin \\theta \\\\\n    \\sin \\theta & \\cos \\theta \\\\\n    \\end{array} \\right],\n    \\quad\n    \\left[ \\begin{array}{cc}\n    a & b \\\\\n    a & b \\\\\n    \\end{array} \\right].\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "What is the volume of the parallelepiped with four of its vertices at $(0, 0, 0)$, $(-1, 2, 2)$, $(2, -1, 2)$, and $(2, 2, -1)$? Where are the other four vertices?"
    },
    {
        "chapter": "Determinants",
        "question": "How many terms are in the expansion of a $5 \\times 5$ determinant, and how many are sure to be zero if $a_{21} = 0$?"
    },
    {
        "chapter": "Determinants",
        "question": "If $P_1$ is an even permutation matrix and $P_2$ is odd, deduce from $P_1 + P_2 = P_1 (P_1^T + P_2^T) P_2$ that $\\det(P_1 + P_2) = 0$."
    },
    {
        "chapter": "Determinants",
        "question": "If $\\det A > 0$, show that $A$ can be connected to $I$ by a continuous chain of matrices $A(t)$ all with positive determinants. (The straight path $A(t) = A + t(I - A)$ does go from $A(0) = A$ to $A(1) = I$, but in between $A(t)$ might be singular. The problem is not so easy, and solutions are welcomed by the author.)"
    },
    {
        "chapter": "Determinants",
        "question": "Explain why the point $(x,y)$ is on the line through $(2,8)$ and $(4,7)$ if\n    \\[\n    \\det \\left[ \\begin{array}{ccc}\n    x & y & 1 \\\\\n    2 & 8 & 1 \\\\\n    4 & 7 & 1 \\\\\n    \\end{array} \\right] = 0, \\quad \\text{or} \\quad x + 2y - 18 = 0.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "In analogy with the previous exercise, what is the equation for $(x,y,z)$ to be on the plane through $(2,0,0)$, $(0,2,0)$, and $(0,0,4)$? It involves a 4 by 4 determinant."
    },
    {
        "chapter": "Determinants",
        "question": "If the points $(x,y,z)$, $(2,1,0)$, and $(1,1,1)$ lie on a plane through the origin, what determinant is zero? Are the vectors $(1,0,-1)$, $(2,1,0)$, $(1,1,1)$ independent?"
    },
    {
        "chapter": "Determinants",
        "question": "If every row of $A$ has either a single $+1$, or a single $-1$, or one of each (and is otherwise zero), show that $\\det A = 1$ or $-1$ or $0$."
    },
    {
        "chapter": "Determinants",
        "question": "If $C = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ and $D = \\begin{bmatrix} u & v \\\\ w & z \\end{bmatrix}$, then $CD = -DC$ yields 4 equations $Ax = 0$:\n    \\[\n    CD + DC = 0 \\quad \\Rightarrow \\quad\n    \\left[ \\begin{array}{cccc}\n    2a & c & b & 0 \\\\\n    b & a+d & 0 & b \\\\\n    c & 0 & a+d & c \\\\\n    0 & c & b & 2d \\\\\n    \\end{array} \\right]\n    \\left[ \\begin{array}{c}\n    u \\\\\n    v \\\\\n    w \\\\\n    z \\\\\n    \\end{array} \\right]\n    = \n    \\left[ \\begin{array}{c}\n    0 \\\\\n    0 \\\\\n    0 \\\\\n    0 \\\\\n    \\end{array} \\right].\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Determinants",
        "question": "Show that $\\det A = 0$ if $a+d = 0$. Solve for $u$, $v$, $w$, $z$, the entries of $D$."
    },
    {
        "chapter": "Determinants",
        "question": "Show that $\\det A = 0$ if $ad = bc$ (so $C$ is singular)."
    },
    {
        "chapter": "Determinants",
        "question": "In all other cases, $CD = -DC$ is only possible with $D = \\text{zero matrix}$."
    },
    {
        "chapter": "Determinants",
        "question": "The circular shift permutes $(1, 2, \\dots, n)$ into $(2, 3, \\dots, 1)$. What is the corresponding permutation matrix $P$, and (depending on $n$) what is its determinant?"
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinant of $A = \\text{eye}(5) + \\text{ones}(5)$ and, if possible, $\\text{eye}(n) + \\text{ones}(n)$."
    },
    {
        "chapter": "Determinants",
        "question": "Prove that if \\( A \\) is an \\( n \\times n \\) matrix and \\( B \\) is a matrix obtained from \\( A \\) by swapping two rows, then \\( \\det(B) = -\\det(A) \\). Additionally, explain how this property extends to higher dimensions, and deduce the implications for the determinant of a matrix when two rows are identical. Use this result to prove that the determinant of a singular matrix is zero."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a square matrix. Prove that \\( \\det(A^T) = \\det(A) \\). Further, provide a geometric interpretation of this property in terms of volumes of parallelepipeds in Euclidean space. Investigate the relationship between the determinant of a matrix and the determinant of its inverse, and deduce a formula for the determinant of the inverse matrix when \\( \\det(A) \\neq 0 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A \\in \\mathbb{R}^{n \\times n} \\) and suppose that its eigenvalues are \\( \\lambda_1, \\lambda_2, \\dots, \\lambda_n \\). Prove that the determinant of \\( A \\) is equal to the product of its eigenvalues, i.e., \\( \\det(A) = \\prod_{i=1}^{n} \\lambda_i \\). Use this result to analyze the effect of matrix diagonalization on the determinant, and explain how this formula applies when \\( A \\) is a diagonalizable matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Prove that for any square matrix \\( A \\), the determinant satisfies the multilinearity property, i.e., for vectors \\( \\mathbf{v}_1, \\dots, \\mathbf{v}_n \\in \\mathbb{R}^n \\), the determinant is linear in each row of the matrix. Specifically, show that if one row of a matrix is a linear combination of two other rows, then the determinant of the matrix is zero. Discuss the implications of this property for solving systems of linear equations."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a square matrix, and consider the following statement: \u201cIf \\( A \\) is a triangular matrix (either upper or lower), then \\( \\det(A) \\) is the product of the diagonal elements.\u201d Prove this statement by induction on \\( n \\), the size of the matrix. Extend the result to block triangular matrices, and provide a geometric interpretation of the determinant in the context of scaling and shearing transformations in Euclidean space."
    },
    {
        "chapter": "Determinants",
        "question": "Prove the following generalization of the cofactor expansion formula for the determinant: for any \\( n \\times n \\) matrix \\( A \\), the determinant can be expanded along any row or column as follows:\n    \\[\n    \\det(A) = \\sum_{i=1}^{n} (-1)^{i+j} a_{ij} \\det(A_{ij})\n    \\]\n    where \\( A_{ij} \\) is the matrix obtained by removing the \\( i \\)-th row and \\( j \\)-th column from \\( A \\). Demonstrate how this formula can be applied to calculate the determinant of a 4x4 matrix, and explore the computational complexity of this method for larger matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) and \\( B \\) be \\( n \\times n \\) matrices. Prove that \\( \\det(AB) = \\det(A) \\det(B) \\). Additionally, investigate whether this property holds for matrices of different dimensions and provide an example of a situation where the product of two non-square matrices is not defined. Discuss the implications of this result in the context of matrix factorization methods such as LU and QR decomposition."
    },
    {
        "chapter": "Determinants",
        "question": "Consider a square matrix \\( A \\in \\mathbb{R}^{n \\times n} \\) and a scalar \\( \\lambda \\). Prove that \\( \\det(\\lambda A) = \\lambda^n \\det(A) \\). Use this result to deduce the behavior of the determinant under scalar multiplication, and explain how it can be used to determine the volume scaling factor when applying a linear transformation represented by \\( A \\) to a geometric object in \\( \\mathbb{R}^n \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a square matrix, and suppose that \\( A \\) is symmetric. Prove that the eigenvalues of \\( A \\) are real, and that \\( A \\) is diagonalizable. Use this result to show that the determinant of a symmetric matrix is always the product of its eigenvalues, and discuss how this property is useful in analyzing the stability of dynamical systems modeled by symmetric matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a square matrix, and let \\( B \\) be the matrix obtained by adding a scalar multiple of one row of \\( A \\) to another row. Prove that \\( \\det(B) = \\det(A) \\). Discuss the implications of this result for row reduction in Gaussian elimination, and explain how it helps in proving the invertibility criterion for matrices (i.e., that a matrix is invertible if and only if its determinant is non-zero)."
    },
    {
        "chapter": "Determinants",
        "question": "Given an \\( n \\times n \\) matrix \\( A \\), prove that the determinant is invariant under row swapping, i.e., if two rows of a matrix are swapped, the determinant changes its sign. Provide a detailed proof and explain how this property follows from the cofactor expansion formula. Furthermore, demonstrate how this property can be used in conjunction with Gaussian elimination to determine the determinant of a matrix by transforming it into an upper triangular form."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be an \\( n \\times n \\) matrix, and let \\( R_1 \\), \\( R_2 \\), and \\( R_3 \\) represent rows of \\( A \\). Suppose that we perform a row operation that adds a scalar multiple of \\( R_1 \\) to \\( R_2 \\) (i.e., \\( R_2 \\leftarrow R_2 + \\alpha R_1 \\)) and adds a scalar multiple of \\( R_3 \\) to \\( R_1 \\) (i.e., \\( R_1 \\leftarrow R_1 + \\beta R_3 \\)). Prove that the determinant of the matrix after these operations is equal to the determinant of the original matrix, i.e., \\( \\det(A') = \\det(A) \\), and discuss the geometric interpretation of this result in the context of volume scaling. Extend this result to a sequence of multiple such row operations."
    },
    {
        "chapter": "Determinants",
        "question": "Prove that if a matrix \\( A \\) is transformed into row echelon form (REF) by a sequence of elementary row operations, then the determinant of the matrix is the product of the diagonal entries of the resulting upper triangular matrix, up to a sign correction determined by the number of row swaps. Specifically, show that if \\( A \\) is transformed to an upper triangular matrix \\( U \\) by a sequence of row operations that involve a certain number of row swaps, the determinant of \\( A \\) is given by\n    \\[\n    \\det(A) = (-1)^s \\prod_{i=1}^{n} u_{ii}\n    \\]\n    where \\( s \\) is the number of row swaps, and \\( u_{ii} \\) are the diagonal entries of \\( U \\). Use this result to compute the determinant of a given matrix by row reduction."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be an \\( n \\times n \\) matrix, and let \\( \\{E_1, E_2, \\dots, E_k\\} \\) be a sequence of elementary row operations that transform \\( A \\) into an upper triangular matrix. Prove that the determinant of \\( A \\) is the product of the determinants of the elementary matrices corresponding to the row operations. Specifically, show that\n    \\[\n    \\det(A) = \\prod_{i=1}^{k} \\det(E_i) \\cdot \\det(\\text{upper triangular matrix after row operations})\n    \\]\n    and discuss the properties of elementary matrices, including their effect on the determinant (i.e., \\( \\det(E) = 1 \\) for a row swap, \\( \\det(E) = \\alpha \\) for scaling a row by a scalar \\( \\alpha \\), and \\( \\det(E) = 1 \\) for adding a multiple of one row to another)."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A \\in \\mathbb{R}^{n \\times n} \\), and suppose that \\( A \\) is transformed into its row echelon form by a sequence of elementary row operations. Let \\( L \\) be the lower triangular matrix representing the matrix of multipliers used during Gaussian elimination. Prove that \\( \\det(A) = \\det(L) \\cdot \\det(U) \\), where \\( U \\) is the upper triangular matrix obtained after row reduction, and discuss how row operations affect the determinant of a matrix. Specifically, prove that the determinant of \\( L \\) is 1, and use this result to compute the determinant of \\( A \\) using only the upper triangular matrix \\( U \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \n    \\[\n    A = \\begin{pmatrix} 2 & 3 & 1 \\\\ 4 & 7 & 2 \\\\ 6 & 10 & 3 \\end{pmatrix},\n    \\]\n    apply Gaussian elimination to find its determinant. Provide a detailed step-by-step solution, including all row operations performed to reduce the matrix to row echelon form, and show how the determinant is calculated by the product of the diagonal entries, adjusted for row swaps. Discuss the computational efficiency of this method for larger matrices and how it relates to the concept of matrix rank."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} 1 & 3 & 2 & 4 \\\\ 2 & 7 & 3 & 8 \\\\ 3 & 12 & 4 & 13 \\\\ 4 & 16 & 5 & 17 \\end{pmatrix}.\n    \\]\n    Using Gaussian elimination, reduce \\( A \\) to upper triangular form and calculate its determinant. Include all the intermediate steps in your solution and explain the effect of each row operation on the matrix. Afterward, investigate the geometric meaning of the determinant of a 4x4 matrix in terms of volume and its relationship with linear transformations."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\in \\mathbb{R}^{5 \\times 5} \\) be a matrix with entries \n    \\[\n    A = \\begin{pmatrix} \n    1 & 2 & 3 & 4 & 5 \\\\ \n    6 & 7 & 8 & 9 & 10 \\\\ \n    11 & 12 & 13 & 14 & 15 \\\\ \n    16 & 17 & 18 & 19 & 20 \\\\ \n    21 & 22 & 23 & 24 & 25\n    \\end{pmatrix}.\n    \\]\n    Perform Gaussian elimination on \\( A \\) to reduce it to row echelon form and compute the determinant of \\( A \\). Discuss how the determinant changes after each row operation and the computational challenges faced when dealing with larger matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 3 & 4 & 5 \\\\ 2 & 5 & 7 \\\\ 6 & 2 & 3 \\end{pmatrix} \\). Use row operations to reduce \\( A \\) to upper triangular form and compute its determinant. Show all steps of your solution and analyze the impact of elementary row operations on the matrix. In addition, prove that Gaussian elimination is equivalent to performing a sequence of elementary row operations on a matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the following matrix \\( A \\):\n    \\[\n    A = \\begin{pmatrix} \n    1 & 2 & 1 & 3 \\\\ \n    0 & 1 & 4 & 5 \\\\ \n    2 & 3 & 5 & 6 \\\\ \n    1 & 2 & 2 & 4\n    \\end{pmatrix}.\n    \\]\n    Using Gaussian elimination, reduce \\( A \\) to row echelon form, and then compute its determinant. Explain the significance of each row operation performed, and discuss how the result can be interpreted geometrically. Afterward, compare the determinant of this matrix with that of a similar matrix with a small perturbation in the entries."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \n    \\[\n    A = \\begin{pmatrix} 2 & 4 & 1 & 3 \\\\ 1 & 3 & 5 & 7 \\\\ 3 & 6 & 4 & 8 \\\\ 2 & 5 & 6 & 9 \\end{pmatrix},\n    \\]\n    apply Gaussian elimination to reduce \\( A \\) to row echelon form, and calculate the determinant. Discuss the mathematical principles behind row operations that preserve the determinant and those that change its value. Analyze how Gaussian elimination reveals important properties of the matrix, such as its rank and invertibility."
    },
    {
        "chapter": "Determinants",
        "question": "Let \n    \\[\n    A = \\begin{pmatrix} 1 & 0 & 2 \\\\ 3 & 1 & 4 \\\\ 5 & 2 & 6 \\end{pmatrix}.\n    \\]\n    Perform Gaussian elimination on \\( A \\) and calculate its determinant. Provide a detailed solution, including every row operation performed, and discuss how the determinant is affected by the operations. Extend this method to a general \\( 3 \\times 3 \\) matrix and derive a general formula for the determinant using Gaussian elimination."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} 2 & 1 & 3 & 4 \\\\ 5 & 2 & 1 & 3 \\\\ 7 & 3 & 2 & 4 \\\\ 1 & 5 & 6 & 7 \\end{pmatrix}.\n    \\]\n    Use Gaussian elimination to reduce this matrix to row echelon form, and then compute its determinant. Afterward, investigate the effect of performing Gaussian elimination with partial pivoting on the accuracy and stability of the determinant computation."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a matrix in \\( \\mathbb{R}^{3 \\times 3} \\), and suppose that it is in row echelon form:\n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 4 & 5 \\\\ 0 & 0 & 6 \\end{pmatrix}.\n    \\]\n    Compute its determinant directly from the row echelon form and explain why this method is more efficient than using cofactor expansion. Discuss how row echelon form simplifies the determinant computation and why it is crucial for matrix inversion algorithms."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 4 \\\\ 0 & 0 & 1 \\end{pmatrix}.\n    \\]\n    Perform Gaussian elimination on \\( A \\) and find its determinant. Discuss the implications of row echelon form for systems of linear equations and how Gaussian elimination can be used to solve such systems while computing the determinant. Additionally, demonstrate how Gaussian elimination can be used to compute the determinant of a singular matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a diagonal matrix with entries \\( a_1, a_2, \\dots, a_n \\) on the diagonal. Prove that the determinant of \\( A \\) is the product of the diagonal entries, i.e., \n    \\[\n    \\det(A) = \\prod_{i=1}^{n} a_i.\n    \\]\n    Subsequently, consider a diagonal matrix \\( D = \\text{diag}(2, 3, 5) \\) and compute its determinant. Further, demonstrate that if the matrix \\( A \\) is scaled by a scalar \\( \\alpha \\), then the determinant of \\( \\alpha A \\) is given by \\( \\alpha^n \\det(A) \\), where \\( n \\) is the size of the matrix. Apply this property to an arbitrary \\( 3 \\times 3 \\) diagonal matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a symmetric matrix, and suppose that \\( A \\) is diagonalizable, i.e., \\( A = P \\Lambda P^T \\), where \\( P \\) is an orthogonal matrix and \\( \\Lambda \\) is a diagonal matrix of eigenvalues. Show that the determinant of \\( A \\) is the product of its eigenvalues, i.e., \n    \\[\n    \\det(A) = \\prod_{i=1}^{n} \\lambda_i.\n    \\]\n    Compute the determinant of a symmetric matrix \\( A = \\begin{pmatrix} 4 & 2 \\\\ 2 & 3 \\end{pmatrix} \\) by finding its eigenvalues and use the above property to verify the result. Discuss the geometric interpretation of this property in terms of the scaling effect of linear transformations represented by symmetric matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Prove that the determinant of a triangular matrix, whether upper or lower triangular, is the product of the diagonal entries. Consider the matrix \n    \\[\n    A = \\begin{pmatrix} \n    3 & 5 & 1 \\\\ \n    0 & 2 & 4 \\\\ \n    0 & 0 & 6\n    \\end{pmatrix}.\n    \\]\n    Compute its determinant by applying the formula for triangular matrices and discuss how this property simplifies the computation of determinants. Furthermore, explain why triangular matrices are crucial in solving systems of linear equations and in LU decomposition."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a block matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    B & C \\\\ \n    D & E\n    \\end{pmatrix},\n    \\]\n    where \\( B \\), \\( C \\), \\( D \\), and \\( E \\) are square matrices. Suppose that \\( B \\) and \\( E \\) are invertible. Prove that the determinant of \\( A \\) is given by \n    \\[\n    \\det(A) = \\det(B) \\det(E - D B^{-1} C).\n    \\]\n    As an example, calculate the determinant of the following block matrix, \n    \\[\n    A = \\begin{pmatrix} \n    2 & 0 & 1 \\\\ \n    0 & 3 & 4 \\\\ \n    0 & 0 & 5\n    \\end{pmatrix}.\n    \\]\n    Provide a detailed step-by-step solution and interpret the result in the context of matrix factorization techniques."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 0 & 0 \\\\ \n    0 & 1 & 0 \\\\ \n    0 & 0 & 0\n    \\end{pmatrix}.\n    \\]\n    Discuss the properties of singular matrices and show that the determinant of \\( A \\) is zero. Further, prove that if a matrix has a row or column of zeros, its determinant is zero. Explain how this property relates to the concept of the rank of a matrix and provide an example of a matrix with full rank where this property does not hold."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a circulant matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    a_0 & a_1 & \\cdots & a_{n-1} \\\\ \n    a_{n-1} & a_0 & \\cdots & a_{n-2} \\\\ \n    \\vdots & \\vdots & \\ddots & \\vdots \\\\ \n    a_1 & a_2 & \\cdots & a_0\n    \\end{pmatrix}.\n    \\]\n    Prove that the determinant of a circulant matrix is the product of the eigenvalues, which can be computed using the discrete Fourier transform (DFT) of the first row of the matrix. Apply this result to compute the determinant of the circulant matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 2 & 3 \\\\ \n    3 & 1 & 2 \\\\ \n    2 & 3 & 1 \n    \\end{pmatrix}.\n    \\]\n    Discuss how this result extends to higher-dimensional circulant matrices and its connection to the concept of circulant graphs."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a \\( 2 \\times 2 \\) matrix given by \n    \\[\n    A = \\begin{pmatrix} \n    a & b \\\\ \n    c & d\n    \\end{pmatrix}.\n    \\]\n    Show that the determinant of \\( A \\) is given by \n    \\[\n    \\det(A) = ad - bc.\n    \\]\n    Additionally, prove that the determinant of the inverse of \\( A \\), if it exists, is given by \n    \\[\n    \\det(A^{-1}) = \\frac{1}{\\det(A)}.\n    \\]\n    Using this result, calculate the determinant of the inverse of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    3 & 2 \\\\ \n    5 & 7\n    \\end{pmatrix}.\n    \\]\n    Discuss how this property extends to larger square matrices and its implications in matrix inversion techniques."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be an orthogonal matrix, i.e., \\( A^T A = I \\). Prove that the determinant of an orthogonal matrix is either \\( 1 \\) or \\( -1 \\), and provide a detailed explanation of why this property holds. As an example, compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    0 & 1 \\\\ \n    -1 & 0\n    \\end{pmatrix}.\n    \\]\n    Discuss the significance of this result in the context of rotations in Euclidean space and the preservation of volume by orthogonal transformations."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    0 & 0 & 1 \\\\ \n    1 & 0 & 0 \\\\ \n    0 & 1 & 0\n    \\end{pmatrix}.\n    \\]\n    Compute the determinant of \\( A \\) and explain how this matrix relates to the concept of a permutation matrix. Show that the determinant of a permutation matrix is \\( 1 \\) if the number of row swaps is even, and \\( -1 \\) if the number of row swaps is odd. Apply this result to compute the determinant of the permutation matrix corresponding to the 3-cycle \\( (1 \\ 2 \\ 3) \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be an upper Hessenberg matrix, i.e., a matrix where all entries below the first subdiagonal are zero. Prove that the determinant of an upper Hessenberg matrix can be computed by a recursive formula involving the diagonal and subdiagonal entries. Compute the determinant of the following \\( 4 \\times 4 \\) upper Hessenberg matrix:\n    \\[\n    A = \\begin{pmatrix} \n    1 & 2 & 3 & 4 \\\\ \n    5 & 6 & 7 & 8 \\\\ \n    0 & 10 & 11 & 12 \\\\ \n    0 & 0 & 14 & 15\n    \\end{pmatrix}.\n    \\]\n    Discuss the role of Hessenberg matrices in numerical methods, particularly in eigenvalue algorithms and LU decomposition."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} \n    1 & 2 & 3 \\\\ \n    0 & 1 & 4 \\\\ \n    5 & 6 & 0\n    \\end{pmatrix} \\). Compute the determinant of \\( A \\) using cofactor expansion along the first row. Subsequently, use the formula for minors and cofactors to compute the determinant and verify the result through row reduction. Explain how these methods relate to the underlying properties of matrix determinants."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} \n    4 & 2 & 1 \\\\ \n    3 & 1 & 2 \\\\ \n    1 & 3 & 4\n    \\end{pmatrix} \\), compute the determinant of \\( A \\) by applying the cofactor expansion method along the second row. Then, using this result, compute the minor and cofactor for the entry in the second row, first column. Discuss the geometric interpretation of the determinant in terms of the volume of a parallelepiped."
    },
    {
        "chapter": "Determinants",
        "question": "Prove the cofactor expansion formula for the determinant of an \\( n \\times n \\) matrix. Specifically, for a given \\( n \\times n \\) matrix \\( A \\), show that \n    \\[\n    \\det(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\det(A_{ij}),\n    \\]\n    where \\( A_{ij} \\) is the matrix obtained by deleting the \\( i \\)-th row and \\( j \\)-th column of \\( A \\). Apply this formula to compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 0 & 2 \\\\ \n    3 & 4 & 1 \\\\ \n    5 & 6 & 0\n    \\end{pmatrix}.\n    \\]\n    Illustrate the importance of this expansion in computing the determinant of large matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a \\( 4 \\times 4 \\) matrix given by \n    \\[\n    A = \\begin{pmatrix} \n    1 & 2 & 3 & 4 \\\\ \n    5 & 6 & 7 & 8 \\\\ \n    9 & 10 & 11 & 12 \\\\ \n    13 & 14 & 15 & 16\n    \\end{pmatrix}.\n    \\]\n    Compute the determinant of \\( A \\) using the cofactor expansion along the first row and confirm the result by applying row reduction. Discuss the computational advantages and limitations of each method in the context of this matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Using the formula for minors and cofactors, compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    3 & 1 & 4 & 1 \\\\ \n    5 & 9 & 2 & 6 \\\\ \n    5 & 3 & 5 & 7 \\\\ \n    2 & 8 & 5 & 3\n    \\end{pmatrix}.\n    \\]\n    Then, verify the result by reducing the matrix to upper triangular form and computing the determinant from the product of diagonal entries. Discuss how these two methods provide insights into the structure of the matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Prove the formula for the determinant of a product of two matrices, i.e., \n    \\[\n    \\det(AB) = \\det(A) \\det(B),\n    \\]\n    where \\( A \\) and \\( B \\) are square matrices of the same size. Use this property to compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 0 \\\\ \n    2 & 3\n    \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} \n    4 & 5 \\\\ \n    6 & 7\n    \\end{pmatrix}.\n    \\]\n    Discuss how this result is used in the context of LU decomposition and matrix factorizations."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be an upper triangular matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    2 & 4 & 3 \\\\ \n    0 & 5 & 1 \\\\ \n    0 & 0 & 6\n    \\end{pmatrix}.\n    \\]\n    Compute the determinant of \\( A \\) and compare this result with that obtained from cofactor expansion. Explain why the determinant of a triangular matrix is simply the product of its diagonal entries, and discuss the implications for matrix inversion and linear systems."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} \n    1 & 1 & 1 \\\\ \n    2 & 4 & 8 \\\\ \n    3 & 9 & 27\n    \\end{pmatrix} \\), compute its determinant by applying row operations to transform the matrix into upper triangular form. Discuss how the choice of row operations affects the computation and how the determinant is affected by elementary row operations."
    },
    {
        "chapter": "Determinants",
        "question": "Use the method of LU decomposition to compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    4 & 3 & 2 \\\\ \n    2 & 1 & 3 \\\\ \n    3 & 2 & 1\n    \\end{pmatrix}.\n    \\]\n    Compute the LU factorization and use the property \\( \\det(A) = \\det(L) \\det(U) \\) to find the determinant. Compare the result with the cofactor expansion method and discuss the computational efficiency of LU decomposition for larger matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    2 & 4 & 1 \\\\ \n    0 & 3 & 5 \\\\ \n    6 & 7 & 8\n    \\end{pmatrix}.\n    \\]\n    Using the cofactor expansion method, compute the determinant of \\( A \\). Then, use row operations to simplify \\( A \\) and verify your result. Discuss how row operations simplify the calculation and the role of the determinant in understanding the invertibility of the matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Show that the determinant of a matrix is a multilinear function of its rows (or columns). Specifically, prove that if a matrix is formed by linear combinations of rows (or columns), the determinant is linear in each row (or column). Use this property to compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    x_1 & x_2 \\\\ \n    y_1 & y_2\n    \\end{pmatrix}.\n    \\]\n    Discuss the significance of this property in the context of solving linear systems and analyzing matrix transformations."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 3 & 2 \\\\ \n    4 & 2 & 1 \\\\ \n    5 & 6 & 3\n    \\end{pmatrix},\n    \\]\n    compute the determinant of \\( A \\) using cofactor expansion. Next, use the LU decomposition method to compute the determinant of the same matrix and compare the results. Discuss the efficiency of each method in solving real-world problems such as numerical optimization."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a \\( 3 \\times 3 \\) matrix with entries \\( a_{ij} \\), and suppose that the matrix is invertible. Prove that if a matrix is invertible, then its determinant is nonzero. Furthermore, show that the inverse of a matrix can be computed using the adjugate matrix, where \n    \\[\n    A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A).\n    \\]\n    Compute the inverse of the matrix \\( A = \\begin{pmatrix} \n    2 & 1 & 3 \\\\ \n    1 & 2 & 1 \\\\ \n    3 & 1 & 2\n    \\end{pmatrix} \\) and verify the result by multiplying \\( A \\) and \\( A^{-1} \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Using the formula for minors and cofactors, compute the determinant of the following matrix:\n    \\[\n    A = \\begin{pmatrix} \n    7 & 4 & 2 \\\\ \n    5 & 3 & 1 \\\\ \n    9 & 6 & 3\n    \\end{pmatrix}.\n    \\]\n    Additionally, show how the determinant can be used to verify the linear independence of the rows or columns of a matrix. Discuss how this property can be useful in applications such as determining the rank of a matrix and solving systems of linear equations."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a \\( 4 \\times 4 \\) block matrix defined as\n    \\[\n    A = \\begin{pmatrix}\n    A_{11} & A_{12} \\\\\n    A_{21} & A_{22}\n    \\end{pmatrix},\n    \\]\n    where \\( A_{11} \\), \\( A_{12} \\), \\( A_{21} \\), and \\( A_{22} \\) are \\( 2 \\times 2 \\) matrices. Using the block determinant formula, express the determinant of \\( A \\) in terms of the determinants of the blocks. Assume that \\( A_{11} \\) and \\( A_{22} \\) are invertible. Prove that the determinant of \\( A \\) is given by \n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Apply this formula to compute the determinant of the block matrix\n    \\[\n    A = \\begin{pmatrix}\n    2 & 1 & 0 & 0 \\\\\n    1 & 2 & 0 & 0 \\\\\n    0 & 0 & 3 & 4 \\\\\n    0 & 0 & 4 & 3\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a block matrix of the form\n    \\[\n    A = \\begin{pmatrix}\n    A_{11} & A_{12} \\\\\n    A_{21} & A_{22}\n    \\end{pmatrix},\n    \\]\n    where \\( A_{11} \\) and \\( A_{22} \\) are square matrices of size \\( n \\times n \\). If \\( A_{12} = A_{21}^T \\), prove that the determinant of \\( A \\) can be expressed as\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Using this result, compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    3 & 2 & 1 & 0 \\\\\n    2 & 3 & 0 & 1 \\\\\n    1 & 0 & 4 & 3 \\\\\n    0 & 1 & 3 & 4\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} \n    A_{11} & A_{12} \\\\ \n    A_{21} & A_{22} \n    \\end{pmatrix} \\) be a block matrix where \\( A_{11} \\), \\( A_{12} \\), \\( A_{21} \\), and \\( A_{22} \\) are square matrices of order \\( n \\). Show that if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is given by\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Prove this result and apply it to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix} \n    4 & 2 & 1 & 0 \\\\ \n    1 & 3 & 2 & 0 \\\\ \n    0 & 1 & 5 & 4 \\\\ \n    0 & 0 & 3 & 6 \n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Consider the block matrix\n    \\[\n    A = \\begin{pmatrix} \n    1 & 0 & 0 \\\\ \n    0 & A_{22} & A_{23} \\\\ \n    0 & A_{32} & A_{33} \n    \\end{pmatrix},\n    \\]\n    where \\( A_{22} \\), \\( A_{23} \\), \\( A_{32} \\), and \\( A_{33} \\) are square matrices of size \\( n \\times n \\). Show that the determinant of \\( A \\) can be computed as the product\n    \\[\n    \\det(A) = \\det(A_{22}) \\det(A_{33} - A_{32} A_{22}^{-1} A_{23}).\n    \\]\n    Apply this result to compute the determinant of the block matrix\n    \\[\n    A = \\begin{pmatrix}\n    1 & 0 & 0 \\\\\n    0 & 2 & 1 \\\\\n    0 & 1 & 3\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a block matrix of the form\n    \\[\n    A = \\begin{pmatrix}\n    A_{11} & A_{12} \\\\\n    A_{21} & A_{22}\n    \\end{pmatrix},\n    \\]\n    where \\( A_{11} \\) and \\( A_{22} \\) are square matrices of order \\( n \\). If \\( A_{21} = A_{12}^T \\), show that the determinant of \\( A \\) satisfies the relation\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Use this formula to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    1 & 2 & 0 & 0 \\\\\n    2 & 1 & 0 & 0 \\\\\n    0 & 0 & 3 & 1 \\\\\n    0 & 0 & 1 & 3\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Consider a block matrix \\( A \\) given by\n    \\[\n    A = \\begin{pmatrix}\n    A_{11} & A_{12} \\\\\n    A_{21} & A_{22}\n    \\end{pmatrix}.\n    \\]\n    If \\( A_{11} \\) is invertible, prove that\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    3 & 1 & 0 & 0 \\\\\n    1 & 2 & 0 & 0 \\\\\n    0 & 0 & 5 & 6 \\\\\n    0 & 0 & 6 & 5\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix}\n    A_{11} & A_{12} \\\\\n    A_{21} & A_{22}\n    \\end{pmatrix} \\) be a block matrix. Show that if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Apply this result to compute the determinant of the block matrix\n    \\[\n    A = \\begin{pmatrix}\n    2 & 1 & 0 & 0 \\\\\n    1 & 3 & 0 & 0 \\\\\n    0 & 0 & 4 & 2 \\\\\n    0 & 0 & 2 & 4\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Show that for a block matrix \\( A = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\), if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Use this formula to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    5 & 3 & 1 & 0 \\\\\n    3 & 5 & 0 & 1 \\\\\n    1 & 0 & 6 & 2 \\\\\n    0 & 1 & 2 & 6\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Given a block matrix \\( A = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\), where \\( A_{11} \\) and \\( A_{22} \\) are square matrices, and assuming that \\( A_{11} \\) is invertible, show that the determinant of \\( A \\) can be written as\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    7 & 4 & 1 & 0 \\\\\n    4 & 7 & 0 & 1 \\\\\n    1 & 0 & 8 & 3 \\\\\n    0 & 1 & 3 & 8\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\) be a block matrix where \\( A_{11} \\) and \\( A_{22} \\) are square matrices. Prove that if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Apply this formula to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    8 & 2 & 1 & 0 \\\\\n    2 & 8 & 0 & 1 \\\\\n    1 & 0 & 9 & 4 \\\\\n    0 & 1 & 4 & 9\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a block matrix of the form\n    \\[\n    A = \\begin{pmatrix} \n    A_{11} & A_{12} \\\\ \n    A_{21} & A_{22} \n    \\end{pmatrix}.\n    \\]\n    If \\( A_{11} \\) is invertible, show that\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Use this to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    6 & 2 & 1 & 0 \\\\\n    2 & 6 & 0 & 1 \\\\\n    1 & 0 & 7 & 3 \\\\\n    0 & 1 & 3 & 7\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Determinants",
        "question": "Consider the following system of linear equations:\n    \\[\n    \\begin{aligned}\n    3x + 4y - 2z &= 1, \\\\\n    2x - y + 3z &= 4, \\\\\n    5x - 2y + z &= 3.\n    \\end{aligned}\n    \\]\n    Solve this system using Cramer's Rule. First, compute the determinants of the coefficient matrix and the matrices formed by replacing each column of the coefficient matrix with the constant vector. Verify the solution by substituting the values back into the original system."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the system of linear equations:\n    \\[\n    \\begin{aligned}\n    x + 2y + 3z &= 9, \\\\\n    2x + 3y + 4z &= 10, \\\\\n    3x + 4y + 5z &= 11.\n    \\end{aligned}\n    \\]\n    Use Cramer's Rule to find the values of \\(x\\), \\(y\\), and \\(z\\). Compute each of the relevant determinants and interpret the results geometrically."
    },
    {
        "chapter": "Determinants",
        "question": "Given the system of equations\n    \\[\n    \\begin{aligned}\n    x + y - 2z &= 1, \\\\\n    2x - y + 3z &= 4, \\\\\n    3x + 2y + z &= 5,\n    \\end{aligned}\n    \\]\n    apply Cramer's Rule to find the values of \\(x\\), \\(y\\), and \\(z\\). Discuss the relationship between the determinant of the coefficient matrix and the existence of a unique solution."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the following system of equations using Cramer's Rule:\n    \\[\n    \\begin{aligned}\n    2x - y + 4z &= 3, \\\\\n    x + 3y - 2z &= 7, \\\\\n    4x - 2y + 3z &= 5.\n    \\end{aligned}\n    \\]\n    Calculate the determinants of the matrix of coefficients and the matrices obtained by replacing each column with the right-hand side vector. Verify that the solution satisfies the original system."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the system of equations\n    \\[\n    \\begin{aligned}\n    4x + 3y - 2z &= 5, \\\\\n    2x + y + z &= 3, \\\\\n    x - y + 2z &= 1,\n    \\end{aligned}\n    \\]\n    using Cramer's Rule. Explicitly compute the determinants of the coefficient matrix and the matrices obtained by replacing columns with the constant vector."
    },
    {
        "chapter": "Determinants",
        "question": "Given the system of linear equations\n    \\[\n    \\begin{aligned}\n    3x + y + 2z &= 7, \\\\\n    x - 2y + z &= 1, \\\\\n    4x + 3y - z &= 2,\n    \\end{aligned}\n    \\]\n    solve for \\(x\\), \\(y\\), and \\(z\\) using Cramer's Rule. Compute the required determinants, and explain how Cramer's Rule applies in this context."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the following system of linear equations using Cramer's Rule:\n    \\[\n    \\begin{aligned}\n    2x - 3y + 4z &= 5, \\\\\n    x + 2y - z &= 4, \\\\\n    3x - y + 2z &= 6.\n    \\end{aligned}\n    \\]\n    Discuss the geometric interpretation of the solution and compute the determinants for each variable."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the system of equations\n    \\[\n    \\begin{aligned}\n    5x + 2y + 3z &= 12, \\\\\n    x + 4y - z &= 2, \\\\\n    3x - y + 2z &= 5.\n    \\end{aligned}\n    \\]\n    Solve this system using Cramer's Rule. Calculate each determinant step-by-step, and determine if the system has a unique solution, infinitely many solutions, or no solution."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the system of equations\n    \\[\n    \\begin{aligned}\n    4x + 5y - z &= 8, \\\\\n    2x - 3y + 3z &= 5, \\\\\n    x + 2y + 4z &= 7,\n    \\end{aligned}\n    \\]\n    using Cramer's Rule. Compute the determinants involved and check that the solution satisfies all the equations."
    },
    {
        "chapter": "Determinants",
        "question": "Solve the system of equations\n    \\[\n    \\begin{aligned}\n    2x + 3y + z &= 10, \\\\\n    x - y + 2z &= 5, \\\\\n    3x + y - z &= 4.\n    \\end{aligned}\n    \\]\n    Use Cramer's Rule to find the values of \\(x\\), \\(y\\), and \\(z\\). Discuss how the determinants of the modified matrices relate to the coefficients of the equations and the constants."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 2 & 1 & 3 \\\\ 4 & 2 & 6 \\\\ 7 & 5 & 8 \\end{pmatrix} \\), compute the cofactor matrix \\( C \\) of \\( A \\) and use it to find the inverse of \\( A \\). Show all steps involved in the computation of the minors, cofactors, and the adjugate matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 5 & 6 & 7 \\\\ 8 & 9 & 10 & 11 \\\\ 12 & 13 & 14 & 15 \\end{pmatrix} \\). Calculate the cofactor matrix of \\( A \\) and use it to find the inverse of \\( A \\). Discuss the implications of the determinant of \\( A \\) in determining the existence of the inverse."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinant of the matrix \\( A = \\begin{pmatrix} 3 & 2 \\\\ 5 & 4 \\end{pmatrix} \\) using the cofactor expansion along the first row. Then, use the cofactor matrix to calculate the inverse of \\( A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( B = \\begin{pmatrix} 1 & 3 & 2 \\\\ 4 & 1 & 3 \\\\ 2 & 5 & 7 \\end{pmatrix} \\), compute the cofactor matrix and the inverse of \\( B \\) by following the process of minors, cofactors, and adjugation."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinant of the matrix \\( C = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and then find its inverse using the cofactor matrix. Verify the result by multiplying \\( C \\) with its inverse to check if the product is the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 4 & 3 \\\\ 6 & 5 \\end{pmatrix} \\). Use the cofactor method to find the determinant and inverse of \\( A \\), and interpret the determinant geometrically."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 4 \\\\ 0 & 0 & 1 \\end{pmatrix} \\). Compute the cofactor matrix, adjugate matrix, and the inverse of \\( A \\). Discuss how the structure of the matrix affects the cofactor calculations."
    },
    {
        "chapter": "Determinants",
        "question": "Given a 3x3 matrix \\( M = \\begin{pmatrix} 1 & 0 & 3 \\\\ 2 & 1 & 1 \\\\ 4 & 5 & 2 \\end{pmatrix} \\), compute the area of the triangle formed by the vectors corresponding to the rows of \\( M \\) using the determinant. Explain how the geometry of the vectors relates to the value of the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 1 & 2 & 0 \\\\ 0 & 3 & 1 \\\\ 4 & 1 & 2 \\end{pmatrix} \\). Use the determinant to calculate the volume of the parallelepiped formed by the vectors corresponding to the rows of \\( A \\). Show all steps and provide a geometric interpretation of the result."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 5 & 3 & 1 \\\\ 6 & 4 & 2 \\\\ 7 & 5 & 3 \\end{pmatrix} \\). Use Cramer's rule, cofactor matrices, and determinants to solve the system of linear equations formed by \\( A \\) and a constant vector \\( \\mathbf{b} \\). Find the solution and verify your calculations."
    },
    {
        "chapter": "Determinants",
        "question": "Given the 4x4 matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 5 & 6 & 7 \\\\ 0 & 0 & 8 & 9 \\\\ 0 & 0 & 0 & 10 \\end{pmatrix} \\), calculate the determinant and the inverse of \\( A \\) using the cofactor expansion method. Explain the computational challenges and benefits of using this method for large matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the following matrix:\n    \\[\n    A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 2 & 2 & 2 \\\\ 3 & 3 & 3 \\end{pmatrix}\n    \\]\n    Compute its determinant and inverse, and discuss the implications of the determinant being zero. What does this imply about the rank and the invertibility of \\( A \\)?"
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 2 & 4 & 1 \\\\ 6 & 5 & 3 \\\\ 7 & 8 & 9 \\end{pmatrix} \\), calculate its determinant and use the cofactor method to find the inverse of \\( A \\). Discuss the relationship between the determinant and the volume of the parallelepiped formed by the rows of \\( A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\). Compute the inverse of \\( A \\) using its cofactor matrix. What does the result suggest about the identity matrix and its properties?"
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( M = \\begin{pmatrix} 2 & 1 & 1 \\\\ 1 & 2 & 1 \\\\ 1 & 1 & 2 \\end{pmatrix} \\). Compute the determinant of \\( M \\) and use it to find the area of the triangle formed by the rows of \\( M \\). Discuss the geometric interpretation of the result."
    },
    {
        "chapter": "Determinants",
        "question": "Use the cofactor method to compute the inverse of the matrix\n    \\[\n    A = \\begin{pmatrix} 3 & 1 & 4 \\\\ 2 & 2 & 1 \\\\ 5 & 1 & 3 \\end{pmatrix}.\n    \\]\n    After calculating the inverse, verify it by multiplying \\( A \\) and its inverse and checking if the result is the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 5 & 6 & 7 \\\\ 0 & 0 & 8 & 9 \\\\ 0 & 0 & 0 & 10 \\end{pmatrix},\n    \\]\n    compute the determinant using cofactor expansion along the first row. Discuss how the structure of the matrix simplifies the computation."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix\n    \\[\n    A = \\begin{pmatrix} 3 & 2 \\\\ 1 & 4 \\end{pmatrix},\n    \\]\n    compute the determinant and the inverse of \\( A \\) using the cofactor matrix. Interpret the determinant in terms of area."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix},\n    \\]\n    compute the determinant and inverse of \\( A \\) using the cofactor method. Discuss the geometric interpretation of the determinant and inverse of a diagonal matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix} 3 & 4 \\\\ 5 & 6 \\end{pmatrix}\n    \\]\n    and use it to determine the volume of the parallelogram formed by the rows of \\( A \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix\n    \\[\n    A = \\begin{pmatrix} 2 & 4 \\\\ 1 & 2 \\end{pmatrix},\n    \\]\n    compute its determinant using cofactor expansion and explain how the determinant relates to the area of a rectangle in the plane."
    },
    {
        "chapter": "Determinants",
        "question": "Find the determinant and inverse of the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 3 \\\\ 2 & 5 \\end{pmatrix},\n    \\]\n    and explain the meaning of the determinant in terms of scaling factors for area."
    },
    {
        "chapter": "Determinants",
        "question": "Calculate the cofactor matrix of the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix}\n    \\]\n    and use it to find the inverse, if possible. Discuss why the inverse does not exist for this matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Using the cofactor matrix, find the inverse of the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 1 \\\\ 2 & 3 & 3 \\\\ 1 & 1 & 2 \\end{pmatrix}.\n    \\]\n    Verify the result by checking if the product of \\( A \\) and its inverse equals the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 3 & 1 & 2 \\\\ 1 & 2 & 1 \\\\ 2 & 3 & 1 \\end{pmatrix} \\), compute the area of the parallelogram formed by the rows of \\( A \\) using the determinant. Discuss the geometric interpretation of the determinant as the scaling factor for the area in \\( \\mathbb{R}^2 \\) and how the matrix entries affect the area calculation."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 1 & 3 & 0 \\\\ 4 & 1 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} \\). Compute the determinant of \\( A \\) and use it to find the volume of the parallelepiped formed by the rows of \\( A \\). Interpret the result geometrically in terms of volume scaling in \\( \\mathbb{R}^3 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\). Calculate the volume of the parallelepiped formed by the rows of \\( A \\) using the determinant. Discuss how the determinant relates to the scaling factors of the coordinate axes."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 4 & 5 \\\\ 0 & 0 & 6 \\end{pmatrix} \\), compute the determinant and use it to calculate the volume of the parallelepiped formed by the columns of \\( A \\). Provide a detailed analysis of how the matrix structure influences the computation."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the area of the triangle formed by the vectors corresponding to the rows of the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\). Use the determinant to calculate the area and interpret the result in terms of geometric properties in \\( \\mathbb{R}^2 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( B = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 1 \\end{pmatrix} \\). Calculate the determinant of \\( B \\) and use it to determine the volume of the solid formed by the vectors corresponding to the rows of \\( B \\). Analyze the result geometrically and discuss the interpretation of the determinant in this context."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 4 & 1 & 3 \\\\ 2 & 2 & 1 \\\\ 1 & 3 & 2 \\end{pmatrix} \\), compute the volume of the parallelepiped formed by the columns of \\( A \\). Discuss how the determinant relates to the geometric volume and how row/column exchanges affect the determinant value."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 2 & 0 & 1 \\\\ 3 & 1 & 0 \\\\ 1 & 4 & 2 \\end{pmatrix} \\). Using the determinant, calculate the volume of the parallelepiped formed by the vectors corresponding to the rows of \\( A \\). Discuss the implications of the result in terms of spatial orientation and how the matrix entries influence the geometric outcome."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 3 & 4 \\\\ 5 & 6 & 7 \\end{pmatrix} \\), compute the determinant and explain how the value of the determinant corresponds to the volume of the parallelepiped formed by the rows of \\( A \\). Discuss the properties of the matrix that affect the determinant and its relation to volume scaling."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 0 & 1 & 2 \\\\ 3 & 1 & 0 \\\\ 1 & 4 & 5 \\end{pmatrix} \\). Calculate the volume of the parallelepiped formed by the columns of \\( A \\) using the determinant. Explain how the determinant behaves as a measure of volume in three-dimensional space and the relationship between the rows and columns in the matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 3 & 1 & 2 \\\\ 1 & 2 & 1 \\\\ 2 & 3 & 1 \\end{pmatrix} \\), compute the area of the parallelogram formed by the rows of \\( A \\) using the determinant. Discuss the geometric interpretation of the determinant as the scaling factor for the area in \\( \\mathbb{R}^2 \\) and how the matrix entries affect the area calculation."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 1 & 3 & 0 \\\\ 4 & 1 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} \\). Compute the determinant of \\( A \\) and use it to find the volume of the parallelepiped formed by the rows of \\( A \\). Interpret the result geometrically in terms of volume scaling in \\( \\mathbb{R}^3 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\). Calculate the volume of the parallelepiped formed by the rows of \\( A \\) using the determinant. Discuss how the determinant relates to the scaling factors of the coordinate axes."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 4 & 5 \\\\ 0 & 0 & 6 \\end{pmatrix} \\), compute the determinant and use it to calculate the volume of the parallelepiped formed by the columns of \\( A \\). Provide a detailed analysis of how the matrix structure influences the computation."
    },
    {
        "chapter": "Determinants",
        "question": "Compute the area of the triangle formed by the vectors corresponding to the rows of the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\). Use the determinant to calculate the area and interpret the result in terms of geometric properties in \\( \\mathbb{R}^2 \\)."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( B = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 1 \\end{pmatrix} \\). Calculate the determinant of \\( B \\) and use it to determine the volume of the solid formed by the vectors corresponding to the rows of \\( B \\). Analyze the result geometrically and discuss the interpretation of the determinant in this context."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 4 & 1 & 3 \\\\ 2 & 2 & 1 \\\\ 1 & 3 & 2 \\end{pmatrix} \\), compute the volume of the parallelepiped formed by the columns of \\( A \\). Discuss how the determinant relates to the geometric volume and how row/column exchanges affect the determinant value."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 2 & 0 & 1 \\\\ 3 & 1 & 0 \\\\ 1 & 4 & 2 \\end{pmatrix} \\). Using the determinant, calculate the volume of the parallelepiped formed by the vectors corresponding to the rows of \\( A \\). Discuss the implications of the result in terms of spatial orientation and how the matrix entries influence the geometric outcome."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 3 & 4 \\\\ 5 & 6 & 7 \\end{pmatrix} \\), compute the determinant and explain how the value of the determinant corresponds to the volume of the parallelepiped formed by the rows of \\( A \\). Discuss the properties of the matrix that affect the determinant and its relation to volume scaling."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 0 & 1 & 2 \\\\ 3 & 1 & 0 \\\\ 1 & 4 & 5 \\end{pmatrix} \\). Calculate the volume of the parallelepiped formed by the columns of \\( A \\) using the determinant. Explain how the determinant behaves as a measure of volume in three-dimensional space and the relationship between the rows and columns in the matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\) be a matrix. Compute the determinant of \\( A \\) and determine whether the permutation represented by the matrix is even or odd. Discuss the relationship between the determinant and the parity of permutations."
    },
    {
        "chapter": "Determinants",
        "question": "Given a matrix \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\), determine the parity of the permutation that transforms the identity matrix into \\( A \\). Explain how the determinant relates to the parity of the permutation and prove the conclusion using the properties of the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( B = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\). Compute the determinant of \\( B \\) and determine whether it represents an even or odd permutation. Provide a detailed explanation of how row swaps affect the determinant and the parity of the permutation."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( C = \\begin{pmatrix} 3 & 4 & 5 \\\\ 6 & 7 & 8 \\\\ 9 & 10 & 11 \\end{pmatrix} \\). Compute the determinant of \\( C \\) and classify the permutation as even or odd. Discuss how the matrix structure relates to the permutation's parity, especially in the context of determinant properties."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( D = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\), calculate the determinant and determine whether the permutation of rows in \\( D \\) is even or odd. How does the parity of the permutation affect the value of the determinant, and what conclusions can be drawn from this observation?"
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( A = \\begin{pmatrix} 2 & 3 \\\\ 5 & 7 \\end{pmatrix} \\). Find the determinant of \\( A \\) and explain the significance of the permutation's parity in relation to the determinant's sign. Discuss whether the matrix represents an even or odd permutation of the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} \\). Calculate the determinant of \\( A \\) and classify the permutation of rows as even or odd. Provide a proof of your classification and explain how row exchanges affect the determinant in this case."
    },
    {
        "chapter": "Determinants",
        "question": "Given a matrix \\( E = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\), compute the determinant and determine whether it corresponds to an even or odd permutation of rows. Discuss the importance of the permutation's parity in determining the determinant\u2019s value and the broader implications for matrix theory."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the matrix \\( F = \\begin{pmatrix} 1 & 3 & 2 \\\\ 4 & 6 & 5 \\\\ 7 & 9 & 8 \\end{pmatrix} \\). Compute the determinant of \\( F \\) and analyze the parity of the permutation it represents. Discuss how the determinant sign and permutation parity are related, and how the order of row swaps influences the final result."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( G = \\begin{pmatrix} 3 & 1 & 2 \\\\ 6 & 4 & 5 \\\\ 9 & 7 & 8 \\end{pmatrix} \\). Calculate the determinant of \\( G \\) and determine whether the permutation is even or odd. Explain the role of the determinant in determining the parity of a permutation and how this property can be extended to higher-dimensional matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Given the matrix \\( A = \\begin{pmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{pmatrix} \\), compute the number of terms in the expansion of \\( \\det(A) \\). Also, determine how many of these terms will be zero and justify your reasoning using the properties of the matrix elements."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 2 \\\\ 0 & 3 & 4 \\\\ 5 & 0 & 6 \\end{pmatrix} \\). Find the number of non-zero terms in the determinant expansion of \\( A \\) and explain why certain terms cancel out to zero. Discuss how the structure of \\( A \\) influences the number of non-zero terms in the expansion."
    },
    {
        "chapter": "Determinants",
        "question": "For the matrix \\( A = \\begin{pmatrix} x & y & z \\\\ 2x & 2y & 2z \\\\ x & -y & z \\end{pmatrix} \\), calculate the number of terms in the determinant expansion. How many of these terms will be zero, and what can be inferred about the matrix\u2019s rank and linear dependence of rows or columns?"
    },
    {
        "chapter": "Determinants",
        "question": "Given a \\( 4 \\times 4 \\) matrix \\( A = \\begin{pmatrix} a_1 & a_2 & a_3 & a_4 \\\\ b_1 & b_2 & b_3 & b_4 \\\\ c_1 & c_2 & c_3 & c_4 \\\\ d_1 & d_2 & d_3 & d_4 \\end{pmatrix} \\), determine the number of terms in the expansion of \\( \\det(A) \\) and the number of zero terms in that expansion. What does this tell you about the number of independent rows or columns in the matrix?"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 2 & 1 & 0 \\\\ 3 & 5 & 0 \\\\ 4 & 2 & 1 \\end{pmatrix} \\). Determine the number of terms in the determinant expansion for this matrix and identify which terms are zero. Discuss the impact of the zeros on the rank of the matrix and how the determinant computation changes with such terms."
    },
    {
        "chapter": "Determinants",
        "question": "For the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 5 & 6 & 7 & 8 \\\\ 9 & 10 & 11 & 12 \\\\ 13 & 14 & 15 & 16 \\end{pmatrix} \\), compute the number of terms in the determinant expansion and the number of terms that will be zero. Analyze how the structure of this specific matrix, with rows forming an arithmetic progression, influences the determinant\u2019s value and the cancellation of terms in the expansion."
    },
    {
        "chapter": "Determinants",
        "question": "Given the points \\( A = (1, 2), B = (3, 5), C = (6, 7) \\), calculate the area of the triangle formed by these points using determinants. Show the step-by-step derivation of the area and discuss the geometric interpretation of the determinant in this context."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the vectors \\( \\mathbf{v}_1 = (1, 2, 3), \\mathbf{v}_2 = (4, 5, 6), \\mathbf{v}_3 = (7, 8, 9) \\). Compute the volume of the parallelepiped formed by these vectors using the scalar triple product. Discuss the geometric interpretation of the determinant in terms of the volume of the parallelepiped."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\) be a matrix. Use determinants to determine the volume of the parallelepiped formed by the row vectors of \\( A \\). Discuss how the structure of the matrix affects the volume of the parallelepiped and its relationship to the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Given the points \\( A = (1, 1, 1), B = (2, 3, 4), C = (4, 5, 6), D = (7, 8, 9) \\), calculate the volume of the tetrahedron formed by these points using determinants. Provide a detailed explanation of how to compute this volume from the determinant of a matrix."
    },
    {
        "chapter": "Determinants",
        "question": "For the parallelogram defined by the vectors \\( \\mathbf{v}_1 = (3, 4), \\mathbf{v}_2 = (1, 2) \\), compute the area using the determinant of the matrix formed by these vectors. Discuss the significance of the determinant as a measure of the area and how it relates to the geometry of the parallelogram."
    },
    {
        "chapter": "Determinants",
        "question": "Consider a parallelepiped in 3D space defined by the vectors \\( \\mathbf{v}_1 = (2, 0, 1), \\mathbf{v}_2 = (1, 3, 0), \\mathbf{v}_3 = (0, 1, 2) \\). Find the volume of this parallelepiped using the determinant of the matrix formed by these vectors. Discuss how the determinant calculation captures the 3D nature of the volume."
    },
    {
        "chapter": "Determinants",
        "question": "Let the points \\( A = (1, 1), B = (4, 2), C = (3, 5) \\) define a triangle in the plane. Use the determinant method to find the area of the triangle. Also, show how this formula generalizes to triangles in higher dimensions."
    },
    {
        "chapter": "Determinants",
        "question": "Find the area of the triangle formed by the points \\( A = (0, 0), B = (1, 2), C = (3, 3) \\) in \\( \\mathbb{R}^2 \\) using determinants. Discuss the conditions under which the determinant-based formula for the area may yield zero and its interpretation in terms of the geometry of the triangle."
    },
    {
        "chapter": "Determinants",
        "question": "Given the vertices of a hypercube in \\( \\mathbb{R}^4 \\), compute the volume of the hypercube using the determinant of a matrix formed by the vectors corresponding to its edges. Provide an in-depth analysis of how the determinant method can be applied to higher-dimensional objects like the hypercube."
    },
    {
        "chapter": "Determinants",
        "question": "Consider a triangle in \\( \\mathbb{R}^3 \\) with vertices \\( A = (1, 0, 0), B = (0, 1, 0), C = (0, 0, 1) \\). Calculate the area of this triangle using determinants. Discuss the relationship between the determinant and the geometry of the triangle in three-dimensional space."
    },
    {
        "chapter": "Determinants",
        "question": "Given a matrix \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\), find the volume of the unit cube and explain how the determinant relates to the geometric interpretation of this volume. Discuss what happens to the volume when the matrix is scaled or rotated."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\). Compute the determinant of \\( A \\) and explain how it can be used to calculate the volume of the parallelepiped formed by the vectors corresponding to the rows of \\( A \\). Discuss the impact of row operations on the volume."
    },
    {
        "chapter": "Determinants",
        "question": "For the matrix \\( B = \\begin{pmatrix} 2 & 1 & 3 \\\\ 1 & 0 & 4 \\\\ 5 & 2 & 6 \\end{pmatrix} \\), compute the volume of the parallelepiped formed by its row vectors. Discuss the effect of the matrix entries on the volume and how it can be interpreted geometrically in 3D space."
    },
    {
        "chapter": "Determinants",
        "question": "Given the vertices of a triangle in \\( \\mathbb{R}^3 \\), \\( A = (1, 2, 3), B = (4, 5, 6), C = (7, 8, 9) \\), compute the area using determinants. Analyze how the determinant-based method for computing the area can be extended to higher dimensions for simplex-like structures."
    },
    {
        "chapter": "Determinants",
        "question": "Consider the parallelogram formed by the vectors \\( \\mathbf{v}_1 = (2, 1) \\) and \\( \\mathbf{v}_2 = (1, 3) \\) in \\( \\mathbb{R}^2 \\). Calculate its area using the determinant of the matrix formed by these two vectors. Discuss the significance of the cross product interpretation of the determinant for 2D areas."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\\\ 2 & 3 & 4 \\end{pmatrix} \\) be the matrix representing the vectors forming a parallelepiped. Compute the volume of the parallelepiped formed by the column vectors of \\( A \\) using the determinant. Discuss the effects of scaling and rotations on the volume as represented by the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "Consider a matrix \\( A \\in \\mathbb{R}^{n \\times n} \\) and a perturbation matrix \\( E \\in \\mathbb{R}^{n \\times n} \\) such that the perturbed matrix is \\( A + E \\). Derive an expression for the sensitivity of the determinant of \\( A \\) to perturbations in \\( E \\) using first-order approximation. Discuss the implications of this result on numerical stability when calculating determinants in high-dimensional systems."
    },
    {
        "chapter": "Determinants",
        "question": "Investigate the condition number of a matrix \\( A \\) and how it is related to the sensitivity of its determinant under perturbation. Provide a detailed proof that the condition number, defined as \\( \\kappa(A) = \\|A\\| \\|A^{-1}\\| \\), can be used to bound the relative change in the determinant \\( \\det(A) \\) due to small perturbations. How does the condition number influence the numerical stability of determinant calculations in computational algorithms?"
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\) be a diagonalizable matrix with eigenvalues \\( \\lambda_1, \\lambda_2, \\dots, \\lambda_n \\). Discuss the effect of a small perturbation \\( E \\) on the eigenvalues of \\( A \\) using perturbation theory. Derive an expression for the change in the determinant \\( \\det(A + E) \\) in terms of the eigenvalue shifts induced by \\( E \\), and explain the role of eigenvalue sensitivity in understanding the stability of determinants."
    },
    {
        "chapter": "Determinants",
        "question": "In the context of eigenvalue perturbation theory, consider the matrix \\( A + E \\), where \\( E \\) is a small perturbation. Show that, to first order, the determinant of \\( A + E \\) can be approximated as \\( \\det(A + E) \\approx \\det(A) \\cdot \\left( 1 + \\text{Tr}(A^{-1}E) \\right) \\). Discuss the implications of this result for matrices with large condition numbers and provide a numerical example to illustrate the behavior."
    },
    {
        "chapter": "Determinants",
        "question": "Given a matrix \\( A \\in \\mathbb{R}^{n \\times n} \\), define the matrix \\( A + \\delta A \\) as a perturbation of \\( A \\), where \\( \\delta A \\) represents a small change. Using perturbation theory, derive a bound for the relative error in \\( \\det(A + \\delta A) \\) in terms of the norm of \\( \\delta A \\) and the condition number of \\( A \\). Discuss the computational techniques to mitigate the effects of large errors when calculating determinants in practical scenarios."
    },
    {
        "chapter": "Determinants",
        "question": "Investigate how the spectral properties of a matrix \\( A \\), including the eigenvalues and singular values, impact the perturbation behavior of its determinant. Specifically, explore the relationship between the largest and smallest eigenvalues of \\( A \\) and the change in the determinant when subjected to small perturbations. Discuss how these properties are used in numerical methods to estimate the stability of determinant calculations in large matrices."
    },
    {
        "chapter": "Determinants",
        "question": "Discuss the perturbation theory for the eigenvalues of symmetric matrices. Derive a first-order approximation for the change in the determinant of a symmetric matrix \\( A \\) when it is perturbed by a small symmetric matrix \\( E \\). How does the spectral theorem help in analyzing the effects of such perturbations, and what insights can be gained about the stability of determinants in this specific case?"
    },
    {
        "chapter": "Determinants",
        "question": "Consider a square matrix \\( A \\in \\mathbb{C}^{n \\times n} \\) and its Singular Value Decomposition \\( A = U \\Sigma V^H \\), where \\( U \\) and \\( V \\) are unitary matrices and \\( \\Sigma \\) is a diagonal matrix of singular values. Derive the relationship between the determinant of \\( A \\) and the singular values in \\( \\Sigma \\). Specifically, express \\( \\det(A) \\) as the product of the singular values and discuss how this provides insight into the geometric properties of the matrix."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\in \\mathbb{R}^{n \\times n} \\) have Singular Value Decomposition \\( A = U \\Sigma V^T \\). Explore the impact of the rank of \\( A \\) on its determinant. Show that if \\( A \\) is of full rank, the determinant is the product of the non-zero singular values, and if \\( A \\) is rank-deficient, the determinant is zero. Provide a proof that the determinant of a rank-deficient matrix vanishes and relate this result to the properties of the SVD."
    },
    {
        "chapter": "Determinants",
        "question": "Suppose \\( A \\in \\mathbb{R}^{n \\times n} \\) has singular values \\( \\sigma_1, \\sigma_2, \\dots, \\sigma_n \\), where some of these singular values are zero. Discuss the geometric interpretation of the determinant of \\( A \\) as it relates to the volume scaling factor of a transformation defined by \\( A \\). How does the presence of zero singular values affect the transformation, and what does it imply about the invertibility of the matrix?"
    },
    {
        "chapter": "Determinants",
        "question": "Consider the case where \\( A \\in \\mathbb{C}^{n \\times n} \\) is a complex matrix, and \\( A = U \\Sigma V^H \\) is its Singular Value Decomposition. Investigate how the determinant of \\( A \\) extends to complex matrices. Discuss how the determinant can be interpreted geometrically in complex vector spaces, and show how the determinant relates to the volume scaling of the linear transformation \\( A \\) in a complex setting."
    },
    {
        "chapter": "Determinants",
        "question": "Let \\( A \\in \\mathbb{C}^{n \\times n} \\) be a complex matrix with singular values \\( \\sigma_1, \\sigma_2, \\dots, \\sigma_n \\), and let \\( \\lambda_1, \\lambda_2, \\dots, \\lambda_n \\) be the eigenvalues of \\( A \\). Discuss the connection between the singular values and eigenvalues of a complex matrix. Prove that for a square matrix \\( A \\), the determinant can be written as the product of both the singular values and eigenvalues. How do these results extend to non-square matrices?"
    },
    {
        "chapter": "Determinants",
        "question": "In the context of rank decomposition, consider a matrix \\( A \\in \\mathbb{R}^{m \\times n} \\) with rank \\( r \\), where \\( r < \\min(m, n) \\). Using the Singular Value Decomposition of \\( A \\), discuss how the rank influences the determinant of \\( A \\). Specifically, show that the determinant of a matrix with rank less than \\( \\min(m, n) \\) is zero, and explain the significance of this result in terms of the matrix's singular values."
    },
    {
        "chapter": "Determinants",
        "question": "Investigate the extension of the determinant function to quaternionic matrices. Let \\( A \\in \\mathbb{H}^{n \\times n} \\) be a matrix with entries in the quaternions, and discuss how the determinant is defined for such matrices. Explore the geometric interpretation of the determinant in quaternionic vector spaces, particularly in terms of scaling and orientation. Provide examples of quaternionic matrices and their determinants, and compare the behavior of quaternionic determinants with those of complex matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of the matrix \n    \\[\n    A = \n    \\begin{bmatrix}\n    1 & -1 \\\\\n    2 & 4\n    \\end{bmatrix}\n    \\]\n    Verify that the trace equals the sum of the eigenvalues, and the determinant equals their product."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "With the same matrix $A$, solve the differential equation \n    \\[\n    \\frac{du}{dt} = A u, \\quad u(0) =\n    \\begin{bmatrix}\n    0 \\\\\n    6\n    \\end{bmatrix}\n    \\]\n    What are the two pure exponential solutions?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If we shift to $A - 7I$, what are the eigenvalues and eigenvectors, and how are they related to those of $A$?\n    \\[\n    B = A - 7I =\n    \\begin{bmatrix}\n    -6 & -1 \\\\\n    2 & -3\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve $\\frac{du}{dt} = P u$, when $P$ is a projection:\n    \\[\n    \\frac{du}{dt} =\n    \\begin{bmatrix}\n    \\frac{1}{2} & \\frac{1}{2} \\\\\n    \\frac{1}{2} & \\frac{1}{2}\n    \\end{bmatrix}\n    u, \\quad u(0) =\n    \\begin{bmatrix}\n    5 \\\\\n    3\n    \\end{bmatrix}\n    \\]\n    Part of $u(0)$ increases exponentially while the nullspace part stays fixed."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of\n    \\[\n    A =\n    \\begin{bmatrix}\n    3 & 4 & 2 \\\\\n    0 & 1 & 2 \\\\\n    0 & 0 & 0\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B =\n    \\begin{bmatrix}\n    0 & 0 & 2 \\\\\n    0 & 2 & 0 \\\\\n    2 & 0 & 0\n    \\end{bmatrix}\n    \\]\n    Check that $\\lambda_1 + \\lambda_2 + \\lambda_3$ equals the trace and $\\lambda_1 \\lambda_2 \\lambda_3$ equals the determinant."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Give an example to show that the eigenvalues can be changed when a multiple of one row is subtracted from another. Why is a zero eigenvalue not changed by the steps of elimination?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose that $\\lambda$ is an eigenvalue of $A$, and $x$ is its eigenvector: $Ax = \\lambda x$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that this same $x$ is an eigenvector of $B = A - 7I$, and find the eigenvalue. This should confirm Exercise 3."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Assuming $\\lambda \\neq 0$, show that $x$ is also an eigenvector of $A^{-1}$\u2014and find the eigenvalue."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the determinant equals the product of the eigenvalues by imagining that the characteristic polynomial is factored into\n    \\[\n    \\det(A - \\lambda I) = (\\lambda_1 - \\lambda)(\\lambda_2 - \\lambda) \\cdots (\\lambda_n - \\lambda),\n    \\]\n    and making a clever choice of $\\lambda$.\\"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the trace equals the sum of the eigenvalues, in two steps. First, find the coefficient of $(-\\lambda)^{n-1}$ on the right side of equation (16). Next, find all the terms in \n    \\[\n    \\det(A - \\lambda I) = \\det\n    \\begin{bmatrix}\n    a_{11} - \\lambda & a_{12} & \\cdots & a_{1n} \\\\\n    a_{21} & a_{22} - \\lambda & \\cdots & a_{2n} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    a_{n1} & a_{n2} & \\cdots & a_{nn} - \\lambda\n    \\end{bmatrix}\n    \\]\n    that involve $(-\\lambda)^{n-1}$. They all come from the main diagonal! Find that coefficient of $(-\\lambda)^{n-1}$ and compare."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Construct $2 \\times 2$ matrices such that the eigenvalues of $AB$ are not the products of the eigenvalues of $A$ and $B$, and the eigenvalues of $A + B$ are not the sums of the individual eigenvalues."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Verify, however, that the sum of the eigenvalues of $A + B$ equals the sum of all the individual eigenvalues of $A$ and $B$, and similarly for products. Why is this true?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The eigenvalues of $A$ equal the eigenvalues of $A^T$. This is because $\\det(A - \\lambda I)$ equals $\\det(A^T - \\lambda I)$. That is true because $\\underline{\\hspace{3cm}}$. Show by an example that the eigenvectors of $A$ and $A^T$ are not the same."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of\n    \\[\n    A =\n    \\begin{bmatrix}\n    3 & 4 \\\\\n    4 & -3\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    A =\n    \\begin{bmatrix}\n    a & b \\\\\n    b & a\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $B$ has eigenvalues $1, 2, 3$, $C$ has eigenvalues $4, 5, 6$, and $D$ has eigenvalues $7, 8, 9$, what are the eigenvalues of the $6 \\times 6$ matrix \n    \\[\n    A =\n    \\begin{bmatrix}\n    B & C \\\\\n    0 & D\n    \\end{bmatrix}?\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the rank and all four eigenvalues for both the matrix of ones and the checkerboard matrix:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & 1 & 1\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    C =\n    \\begin{bmatrix}\n    0 & 1 & 0 & 1 \\\\\n    1 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 1 \\\\\n    1 & 0 & 1 & 0\n    \\end{bmatrix}.\n    \\]\n    Which eigenvectors correspond to nonzero eigenvalues?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What are the rank and eigenvalues when $A$ and $C$ in the previous exercise are $n \\times n$? Remember that the eigenvalue $\\lambda = 0$ is repeated $n - r$ times."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A$ is the $4 \\times 4$ matrix of ones, find the eigenvalues and the determinant of $A - I$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Choose the third row of the \u201ccompanion matrix\u201d\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & 1 & 0 \\\\\n    0 & 0 & 1 \\\\\n    \\vdots\n    \\end{bmatrix}\n    \\]\n    so that its characteristic polynomial $|A - \\lambda I|$ is $-\\lambda^3 + 4\\lambda^2 + 5\\lambda + 6$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose $A$ has eigenvalues $0, 3, 5$ with independent eigenvectors $u, v, w$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Give a basis for the nullspace and a basis for the column space."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a particular solution to $Ax = v + w$. Find all solutions."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that $Ax = u$ has no solution. (If it had a solution, then $\\underline{\\hspace{4cm}}$ would be in the column space.)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The powers $A^k$ of this matrix $A$ approach a limit as $k \\to \\infty$:\n    \\[\n    A =\n    \\begin{bmatrix}\n    0.8 & 0.3 \\\\\n    0.2 & 0.7\n    \\end{bmatrix},\n    \\quad\n    A^2 =\n    \\begin{bmatrix}\n    0.70 & 0.45 \\\\\n    0.30 & 0.55\n    \\end{bmatrix},\n    \\quad\n    A^\\infty =\n    \\begin{bmatrix}\n    0.6 & 0.6 \\\\\n    0.4 & 0.4\n    \\end{bmatrix}.\n    \\]\n    The matrix $A^2$ is halfway between $A$ and $A^\\infty$. Explain why \n    \\[\n    A^2 = \\frac{1}{2} (A + A^\\infty)\n    \\]\n    from the eigenvalues and eigenvectors of these three matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of these two matrices:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 4 \\\\\n    2 & 3\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    A + I =\n    \\begin{bmatrix}\n    2 & 4 \\\\\n    2 & 4\n    \\end{bmatrix}.\n    \\]\n    $A + I$ has the same eigenvectors as $A$. Its eigenvalues are $\\underline{\\hspace{3cm}}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Compute the eigenvalues and eigenvectors of $A$ and $A^{-1}$:\n    \\[\n    A =\n    \\begin{bmatrix}\n    0 & 2 \\\\\n    2 & 3\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    A^{-1} =\n    \\begin{bmatrix}\n    -3/4 & 1/2 \\\\\n    1/2 & 0\n    \\end{bmatrix}.\n    \\]\n    $A^{-1}$ has the same eigenvectors as $A$. When $A$ has eigenvalues $\\lambda_1$ and $\\lambda_2$, its inverse has eigenvalues $\\underline{\\hspace{3cm}}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Compute the eigenvalues and eigenvectors of $A$ and $A^2$:\n    \\[\n    A =\n    \\begin{bmatrix}\n    -1 & 3 \\\\\n    2 & 0\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    A^2 =\n    \\begin{bmatrix}\n    7 & -3 \\\\\n    -2 & 6\n    \\end{bmatrix}.\n    \\]\n    $A^2$ has the same $\\underline{\\hspace{3cm}}$ as $A$. When $A$ has eigenvalues $\\lambda_1$ and $\\lambda_2$, $A^2$ has eigenvalues $\\underline{\\hspace{3cm}}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If you know $x$ is an eigenvector, the way to find $\\lambda$ is to $\\underline{\\hspace{3cm}}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If you know $\\lambda$ is an eigenvalue, the way to find $x$ is to $\\underline{\\text{\\hspace{3cm}}}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What do you do to $Ax = \\lambda x$, in order to prove the following?\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) $\\lambda^2$ is an eigenvalue of $A^2$, as in Problem 22."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) $\\lambda^{-1}$ is an eigenvalue of $A^{-1}$, as in Problem 21."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) $\\lambda +1$ is an eigenvalue of $A+I$, as in Problem 20.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "From the unit vector $u = \\begin{bmatrix} \\frac{1}{6} \\\\ \\frac{1}{6} \\\\ \\frac{3}{6} \\\\ \\frac{5}{6} \\end{bmatrix}$, construct the rank-1 projection matrix $P = uu^T$.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) Show that $Pu = u$. Then $u$ is an eigenvector with $\\lambda = 1$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) If $v$ is perpendicular to $u$, show that $Pv = \\mathbf{0}$. Then $\\lambda = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) Find three independent eigenvectors of $P$, all with eigenvalue $\\lambda = 0$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve $\\det(Q-\\lambda I) = 0$ using the quadratic formula to reach $\\lambda = \\cos\\theta \\pm i\\sin\\theta$:\n    \\[\n    Q = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}\n    \\]\n    which rotates the $xy$-plane by the angle $\\theta$. Find the eigenvectors of $Q$ by solving $(Q-\\lambda I)x = 0$. Use $i^2 = -1$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Every permutation matrix leaves $x = (1,1,...,1)$ unchanged. Then $\\lambda = 1$. Find two more eigenvalues for these permutations:\n    \\[\n    P_1 = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix},\n    \\quad\n    P_2 = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A$ has $\\lambda_1 = 4$ and $\\lambda_2 = 5$, then\n    \\[\n    \\det(A-\\lambda I) = (\\lambda -4)(\\lambda -5) = \\lambda^2 -9\\lambda +20.\n    \\]\n    Find three matrices that have trace $a+d = 9$, determinant $20$, and eigenvalues $\\lambda = 4,5$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A $3 \\times 3$ matrix $B$ is known to have eigenvalues $0, 1, 2$. This information is enough to find three of the following:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) The rank of $B$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) The determinant of $B^T B$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) The eigenvalues of $B^T B$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(d) The eigenvalues of $(B+I)^{-1}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Choose the second row of $A = \\begin{bmatrix} 0 & 1 \\\\ * & * \\end{bmatrix}$ so that $A$ has eigenvalues $4$ and $7$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Choose $a, b, c$ so that $\\det(A-\\lambda I) = 9\\lambda - \\lambda^3$. Then the eigenvalues are $-3, 0, 3$:\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ a & b & c \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Construct any $3 \\times 3$ Markov matrix $M$: positive entries down each column add to 1. If $e = (1,1,1)$, verify that $M^T e = e$. By Problem 11, $\\lambda = 1$ is also an eigenvalue of $M$. \n    \n    Challenge: A $3 \\times 3$ singular Markov matrix with trace $\\frac{1}{2}$ has eigenvalues $\\lambda =$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find three $2 \\times 2$ matrices that have $\\lambda_1 = \\lambda_2 = 0$. The trace is zero and the determinant is zero. The matrix $A$ might not be 0 but check that $A^2 = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "This matrix is singular with rank 1. Find three $\\lambda$\u2019s and three eigenvectors:\n    \\[\n    A = \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} 2 & 1 & 2 \\end{bmatrix} = \\begin{bmatrix} 2 & 1 & 2 \\\\ 4 & 2 & 4 \\\\ 2 & 1 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose $A$ and $B$ have the same eigenvalues $\\lambda_1, \\dots, \\lambda_n$ with the same independent eigenvectors $x_1, \\dots, x_n$. Then $A = B$. Reason: Any vector $x$ is a combination $c_1 x_1 + \\dots + c_n x_n$. What is $Ax$? What is $Bx$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(Review) Find the eigenvalues of $A$, $B$, and $C$:\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 0 & 4 & 5 \\\\ 0 & 0 & 6 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 2 & 0 \\\\ 3 & 0 & 0 \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix} 2 & 2 & 2 \\\\ 2 & 2 & 2 \\\\ 2 & 2 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "When $a+b = c+d$, show that $(1,1)$ is an eigenvector and find both eigenvalues:\n    \\[\n    A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "When $P$ exchanges rows 1 and 2 and columns 1 and 2, the eigenvalues don\u2019t change.\n    Find eigenvectors of $A$ and $PAP$ for $\\lambda = 11$:\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 1 \\\\ 3 & 6 & 3 \\\\ 4 & 8 & 4 \\end{bmatrix}, \\quad\n    PAP = \\begin{bmatrix} 6 & 3 & 3 \\\\ 2 & 1 & 1 \\\\ 8 & 4 & 4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Challenge problem: Is there a real $2 \\times 2$ matrix (other than $I$) with $A^3 = I$? Its eigenvalues must satisfy $\\lambda^3 = I$. They can be $e^{2\\pi i / 3}$ and $e^{-2\\pi i / 3}$. What trace and determinant would this give? Construct $A$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "There are six $3 \\times 3$ permutation matrices $P$. What numbers can be the determinants of $P$? What numbers can be pivots? What numbers can be the trace of $P$? What four numbers can be eigenvalues of $P$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Factor the following matrices into \\( S \\Lambda S^{-1} \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A = \\begin{pmatrix} 2 & 1 \\\\ 0 & 0 \\end{pmatrix} \\)\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the matrix \\( A \\) whose eigenvalues are 1 and 4, and whose eigenvectors are \\( \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} \\) and \\( \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\), respectively. (Hint: \\( A = S \\Lambda S^{-1} \\).)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find all the eigenvalues and eigenvectors of\n    \\[\n    A = \\begin{pmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 1\n    \\end{pmatrix}\n    \\]\n    and write two different diagonalizing matrices \\( S \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If a 3 by 3 upper triangular matrix has diagonal entries 1, 2, 7, how do you know it can be diagonalized? What is \\( \\Lambda \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Which of these matrices cannot be diagonalized?\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A_1 = \\begin{pmatrix} 2 & -2 \\\\ 2 & -2 \\end{pmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A_2 = \\begin{pmatrix} 2 & 0 \\\\ 2 & -2 \\end{pmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A_3 = \\begin{pmatrix} 2 & 0 \\\\ 2 & 2 \\end{pmatrix} \\)\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) If \\( A^2 = I \\), what are the possible eigenvalues of \\( A \\)?\n    \n    (b) If this \\( A \\) is 2 by 2, and not \\( I \\) or \\( -I \\), find its trace and determinant.\n    \n    (c) If the first row is \\( (3, -1) \\), what is the second row?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A = \\begin{pmatrix} 4 & 3 \\\\ 1 & 2 \\end{pmatrix} \\), find \\( A^{100} \\) by diagonalizing \\( A \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A = uv^T \\) is a column times a row (a rank-1 matrix).\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) By multiplying \\( A \\) times \\( u \\), show that \\( u \\) is an eigenvector. What is \\( \\lambda \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) What are the other eigenvalues of \\( A \\) (and why)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) Compute \\( \\text{trace}(A) \\) from the sum on the diagonal and the sum of \\( \\lambda \\)'s.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show by direct calculation that \\( \\text{trace}(AB) \\) and \\( \\text{trace}(BA) \\) are the same when\n    \\[\n    A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} q & r \\\\ s & t \\end{pmatrix}.\n    \\]\n    Deduce that \\( AB - BA = I \\) is impossible (except in infinite dimensions)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A \\) has eigenvalues 1, 2, 4. What is the trace of \\( A^2 \\)? What is the determinant of \\( (A^{-1})^T \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the eigenvalues of \\( A \\) are 1, 1, 2, which of the following are certain to be true? Give a reason if true or a counterexample if false:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) \\( A \\) is invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) \\( A \\) is diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) \\( A \\) is not diagonalizable.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose the only eigenvectors of \\( A \\) are multiples of \\( x = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\). True or false:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) \\( A \\) is not invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) \\( A \\) has a repeated eigenvalue."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) \\( A \\) is not diagonalizable.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize the matrix \\( A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix} \\) and find one of its square roots\u2014a matrix such that \\( R^2 = A \\). How many square roots will there be?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose the eigenvector matrix \\( S \\) has \\( S^T = S^{-1} \\). Show that \\( A = S \\Lambda S^{-1} \\) is symmetric and has orthogonal eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Factor these two matrices into \\( A = S \\Lambda S^{-1} \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A = \\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A = \\begin{pmatrix} 1 & 1 \\\\ 2 & 2 \\end{pmatrix} \\)\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A = S \\Lambda S^{-1} \\), then \\( A^3 = ( ) ( ) ( ) \\) and \\( A^{-1} = ( ) ( ) ( ) \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A \\) has \\( \\lambda_1 = 2 \\) with eigenvector \\( x_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\) and \\( \\lambda_2 = 5 \\) with \\( x_2 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\), use \\( S \\Lambda S^{-1} \\) to find \\( A \\). No other matrix has the same \\( \\lambda \\)'s and \\( x \\)'s."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A = S \\Lambda S^{-1} \\). What is the eigenvalue matrix for \\( A + 2I \\)? What is the eigenvector matrix? Check that \\( A + 2I = ( ) ( ) ( )^{-1} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "True or false: If the \\( n \\) columns of \\( S \\) (eigenvectors of \\( A \\)) are independent, then:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) \\( A \\) is invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) \\( A \\) is diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) \\( S \\) is invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(d) \\( S \\) is diagonalizable.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the eigenvectors of \\( A \\) are the columns of \\( I \\), then \\( A \\) is a matrix. If the eigenvector matrix \\( S \\) is triangular, then \\( S^{-1} \\) is triangular and \\( A \\) is triangular."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Describe all matrices \\( S \\) that diagonalize this matrix \\( A \\):\n    \\[\n    A = \\begin{pmatrix} 4 & 0 \\\\ 1 & 2 \\end{pmatrix}.\n    \\]\n    Then describe all matrices that diagonalize \\( A^{-1} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write the most general matrix that has eigenvectors \\( \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\) and \\( \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues of \\( A \\) and \\( B \\) and \\( A + B \\):\n    \\[\n    A = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}, \\quad A + B = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}.\n    \\]\n    Eigenvalues of \\( A + B \\) (are equal to) (are not equal to) eigenvalues of \\( A \\) plus eigenvalues of \\( B \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues of \\( A \\), \\( B \\), \\( AB \\), and \\( BA \\):\n    \\[\n    A = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}, \\quad AB = \\begin{pmatrix} 1 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad BA = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix}.\n    \\]\n    Eigenvalues of \\( AB \\) (are equal to) (are not equal to) eigenvalues of \\( A \\) times eigenvalues of \\( B \\). Eigenvalues of \\( AB \\) (are) (are not) equal to eigenvalues of \\( BA \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "True or false: If the eigenvalues of \\( A \\) are 2, 2, 5, then the matrix is certainly:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) not diagonalizable.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the eigenvalues of \\( A \\) are 1 and 0, write everything you know about the matrices \\( A \\) and \\( A^2 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Complete these matrices so that \\( \\text{det}(A) = 25 \\). Then trace = 10, and \\( \\lambda = 5 \\) is repeated! Find an eigenvector with \\( A x = 5x \\). These matrices will not be diagonalizable because there is no second line of eigenvectors.\n    \\[\n    A = \\begin{pmatrix} 8 & 2 \\\\ \\end{pmatrix}, \\quad A = \\begin{pmatrix} 9 & 4 \\\\ 1 & \\end{pmatrix}, \\quad A = \\begin{pmatrix} 10 & 5 \\\\ -5 & \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The matrix \\( A = \\begin{pmatrix} 3 & 1 \\\\ 0 & 3 \\end{pmatrix} \\) is not diagonalizable because the rank of \\( A - 3I \\) is $\\underline{\\hspace{2cm}}$. Change one entry to make \\( A \\) diagonalizable. Which entries could you change?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A^k = S \\Lambda^k S^{-1} \\) approaches the zero matrix as \\( k \\to \\infty \\) if and only if every \\( \\lambda \\) has absolute value less than 1. Does \\( A^k \\to 0 \\) or \\( B^k \\to 0 \\)?\n    \\[\n    A = \\begin{pmatrix} 0.6 & 0.4 \\\\ 0.4 & 0.6 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0.6 & 0.9 \\\\ 0.1 & 0.6 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(Recommended) Find \\( \\Lambda \\) and \\( S \\) to diagonalize \\( A \\) in Problem 29. What is the limit of \\( \\Lambda^k \\) as \\( k \\to \\infty \\)? What is the limit of \\( S \\Lambda^k S^{-1} \\)? In the columns of this limiting matrix you see the \\_."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find \\( \\Lambda \\) and \\( S \\) to diagonalize \\( B \\) in Problem 29. What is \\( B^{10} u_0 \\) for these \\( u_0 \\)?\n    \\[\n    u_0 = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}, \\quad u_0 = \\begin{pmatrix} 3 \\\\ -1 \\end{pmatrix}, \\quad u_0 = \\begin{pmatrix} 6 \\\\ 0 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize \\( A \\) and compute \\( S \\Lambda^k S^{-1} \\) to prove this formula for \\( A^k \\):\n    \\[\n    A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad A^k = \\frac{1}{2} \\begin{pmatrix} 3k+1 & 3k-1 \\\\ 3k-1 & 3k+1 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize \\( B \\) and compute \\( S \\Lambda^k S^{-1} \\) to prove this formula for \\( B^k \\):\n    \\[\n    B = \\begin{pmatrix} 3 & 1 \\\\ 0 & 2 \\end{pmatrix}, \\quad B^k = \\begin{pmatrix} 3^k & 3^{k-2} \\\\ k & 2^k \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose that \\( A = S \\Lambda S^{-1} \\). Take determinants to prove that \\( \\text{det}(A) = \\lambda_1 \\lambda_2 \\cdots \\lambda_n \\) = product of \\( \\lambda \\)\u2019s. This quick proof only works when \\( A \\) is \\underline{\\hspace{2cm}}."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The trace of \\( S \\times \\Lambda S^{-1} \\) equals the trace of \\( \\Lambda S^{-1} \\times S \\). So the trace of a diagonalizable \\( A \\) equals the trace of \\( \\Lambda \\), which is \\underline{\\hspace{2cm}}."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A = S \\Lambda S^{-1} \\), diagonalize the block matrix\n    \\[\n    B = \\begin{pmatrix} A & 0 \\\\ 0 & 2A \\end{pmatrix}.\n    \\]\n    Find its eigenvalue and eigenvector matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider all \\( 4 \\times 4 \\) matrices \\( A \\) that are diagonalized by the same fixed eigenvector matrix \\( S \\). Show that the \\( A \\)\u2019s form a subspace (i.e., \\( cA \\) and \\( A_1 + A_2 \\) have this same \\( S \\)). What is this subspace when \\( S = I \\)? What is its dimension?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A^2 = A \\). On the left side, \\( A \\) multiplies each column of \\( A \\). Which of our four subspaces contains eigenvectors with \\( \\lambda = 1 \\)? Which subspace contains eigenvectors with \\( \\lambda = 0 \\)? From the dimensions of those subspaces, \\( A \\) has a full set of independent eigenvectors and can be diagonalized."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A x = \\lambda x \\). If \\( \\lambda = 0 \\), then \\( x \\) is in the nullspace. If \\( \\lambda \\neq 0 \\), then \\( x \\) is in the column space. Those spaces have dimensions \\( (n - r) + r = n \\). So why doesn\u2019t every square matrix have \\( n \\) linearly independent eigenvectors?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Substitute \\( A = S \\Lambda S^{-1} \\) into the product \\( (A - \\lambda_1 I)(A - \\lambda_2 I) \\cdots (A - \\lambda_n I) \\) and explain why this produces the zero matrix. We are substituting the matrix \\( A \\) for the number \\( \\lambda \\) in the polynomial \\( p(\\lambda) = \\text{det}(A - \\lambda I) \\). The Cayley-Hamilton Theorem says that this product is always \\( p(A) = \\) zero matrix, even if \\( A \\) is not diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Test the Cayley-Hamilton Theorem on Fibonacci\u2019s matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix}.\n    \\]\n    The theorem predicts that \\( A^2 - A - I = 0 \\), since \\( \\text{det}(A - \\lambda I) \\) is \\( \\lambda^2 - \\lambda - 1 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\), then \\( \\text{det}(A - \\lambda I) \\) is \\( (\\lambda - a)(\\lambda - d) \\). Check the Cayley-Hamilton statement that \\( (A - aI)(A - dI) = \\) zero matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\) and \\( AB = BA \\), show that \\( B = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\) is also diagonal. \\( B \\) has the same eigen\\underline{\\hspace{2cm}} as \\( A \\), but different eigen\\underline{\\hspace{2cm}}. These diagonal matrices \\( B \\) form a two-dimensional subspace of matrix space. \\( AB - BA = 0 \\) gives four equations for the unknowns \\( a, b, c, d \\)\u2014find the rank of the \\( 4 \\times 4 \\) matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A \\) is \\( 5 \\times 5 \\), then \\( AB - BA = 0 \\) gives 25 equations for the 25 entries in \\( B \\). Show that the \\( 25 \\times 25 \\) matrix is singular by noticing a simple nonzero solution for \\( B \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors for both of these Markov matrices \\( A \\) and \\( A_{\\infty} \\). Explain why \\( A^{100} \\) is close to \\( A_{\\infty} \\):\n    \\[\n    A = \\begin{pmatrix} 0.6 & 0.2 \\\\ 0.4 & 0.8 \\end{pmatrix}, \\quad A_{\\infty} = \\begin{pmatrix} \\frac{1}{3} & \\frac{1}{3} \\\\ \\frac{2}{3} & \\frac{2}{3} \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that every third Fibonacci number in \\( 0, 1, 1, 2, 3, \\dots \\) is even."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Bernadelli studied a beetle \u201cwhich lives three years only and propagates in its third year.\u201d They survive the first year with probability \\( \\frac{1}{2} \\), and the second with probability \\( \\frac{1}{3} \\), and then produce six females on the way out. The beetle matrix \\( A \\) is\n    \\[\n    A = \\begin{pmatrix} 0 & 0 & 6 \\\\ \\frac{1}{2} & 0 & 0 \\\\ 0 & \\frac{1}{3} & 0 \\end{pmatrix}.\n    \\]\n    Show that \\( A^3 = I \\), and follow the distribution of 3000 beetles for six years."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the Fibonacci matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix},\n    \\]\n    compute \\( A^2 \\), \\( A^3 \\), and \\( A^4 \\). Then use the text and a calculator to find \\( F_{20} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose each \u201cGibonacci\u201d number \\( G_{k+2} \\) is the average of the two previous numbers, \\( G_{k+1} \\) and \\( G_k \\). Then\n    \\[\n    G_{k+2} = \\frac{1}{2} (G_{k+1} + G_k) = \\frac{1}{2} G_{k+1} + \\frac{1}{2} G_k.\n    \\]\n    This can be written as\n    \\[\n    \\begin{pmatrix} G_{k+2} \\\\ G_{k+1} \\end{pmatrix} = A \\begin{pmatrix} G_{k+1} \\\\ G_k \\end{pmatrix},\n    \\]\n    where \\( A \\) is the transformation matrix.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize the Fibonacci matrix by completing \\( S^{-1} \\):\n    \\[\n    \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} \\lambda_1 & \\lambda_2 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix}.\n    \\]\n    Do the multiplication \\( S \\Lambda^k S^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\) to find its second component. This is the \\( k \\)-th Fibonacci number \\( F_k = \\frac{\\lambda_1^k - \\lambda_2^k}{\\lambda_1 - \\lambda_2} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The numbers \\( \\lambda_1^k \\) and \\( \\lambda_2^k \\) satisfy the Fibonacci rule\n    \\[\n    F_{k+2} = F_{k+1} + F_k,\n    \\]\n    where\n    \\[\n    \\lambda_{k+2}^1 = \\lambda_{k+1}^1 + \\lambda_k^1 \\quad \\text{and} \\quad \\lambda_{k+2}^2 = \\lambda_{k+1}^2 + \\lambda_k^2.\n    \\]\n    Prove this by using the original equation for the \\( \\lambda \\)\u2019s (multiply it by \\( \\lambda_k \\)). Then any combination of \\( \\lambda_1^k \\) and \\( \\lambda_2^k \\) satisfies the rule. The combination\n    \\[\n    F_k = \\frac{\\lambda_1^k - \\lambda_2^k}{\\lambda_1 - \\lambda_2}\n    \\]\n    gives the right start of \\( F_0 = 0 \\) and \\( F_1 = 1 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Lucas started with \\( L_0 = 2 \\) and \\( L_1 = 1 \\). The rule \\( L_{k+2} = L_{k+1} + L_k \\) is the same, so \\( A \\) is still Fibonacci\u2019s matrix. Add its eigenvectors \\( \\mathbf{x_1} + \\mathbf{x_2} \\):\n    \\[\n    \\begin{pmatrix} \\lambda_1 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} \\lambda_2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2}(1+\\sqrt{5}) \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2}(1-\\sqrt{5}) \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.\n    \\]\n    Multiplying by \\( A^k \\), the second component is \\( L_k = \\lambda_1^k + \\lambda_2^k \\). Compute the Lucas number \\( L_{10} \\) slowly by \\( L_{k+2} = L_{k+1} + L_k \\), and compute approximately by \\( \\lambda_1^{10} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose there is an epidemic in which every month half of those who are well become sick, and a quarter of those who are sick become dead. Find the steady state for the corresponding Markov process:\n    \\[\n    \\begin{pmatrix} d_{k+1} \\\\ s_{k+1} \\\\ w_{k+1} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} & 0 & 0 \\\\ \\frac{1}{2} & \\frac{3}{4} & 0 \\\\ 0 & \\frac{1}{2} & 1 \\end{pmatrix} \\begin{pmatrix} d_k \\\\ s_k \\\\ w_k \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write the 3 by 3 transition matrix for a chemistry course that is taught in two sections, if every week \\( \\frac{1}{4} \\) of those in Section A and \\( \\frac{1}{3} \\) of those in Section B drop the course, and \\( \\frac{1}{6} \\) of each section transfer to the other section."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the limiting values of \\( y_k \\) and \\( z_k \\) as \\( k \\to \\infty \\) if\n    \\[\n    y_{k+1} = 0.8 y_k + 0.3 z_k, \\quad y_0 = 0\n    \\]\n    \\[\n    z_{k+1} = 0.2 y_k + 0.7 z_k, \\quad z_0 = 5.\n    \\]\n    Also, find formulas for \\( y_k \\) and \\( z_k \\) from \\( A^k = S \\Lambda^k S^{-1} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) From the fact that column 1 + column 2 = 2(column 3), so the columns are linearly dependent, find one eigenvalue and one eigenvector of \\( A \\):\n    \\[\n    A = \\begin{pmatrix} 0.2 & 0.4 & 0.3 \\\\ 0.4 & 0.2 & 0.3 \\\\ 0.4 & 0.4 & 0.4 \\end{pmatrix}.\n    \\]\n    (b) Find the other eigenvalues of \\( A \\) (it is Markov). \n    (c) If \\( u_0 = \\begin{pmatrix} 0 \\\\ 10 \\\\ 0 \\end{pmatrix} \\), find the limit of \\( A^k u_0 \\) as \\( k \\to \\infty \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose there are three major centers for Move-It-Yourself trucks. Every month half of those in Boston and in Los Angeles go to Chicago, the other half stay where they are, and the trucks in Chicago are split equally between Boston and Los Angeles. Set up the 3 by 3 transition matrix \\( A \\), and find the steady state \\( u_\\infty \\) corresponding to the eigenvalue \\( \\lambda = 1 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) In what range of \\( a \\) and \\( b \\) is the following equation a Markov process?\n    \\[\n    u_{k+1} = A u_k = \\begin{pmatrix} a & b \\\\ 1-a & 1-b \\end{pmatrix} u_k, \\quad u_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n    \\]\n    (b) Compute \\( u_k = S \\Lambda^k S^{-1} u_0 \\) for any \\( a \\) and \\( b \\).\n    (c) Under what condition on \\( a \\) and \\( b \\) does \\( u_k \\) approach a finite limit as \\( k \\to \\infty \\), and what is the limit? Does \\( A \\) have to be a Markov matrix?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Multinational companies in the Americas, Asia, and Europe have assets of \\$4 trillion. At the start, \\$2 trillion are in the Americas and \\$2 trillion in Europe. Each year \\( \\frac{1}{2} \\) of the American money stays home, and \\( \\frac{1}{4} \\) goes to each of Asia and Europe. For Asia and Europe, \\( \\frac{1}{2} \\) stays home and \\( \\frac{1}{2} \\) is sent to the Americas.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the matrix \\( A \\) that gives\n        \\[\n        \\begin{pmatrix} \\text{Americas}_{k+1} \\\\ \\text{Asia}_{k+1} \\\\ \\text{Europe}_{k+1} \\end{pmatrix} = A \\begin{pmatrix} \\text{Americas}_k \\\\ \\text{Asia}_k \\\\ \\text{Europe}_k \\end{pmatrix}.\n        \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of \\( A \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the limiting distribution of the \\$4 trillion as the world ends."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the distribution of the \\$4 trillion at year \\( k \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A \\) is a Markov matrix, show that the sum of the components of \\( A \\mathbf{x} \\) equals the sum of the components of \\( \\mathbf{x} \\). Deduce that if \\( A \\mathbf{x} = \\lambda \\mathbf{x} \\) with \\( \\lambda \\neq 1 \\), the components of the eigenvector add to zero."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The solution to \\( \\frac{du}{dt} = A u \\) with\n    \\[\n    A = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix},\n    \\]\n    where the eigenvalues are \\( i \\) and \\( -i \\), goes around in a circle:\n    \\[\n    u = (\\cos t, \\sin t).\n    \\]\n    Suppose we approximate \\( \\frac{du}{dt} \\) by forward, backward, and centered differences:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(F) \\( u_{n+1} - u_n = A u_n \\) or \\( u_{n+1} = (I + A) u_n \\) (this is Euler\u2019s method)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(B) \\( u_{n+1} - u_n = A u_{n+1} \\) or \\( u_{n+1} = (I - A)^{-1} u_n \\) (backward Euler)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(C) \\( u_{n+1} - u_n = \\frac{1}{2} A (u_{n+1} + u_n) \\) or \\( u_{n+1} = (I - \\frac{1}{2} A)^{-1} (I + \\frac{1}{2} A) u_n \\).\n    \\end{itemize}\n    Find the eigenvalues of \\( I + A \\), \\( (I - A)^{-1} \\), and \\( (I - \\frac{1}{2} A)^{-1} (I + \\frac{1}{2} A) \\). For which difference equation does the solution \\( u_n \\) stay on a circle?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What values of \\( \\alpha \\) produce instability in\n    \\[\n    v_{n+1} = \\alpha (v_n + w_n), \\quad w_{n+1} = \\alpha (v_n + w_n)?\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the largest values of \\( a \\), \\( b \\), and \\( c \\) for which these matrices are stable or neutrally stable:\n    \\[\n    \\begin{pmatrix} a & -0.8 \\\\ 0.8 & 0.2 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} b & 0.8 \\\\ 0 & 0.2 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 0.8 & 0.2 \\\\ c & 0.8 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Multiplying term by term, check that \\( (I - A)(I + A + A^2 + \\cdots) = I \\). This series represents \\( (I - A)^{-1} \\). It is nonnegative when \\( A \\) is nonnegative, provided it has a finite sum; the condition for that is \\( \\lambda_{\\text{max}} < 1 \\). Add up the infinite series and confirm that it equals \\( (I - A)^{-1} \\), for the consumption matrix\n    \\[\n    A = \\begin{pmatrix} 0 & 1 & 1 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix},\n    \\]\n    which has \\( \\lambda_{\\text{max}} = 0 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For \\( A = \\begin{pmatrix} 0 & 0.2 \\\\ 0 & 0.5 \\end{pmatrix} \\), find the powers \\( A^k \\) (including \\( A^0 \\)) and show explicitly that their sum agrees with \\( (I - A)^{-1} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Explain by mathematics or economics why increasing the \u201cconsumption matrix\u201d \\( A \\) must increase \\( t_{\\text{max}} = \\lambda_1 \\) (and slow down the expansion)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What are the limits as \\( k \\to \\infty \\) (the steady states) of the following?\n    \\[\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize \\( A = \\begin{pmatrix} 3 & 2 \\\\ 2 & 3 \\end{pmatrix} \\) and compute \\( S \\Lambda^k S^{-1} \\) to prove this formula for \\( A^k \\):\n    \\[\n    A^k = \\frac{1}{2} \\begin{pmatrix} 5^{k+1} & 5^k - 1 \\\\ 5^k - 1 & 5^{k+1} \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize \\( B = \\begin{pmatrix} 3 & 1 \\\\ 0 & 2 \\end{pmatrix} \\) and compute \\( S \\Lambda^k S^{-1} \\) to prove this formula for \\( B^k \\):\n    \\[\n    B^k = \\begin{pmatrix} 3^k & 3^k - 2^k \\\\ 0 & 2^k \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The eigenvalues of \\( A \\) are 1 and 9, and the eigenvalues of \\( B \\) are \\( -1 \\) and 9:\n    \\[\n    A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix}, \\quad\n    B = \\begin{pmatrix} 4 & 5 \\\\ 5 & 4 \\end{pmatrix}.\n    \\]\n    Find a matrix square root of \\( A \\) from \\( R = S \\sqrt{\\Lambda} S^{-1} \\). Why is there no real matrix square root of \\( B \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( A \\) and \\( B \\) have the same eigenvalues with the same full set of independent eigenvectors, their factorizations into \\( A = S \\Lambda_1 S^{-1} \\) and \\( B = S \\Lambda_2 S^{-1} \\) are the same. So, \\( A = B \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A \\) and \\( B \\) have the same full set of eigenvectors, so that \\( A = S \\Lambda_1 S^{-1} \\) and \\( B = S \\Lambda_2 S^{-1} \\). Prove that \\( AB = BA \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "When do the eigenvectors for \\( \\lambda = 0 \\) span the nullspace \\( N(A) \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "When do all the eigenvectors for \\( \\lambda \\neq 0 \\) span the column space \\( C(A) \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The powers \\( A^k \\) approach zero if all \\( |\\lambda_i| < 1 \\), and they blow up if any \\( |\\lambda_i| > 1 \\). Peter Lax gives four striking examples in his book *Linear Algebra*:\n    \\[\n    A = \\begin{pmatrix} 3 & 2 \\\\ 1 & 4 \\end{pmatrix}, \\quad\n    B = \\begin{pmatrix} 3 & 2 \\\\ -5 & -3 \\end{pmatrix}, \\quad\n    C = \\begin{pmatrix} 5 & 7 \\\\ -3 & -4 \\end{pmatrix}, \\quad\n    D = \\begin{pmatrix} 5 & 6.9 \\\\ -3 & -4 \\end{pmatrix}.\n    \\]\n    \\[\n     ||A^{1024}|| \\approx 10^{700}, \\quad B^{1024} = I, \\quad C^{1024} = -C, \\quad ||D^{1024}||\\approx 10^{-78}.\n\n    \\]\n    Find the eigenvalues \\( \\lambda = e^{i\\theta} \\) of \\( B \\) and \\( C \\) to show that \\( B^4 = I \\) and \\( C^3 = -I \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Following the first example in this section, find the eigenvalues and eigenvectors, and the exponential $e^{At}$, for \n    \\[\n    A = \\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the previous matrix, write the general solution to $\\frac{du}{dt} = Au$, and the specific solution that matches $u(0) = \\begin{bmatrix}3 \\\\ 1\\end{bmatrix}$. What is the steady state as $t \\to \\infty$? (This is a continuous Markov process; $\\lambda = 0$ in a differential equation corresponds to $\\lambda = 1$ in a difference equation, since $e^{0t} = 1$.)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose the time direction is reversed to give the matrix $-A$:\n    \\[\n    \\frac{du}{dt} = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} u \\quad \\text{with} \\quad u(0) = \\begin{bmatrix}3 \\\\ 1\\end{bmatrix}.\n    \\]\n    Find $u(t)$ and show that it blows up instead of decaying as $t \\to \\infty$. (Diffusion is irreversible, and the heat equation cannot run backward.)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $P$ is a projection matrix, show from the infinite series that\n    \\[\n    e^P \\approx I + 1.718P.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A diagonal matrix like $\\Lambda = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}$ satisfies the usual rule $e^{\\Lambda(t+T)} = e^{\\Lambda t} e^{\\Lambda T}$, because the rule holds for each diagonal entry.\n    \n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The higher-order equation $y'' + y = 0$ can be written as a first-order system by introducing the velocity $y'$ as another unknown:\n    \\[\n    \\frac{d}{dt} \\begin{bmatrix} y \\\\ y' \\end{bmatrix} = \\begin{bmatrix} y' \\\\ y'' \\end{bmatrix} = \\begin{bmatrix} y' \\\\ -y \\end{bmatrix}.\n    \\]\n    If this is $\\frac{du}{dt} = Au$, what is the $2 \\times 2$ matrix $A$? Find its eigenvalues and eigenvectors, and compute the solution that starts from $y(0) = 2, y'(0) = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Convert $y'' = 0$ to a first-order system $\\frac{du}{dt} = Au$:\n    \\[\n    \\frac{d}{dt} \\begin{bmatrix} y \\\\ y' \\end{bmatrix} = \\begin{bmatrix} y' \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} y \\\\ y' \\end{bmatrix}.\n    \\]\n    This $2 \\times 2$ matrix $A$ has only one eigenvector and cannot be diagonalized. Compute $e^{At}$ from the series $I + At + \\dots$ and write the solution $e^{At} u(0)$ starting from $y(0) = 3, y'(0) = 4$. Check that your $(y, y')$ satisfies $y'' = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose the rabbit population $r$ and the wolf population $w$ are governed by\n    \\[\n    \\frac{dr}{dt} = 4r - 2w, \\quad \\frac{dw}{dt} = r + w.\n    \\]\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Decide the stability of $u' = Au$ for the following matrices:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Decide on the stability or instability of $\\frac{dv}{dt} = w$, $\\frac{dw}{dt} = v$. Is there a solution that decays?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "From their trace and determinant, at what time $t$ do the following matrices change between stable with real eigenvalues, stable with complex eigenvalues, and unstable?\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A_1 = \\begin{bmatrix} 1 & -1 \\\\ t & -1 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A_2 = \\begin{bmatrix} 0 & 4 - t \\\\ 1 & -2 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A_3 = \\begin{bmatrix} t & -1 \\\\ 1 & t \\end{bmatrix}$\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors for\n    \\[\n        \\frac{du}{dt} = Au = \\begin{bmatrix} 0 & 3 & 0 \\\\ -3 & 0 & 4 \\\\ 0 & -4 & 0 \\end{bmatrix} u.\n    \\]\n    Why do you know, without computing, that $e^{At}$ will be an orthogonal matrix and $||u(t)||^2 = u_1^2 + u_2^2 + u_3^2$ will be constant?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the skew-symmetric equation\n    \\[\n        \\frac{du}{dt} = Au = \\begin{bmatrix} 0 & c & -b \\\\ -c & 0 & a \\\\ b & -a & 0 \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\\\ u_3 \\end{bmatrix},\n    \\]\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What are the eigenvalues $\\lambda$ and frequencies $\\omega$, and the general solution, of the following equation?\n    \\[\n        \\frac{d^2 u}{dt^2} = \\begin{bmatrix} -5 & 4 \\\\ 4 & -5 \\end{bmatrix} u.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve the second-order equation\n    \\[\n        \\frac{d^2 u}{dt^2} = \\begin{bmatrix} -5 & -1 \\\\ -1 & -5 \\end{bmatrix} u\n    \\]\n    with $u(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ and $u'(0) = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "In most applications, the second-order equation looks like $M u'' + K u = 0$, with a mass matrix multiplying the second derivatives. Substitute the pure exponential $u = e^{i \\omega t} x$ and find the \u201cgeneralized eigenvalue problem\u201d that must be solved for the frequency $\\omega$ and the vector $x$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "With a friction matrix $F$ in the equation $u'' + F u' - A u = 0$, substitute a pure exponential $u = e^{\\lambda t} x$ and find a quadratic eigenvalue problem for $\\lambda$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For equation (16) in the text, with $\\omega = 1$ and $\\sqrt{3}$, find the motion if the first mass is hit at $t = 0$; $u(0) = (0,0)$ and $u'(0) = (1,0)$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Every $2 \\times 2$ matrix with trace zero can be written as\n    \\[\n        A = \\begin{bmatrix} a & b+c \\\\ b-c & -a \\end{bmatrix}.\n    \\]\n    Show that its eigenvalues are real exactly when $a^2 + b^2 \\geq c^2$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "By back-substitution or by computing eigenvectors, solve\n    \\[\n        \\frac{du}{dt} = \\begin{bmatrix} 1 & 2 & 1 \\\\ 0 & 3 & 6 \\\\ 0 & 0 & 4 \\end{bmatrix} u\n    \\]\n    with $u(0) = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find $\\lambda$'s and $x$'s so that $u = e^{\\lambda t} x$ solves\n    \\[\n        \\frac{du}{dt} = \\begin{bmatrix} 4 & 3 \\\\ 0 & 1 \\end{bmatrix} u.\n    \\]\n    What combination $u = c_1 e^{\\lambda_1 t} x_1 + c_2 e^{\\lambda_2 t} x_2$ starts from $u(0) = (5, -2)$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve Problem 21 for $u(t) = (y(t),z(t))$ by back-substitution:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "First solve $\\frac{dz}{dt} = z$, starting from $z(0) = -2$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Then solve $\\frac{dy}{dt} = 4y+3z$, starting from $y(0) = 5$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The solution for $y$ will be a combination of $e^{4t}$ and $e^{t}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find $A$ to change $y'' = 5y' +4y$ into a vector equation for $u(t) = (y(t),y'(t))$:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\frac{du}{dt} = \\begin{bmatrix} y' \\\\ y'' \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 4 & 5 \\end{bmatrix} \\begin{bmatrix} y \\\\ y' \\end{bmatrix} = Au.$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What are the eigenvalues of $A$? Find them also by substituting $y = e^{\\lambda t}$ into the scalar equation $y'' = 5y' +4y$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A door is opened between rooms that hold $v(0) = 30$ people and $w(0) = 10$ people.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The movement between rooms is proportional to the difference $v-w$: \\[ \\frac{dv}{dt} = w-v, \\quad \\frac{dw}{dt} = v-w. \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the total $v+w$ is constant (40 people)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the matrix in $\\frac{du}{dt} = Au$, and its eigenvalues and eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What are $v$ and $w$ at $t = 1$?\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Reverse the diffusion of people in Problem 24 to $\\frac{du}{dt} = -Au$:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\frac{dv}{dt} = v-w$, $\\frac{dw}{dt} = w-v$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The total $v+w$ still remains constant."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "How are the $\\lambda$'s changed now that $A$ is changed to $-A$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that $v(t)$ grows to infinity from $v(0) = 30$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The solution to $y'' = 0$ is a straight line $y = C +Dt$. Convert to a matrix equation:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\frac{d}{dt} \\begin{bmatrix} y \\\\ y' \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} y \\\\ y' \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Compute $e^{At} = I +At + \\frac{1}{2} A^2 t^2 + \\dots$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Multiply your $e^{At}$ times $(y(0),y'(0))$ to check the straight line $y(t) = y(0) + y'(0)t$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Substitute $y = e^{\\lambda t}$ into $y'' = 6y' - 9y$ to show that $\\lambda = 3$ is a repeated root.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Convert to matrix equation: \\[ \\frac{d}{dt} \\begin{bmatrix} y \\\\ y' \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ -9 & 6 \\end{bmatrix} \\begin{bmatrix} y \\\\ y' \\end{bmatrix}. \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that this matrix has $\\lambda = 3,3$ and only one line of eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the second solution is $y = te^{3t}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Figure out how to write $my'' + by' + ky = 0$ as a vector equation $Mu' = Au$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find two familiar functions that solve the equation $\\frac{d^2 y}{dt^2} = -y$.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Which one starts with $y(0) = 1$ and $y'(0) = 0$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Convert to a vector equation: \\[ \\frac{du}{dt} = Au, \\quad A = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}. \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve Problem 6 again using this formulation.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A particular solution to $\\frac{du}{dt} = Au - b$ is $u_p = A^{-1}b$, if $A$ is invertible. The solutions to $\\frac{du}{dt} = Au$ give $u_n$. Find the complete solution $u_p + u_n$ to:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\frac{du}{dt} = 2u - 8$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\frac{du}{dt} = \\begin{bmatrix} 2 & 0 \\\\ 0 & 3 \\end{bmatrix} u - \\begin{bmatrix} 8 \\\\ 6 \\end{bmatrix}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $c$ is not an eigenvalue of $A$, substitute $u = e^{ct}v$ and find $v$ to solve $\\frac{du}{dt} = Au - e^{ct}b$. This $u = e^{ct}v$ is a particular solution. How does it break down when $c$ is an eigenvalue?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a matrix $A$ to illustrate each of the unstable regions in Figure 5.2:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\lambda_1 < 0$ and $\\lambda_2 > 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\lambda_1 > 0$ and $\\lambda_2 > 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Complex $\\lambda$'s with real part $a > 0$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write five terms of the infinite series for $e^{At}$. Take the $t$ derivative of each term. Show that you have four terms of $Ae^{At}$. Conclusion: $e^{At}u(0)$ solves $u' = Au$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The matrix $B = \\begin{bmatrix} 0 & -1 \\\\ 0 & 0 \\end{bmatrix}$ has $B^2 = 0$. Find $e^{Bt}$ from a (short) infinite series. Check that the derivative of $e^{Bt}$ is $Be^{Bt}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Starting from $u(0)$, the solution at time $T$ is $e^{AT} u(0)$. Go an additional time $t$ to reach $e^{At}(e^{AT} u(0))$. This solution at time $t + T$ can also be written as $e^{A(t+T)}$. Conclusion: $e^{At} e^{AT} = e^{A(t+T)}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$ in the form $S\\Lambda S^{-1}$. Find $e^{At}$ from $S e^{\\Lambda t} S^{-1}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A^2 = A$, show that the infinite series produces $e^{At} = I + (e^t -1)A$. For $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$ in Problem 36, this gives $e^{At}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Generally, $e^A e^B$ is different from $e^B e^A$. They are both different from $e^{A+B}$. Check this using Problems 36--37 and 34:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$B = \\begin{bmatrix} 0 & -1 \\\\ 0 & 0 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A+B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 3 \\end{bmatrix}$ as $S\\Lambda S^{-1}$. Multiply $S e^{\\Lambda t} S^{-1}$ to find the matrix exponential $e^{At}$. Check $e^{At} = I$ when $t = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Put $A = \\begin{bmatrix} 1 & 3 \\\\ 0 & 0 \\end{bmatrix}$ into the infinite series to find $e^{At}$. First compute $A^2$:\n    \\[\n    e^{At} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} + \\begin{bmatrix} t & 3t \\\\ 0 & 0 \\end{bmatrix} + \\frac{1}{2} \\begin{bmatrix} ? & ? \\\\ ? & ? \\end{bmatrix} + \\cdots = \\begin{bmatrix} e^t & 0 \\\\ 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Give two reasons why the matrix exponential $e^{At}$ is never singular:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) Write its inverse."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) Write its eigenvalues. If $Ax = \\lambda x$ then $e^{At}x = e^{\\lambda t} x$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a solution $x(t), y(t)$ of the first system that gets large as $t \\to \\infty$. To avoid this instability a scientist thought of exchanging the two equations!\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Original system:\n        \\[\n        \\frac{dx}{dt} = 0x - 4y, \\quad \\frac{dy}{dt} = -2x + 2y.\n        \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Exchanged system:\n        \\[\n        \\frac{dy}{dt} = -2x + 2y, \\quad \\frac{dx}{dt} = 0x - 4y.\n        \\]\n    \\end{itemize}\n    Now the matrix $\\begin{bmatrix} -2 & 2 \\\\ 0 & -4 \\end{bmatrix}$ is stable. It has $\\lambda < 0$. Comment on this craziness."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "From this general solution to $\\frac{du}{dt} = Au$, find the matrix $A$:\n    \\[\n    u(t) = c_1 e^{2t} \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + c_2 e^{5t} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the complex numbers \\( 3 + 4i \\) and \\( 1 - i \\),\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find their positions in the complex plane."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find their sum and product."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find their conjugates and their absolute values."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Do the original numbers lie inside or outside the unit circle?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What can you say about\n    \\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The sum of a complex number and its conjugate?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The conjugate of a number on the unit circle?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The product of two numbers on the unit circle?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The sum of two numbers on the unit circle?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( x = 2 + i \\) and \\( y = 1 + 3i \\), find \\( x \\), \\( x^2 \\), \\( \\frac{1}{x} \\), and \\( \\frac{x}{y} \\). Check that the absolute value \\( |xy| \\) equals \\( |x| \\) times \\( |y| \\), and the absolute value \\( \\left| \\frac{1}{x} \\right| \\) equals \\( \\frac{1}{|x|} \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find \\( a \\) and \\( b \\) for the complex numbers \\( a + ib \\) at the angles \\( \\theta = 30^\\circ, 60^\\circ, 90^\\circ \\) on the unit circle. Verify by direct multiplication that the square of the first is the second, and the cube of the first is the third."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If \\( x = re^{i\\theta} \\), what are \\( x^2 \\), \\( x^{-1} \\), and \\( x \\) in polar coordinates? Where are the complex numbers that have \\( x^{-1} = x \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "At \\( t = 0 \\), the complex number \\( e^{(-1 + i)t} \\) equals one. Sketch its path in the complex plane as \\( t \\) increases from \\( 0 \\) to \\( 2\\pi \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the lengths and the inner product of\n    \\[\n    x = \\begin{bmatrix} 2 - 4i \\\\ 4i \\end{bmatrix}, \\quad y = \\begin{bmatrix} 2 + 4i \\\\ 4i \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write out the matrix \\( A^H \\) and compute \\( C = A^H A \\) if\n    \\[\n    A = \\begin{bmatrix} 1 & i & 0 \\\\ i & 0 & 1 \\end{bmatrix}.\n    \\]\n    What is the relation between \\( C \\) and \\( C^H \\)? Does it hold whenever \\( C \\) is constructed from some \\( A^H A \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "With the preceding \\( A \\), use elimination to solve \\( Ax = 0 \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the nullspace you just computed is orthogonal to \\( C(A^H) \\) and not to the usual row space \\( C(A^T) \\). The four fundamental spaces in the complex case are \\( N(A) \\) and \\( C(A) \\) as before, and then \\( N(A^H) \\) and \\( C(A^H) \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "How is the determinant of \\( A^H \\) related to the determinant of \\( A \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that the determinant of any Hermitian matrix is real."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "How many degrees of freedom are there in a real symmetric matrix, a real diagonal matrix, and a real orthogonal matrix? The first answer is the sum of the other two, because \\( A = Q \\Lambda Q^T \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that \\( 3 \\times 3 \\) Hermitian matrices \\( A \\) and also unitary \\( U \\) have 9 real degrees of freedom (columns of \\( U \\) can be multiplied by any \\( e^{i\\theta} \\))."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write \\( P \\), \\( Q \\), and \\( R \\) in the form \\( \\lambda_1 x_1 x_1^H + \\lambda_2 x_2 x_2^H \\) of the spectral theorem:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( P = \\begin{bmatrix} 1 & 2 \\\\ 1 & 2 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( Q = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( R = \\begin{bmatrix} 3 & 4 \\\\ 4 & -3 \\end{bmatrix} \\)\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Give a reason if true or a counterexample if false:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) If \\( A \\) is Hermitian, then \\( A + iI \\) is invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) If \\( Q \\) is orthogonal, then \\( Q^{+1/2} I \\) is invertible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) If \\( A \\) is real, then \\( A + iI \\) is invertible.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose \\( A \\) is a symmetric \\( 3 \\times 3 \\) matrix with eigenvalues 0, 1, 2.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) What properties can be guaranteed for the corresponding unit eigenvectors \\( u \\), \\( v \\), \\( w \\)?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) In terms of \\( u \\), \\( v \\), \\( w \\), describe the nullspace, left nullspace, row space, and column space of \\( A \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) Find a vector \\( x \\) that satisfies \\( A x = v + w \\). Is \\( x \\) unique?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(d) Under what conditions on \\( b \\) does \\( A x = b \\) have a solution?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(e) If \\( u \\), \\( v \\), \\( w \\) are the columns of \\( S \\), what are \\( S^{-1} \\) and \\( S^{-1} A S \\)?\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "In the list below, which classes of matrices contain \\( A \\) and which contain \\( B \\)?\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( A = \\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\( B = \\frac{1}{4} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{bmatrix} \\)\n    \\end{itemize}\n    Classes to check: Orthogonal, invertible, projection, permutation, Hermitian, rank-1, diagonalizable, Markov.\n    Find the eigenvalues of \\( A \\) and \\( B \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What is the dimension of the space \\( S \\) of all \\( n \\times n \\) real symmetric matrices? The spectral theorem says that every symmetric matrix is a combination of \\( n \\) projection matrices. Since the dimension exceeds \\( n \\), how is this difference explained?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write one significant fact about the eigenvalues of each of the following:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) A real symmetric matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) A stable matrix: all solutions to \\( \\frac{du}{dt} = A u \\) approach zero."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) An orthogonal matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(d) A Markov matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(e) A defective matrix (nondiagonalizable)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(f) A singular matrix.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that if $U$ and $V$ are unitary, so is $UV$. Use the criterion $U^H U = I$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that a unitary matrix has $|\\det U| = 1$, but possibly $\\det U$ is different from $\\det U^H$. Describe all $2 \\times 2$ matrices that are unitary."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a third column so that $U$ is unitary. How much freedom in column 3?\n    \\[\n    U = \\begin{bmatrix} \n    \\frac{1}{\\sqrt{3}} & \\frac{i}{\\sqrt{2}} \\\\\n    \\frac{1}{\\sqrt{3}} & 0 \\\\\n    \\frac{i}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} \n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize the $2 \\times 2$ skew-Hermitian matrix \n    \\[\n    K = \\begin{bmatrix} i & i \\\\ i & i \\end{bmatrix},\n    \\]\n    whose entries are all $\\sqrt{-1}$. Compute $e^{Kt} = S e^{\\Lambda t} S^{-1}$, and verify that $e^{Kt}$ is unitary. What is the derivative of $e^{Kt}$ at $t = 0$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Describe all $3 \\times 3$ matrices that are simultaneously Hermitian, unitary, and diagonal. How many are there?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Every matrix $Z$ can be split into a Hermitian and a skew-Hermitian part, $Z = A + K$, just as a complex number $z$ is split into $a + ib$. The real part of $z$ is half of $z + \\bar{z}$, and the \"real part\" of $Z$ is half of $Z + Z^H$. Find a similar formula for the \"imaginary part\" $K$, and split these matrices into $A+K$:\n    \\[\n    Z = \\begin{bmatrix} 3+i & 4+2i \\\\ 0 & 5 \\end{bmatrix}, \\quad Z = \\begin{bmatrix} i & i \\\\ -i & i \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that the columns of the $4 \\times 4$ Fourier matrix $F$ in Example 5 are eigenvectors of the permutation matrix $P$ in Example 6."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the permutation of Example 6, write out the circulant matrix \n    \\[\n    C = c_0 I + c_1 P + c_2 P^2 + c_3 P^3.\n    \\]\n    (Its eigenvector matrix is again the Fourier matrix.) Write out also the four components of the matrix-vector product $Cx$, which is the convolution of $c = (c_0, c_1, c_2, c_3)$ and $x = (x_0, x_1, x_2, x_3)$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For a circulant $C = F \\Lambda F^{-1}$, why is it faster to multiply by $F^{-1}$, then $\\Lambda$, then $F$ (the convolution rule), than to multiply directly by $C$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the lengths of $u = (1+i, 1-i, 1+2i)$ and $v = (i, i, i)$. Also find $u^H v$ and $v^H u$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that $A^H A$ is always a Hermitian matrix. Compute $A^H A$ and $A A^H$:\n    \\[\n    A = \\begin{bmatrix} i & 1 & i \\\\ 1 & i & i \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A z = 0$, then $A^H A z = 0$. If $A^H A z = 0$, multiply by $z^H$ to prove that $A z = 0$. The nullspaces of $A$ and $A^H A$ are \\dots $A^H A$ is an invertible Hermitian matrix when the nullspace of $A$ contains only $z = \\dots$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "When you multiply a Hermitian matrix by a real number $c$, is $cA$ still Hermitian? If $c = i$, show that $iA$ is skew-Hermitian. The $3 \\times 3$ Hermitian matrices form a subspace, provided that the \u201cscalars\u201d are real numbers."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Which classes of matrices does $P$ belong to: orthogonal, invertible, Hermitian, unitary, factorizable into LU, factorizable into QR?\n    \\[\n    P = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Compute $P^2$, $P^3$, and $P^{100}$ in Problem 30. What are the eigenvalues of $P$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the unit eigenvectors of $P$ in Problem 30, and put them into the columns of a unitary matrix $U$. What property of $P$ makes these eigenvectors orthogonal?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Write down the $3 \\times 3$ circulant matrix $C = 2I + 5P + 4P^2$. It has the same eigenvectors as $P$ in Problem 30. Find its eigenvalues."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $U$ is unitary and $Q$ is a real orthogonal matrix, show that $U^{-1}$ is unitary and also $UQ$ is unitary. Start from $U^H U = I$ and $Q^T Q = I$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize $A$ (real $\\lambda$\u2019s) and $K$ (imaginary $\\lambda$\u2019s) to reach $U \\Lambda U^H$:\n    \\[\n    A = \\begin{bmatrix} 0 & 1-i \\\\ i+1 & 1 \\end{bmatrix}, \\quad K = \\begin{bmatrix} 0 & -1+i \\\\ 1+i & i \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize this orthogonal matrix to reach $Q = U \\Lambda U^H$. Now all $\\lambda$\u2019s are:\n    \\[\n    Q = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize this unitary matrix $V$ to reach $V = U \\Lambda U^H$. Again all $|\\lambda| = 1$:\n    \\[\n    V = \\frac{1}{\\sqrt{3}} \\begin{bmatrix} 1 & 1-i \\\\ 1+i & -1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $v_1,\\dots,v_n$ is an orthonormal basis for $\\mathbb{C}^n$, the matrix with those columns is a unitary matrix. Show that any vector $z$ equals $(v_1^H z)v_1 + \\dots + (v_n^H z)v_n$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The functions $e^{-ix}$ and $e^{-ix}$ are orthogonal on the interval $0 \\leq x \\leq 2\\pi$ because their complex inner product is $\\int_0^{2\\pi} e^{-ix} e^{ix}dx = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The vectors $v = (1,i,1)$, $w = (i,1,0)$ and $z = \\begin{bmatrix} a & b & c \\end{bmatrix}^T$ are an orthogonal basis for $\\mathbb{C}^n$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A = R + iS$ is a Hermitian matrix, are the real matrices $R$ and $S$ symmetric?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The (complex) dimension of $\\mathbb{C}^n$ is $n$. Find a nonreal basis for $\\mathbb{C}^n$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Describe all $1 \\times 1$ matrices that are Hermitian and also unitary. Do the same for $2 \\times 2$ matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "How are the eigenvalues of $A^H$ (square matrix) related to the eigenvalues of $A$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $u^H u = 1$, show that $I -2uu^H$ is Hermitian and also unitary. The rank-1 matrix $uu^H$ is the projection onto what line in $\\mathbb{C}^n$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A+iB$ is a unitary matrix ($A$ and $B$ are real), show that \n    \\[\n        Q = \\begin{bmatrix} A & -B \\\\ B & A \\end{bmatrix}\n    \\]\n    is an orthogonal matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A+iB$ is a Hermitian matrix ($A$ and $B$ are real), show that \n    \\[\n        \\begin{bmatrix} A & -B \\\\ B & A \\end{bmatrix}\n    \\]\n    is symmetric."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that the inverse of a Hermitian matrix is again a Hermitian matrix."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Diagonalize this matrix by constructing its eigenvalue matrix $\\Lambda$ and its eigenvector matrix $S$:\n    \\[\n        A = \\begin{bmatrix} 2 & 1-i \\\\ 1+i & 3 \\end{bmatrix} = A^H.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A matrix with orthonormal eigenvectors has the form $A = U\\Lambda U^{-1} = U\\Lambda U^H$. Prove that $AA^H = A^H A$. These are exactly the normal matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $B$ is similar to $A$ and $C$ is similar to $B$, show that $C$ is similar to $A$. (Let $B = M^{-1}AM$ and $C = N^{-1}BN$.) Which matrices are similar to $I$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Describe in words all matrices that are similar to $\\begin{bmatrix}1 & 0 \\\\ 0 & -1\\end{bmatrix}$, and find two of them."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Explain why $A$ is never similar to $A+I$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a diagonal $M$, made up of $1$s and $-1$s, to show that\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A = \\begin{bmatrix} 2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "is similar to $B = \\begin{bmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{bmatrix}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show (if $B$ is invertible) that $BA$ is similar to $AB$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider any $A$ and a \u201cGivens rotation\u201d $M$ in the 1\u20132 plane:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix}$, $M = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta & 0 \\\\ \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Choose the rotation angle $\\theta$ to produce zero in the $(3,1)$ entry of $M^{-1}AM$.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What matrix $M$ changes the basis $V_1 = (1,1)$, $V_2 = (1,4)$ to the basis $v_1 = (2,5)$, $v_2 = (1,4)$? The columns of $M$ come from expressing $V_1$ and $V_2$ as combinations $\\sum m_{ij} v_j$ of the $v$\u2019s."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the same two bases, express the vector $(3,9)$ as a combination $c_1V_1 + c_2V_2$ and also as $d_1v_1 + d_2v_2$. Check numerically that $M$ connects $c$ to $d$: $Mc = d$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Confirm the last exercise: If $V_1 = m_{11}v_1 + m_{21}v_2$ and $V_2 = m_{12}v_1 + m_{22}v_2$, and $m_{11}c_1 + m_{12}c_2 = d_1$ and $m_{21}c_1 + m_{22}c_2 = d_2$, the vectors $c_1V_1 + c_2V_2$ and $d_1v_1 + d_2v_2$ are the same. This is the \u201cchange of basis formula\u201d $Mc = d$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the transformation $T$ is a reflection across the $45^\\circ$ line in the plane, find its matrix with respect to the standard basis $v_1 = (1,0)$, $v_2 = (0,1)$, and also with respect to $V_1 = (1,1)$, $V_2 = (1,-1)$. Show that those matrices are similar."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The identity transformation takes every vector to itself: $Tx = x$. Find the corresponding matrix, if the first basis is $v_1 = (1,2)$, $v_2 = (3,4)$ and the second basis is $w_1 = (1,0)$, $w_2 = (0,1)$. (It is not the identity matrix!)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The derivative of $a + bx + cx^2$ is $b + 2cx + 0x^2$.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that every number is an eigenvalue for $T f(x) = \\frac{d f}{dx}$, but the transformation $T f(x) = \\int_{0}^{x} f(t) dt$ has no eigenvalues (here $-\\infty < x < \\infty$)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "On the space of $2 \\times 2$ matrices, let $T$ be the transformation that transposes every matrix. Find the eigenvalues and \"eigenmatrices\" for $A^T = \\lambda A$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that every unitary matrix $A$ is diagonalizable, in two steps:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a normal matrix ($N N^H = N^H N$) that is not Hermitian, skew-Hermitian, unitary, or diagonal. Show that all permutation matrices are normal."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose $T$ is a $3 \\times 3$ upper triangular matrix, with entries $t_{ij}$. Compare the entries of $T T^H$ and $T^H T$, and show that if they are equal, then $T$ must be diagonal. All normal triangular matrices are diagonal."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $N$ is normal, show that $\\|N x\\| = \\|N^H x\\|$ for every vector $x$. Deduce that the $i$th row of $N$ has the same length as the $i$th column. Note: If $N$ is also upper triangular, this leads again to the conclusion that it must be diagonal."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that a matrix with orthonormal eigenvectors must be normal, as claimed: If $U^{-1} N U = A$, or $N = U \\Lambda U^H$, then $N N^H = N^H N$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find a unitary $U$ and triangular $T$ so that $U^{-1} A U = T$, for \n    \\[\n    A = \\begin{bmatrix} 5 & -3 \\\\ 4 & -2 \\end{bmatrix}, \\quad \n    A = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A$ has eigenvalues $0, 1, 2$, what are the eigenvalues of $A(A - I)(A - 2I)$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The characteristic polynomial of \n    \\[\n    A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\n    \\]\n    is $\\lambda^2 - (a+d)\\lambda + (ad - bc)$. By direct substitution, verify Cayley-Hamilton: \n    \\[\n    A^2 - (a+d)A + (ad - bc)I = 0.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $a_{ij} = 1$ above the main diagonal and $a_{ij} = 0$ elsewhere, find the Jordan form (say $4 \\times 4$) by finding all the eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show, by trying for an $M$ and failing, that no two of the three Jordan forms in equation (8) are similar: \n    \\[\n    J_1 \\neq M^{-1} J_2 M, \\quad J_1 \\neq M^{-1} J_3 M, \\quad \\text{and} \\quad J_2 \\neq M^{-1} J_3 M.\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve $ u' = Ju $ by back-substitution, solving first for $ u_2(t) $:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$ \\frac{du}{dt} = Ju = \\begin{bmatrix} 5 & 1 \\\\ 0 & 5 \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} $ with initial value $ u(0) = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Notice $ te^{5t} $ in the first component $ u_1(t) $.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Compute $ A^{10} $ and $ e^A $ if $ A = MJM^{-1} $:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$ A = \\begin{bmatrix} 14 & 9 \\\\ -16 & -10 \\end{bmatrix} = \\begin{bmatrix} 3 & -2 \\\\ -4 & 3 \\end{bmatrix} \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix} \\begin{bmatrix} 3 & 2 \\\\ 4 & 3 \\end{bmatrix} $.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that $ A $ and $ B $ are similar by finding $ M $ so that $ B = M^{-1}AM $:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) $ A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\end{bmatrix} $ and $ B = \\begin{bmatrix} 0 & 1 \\\\ 0 & 1 \\end{bmatrix} $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) $ A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} $ and $ B = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(c) $ A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} $ and $ B = \\begin{bmatrix} 4 & 3 \\\\ 2 & 1 \\end{bmatrix} $.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Which of these matrices $ A_1 $ to $ A_6 $ are similar? Check their eigenvalues.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$ \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 0 \\\\ 1 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 1 \\\\ 0 & 1 \\end{bmatrix} $.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "There are sixteen $ 2 \\times 2 $ matrices whose entries are 0s and 1s. Similar matrices go into the same family.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "How many families? How many matrices (total 16) in each family?\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(a) If $ x $ is in the nullspace of $ A $, show that $ M^{-1} x $ is in the nullspace of $ M^{-1}AM $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "(b) The nullspaces of $ A $ and $ M^{-1}AM $ have the same (vectors)(basis)(dimension)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $ A $ and $ B $ have exactly the same eigenvalues and eigenvectors, does $ A = B $? With $ n $ independent eigenvectors, we do have $ A = B $. Find $ A \\neq B $ when $ \\lambda = 0,0 $ (repeated), but there is only one line of eigenvectors $ (x_1,0) $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "By direct multiplication, find $ J^2 $ and $ J^3 $ when $ J = \\begin{bmatrix} c & 1 \\\\ 0 & c \\end{bmatrix} $. Guess the form of $ J^k $. Set $ k = 0 $ to find $ J^0 $. Set $ k = -1 $ to find $ J^{-1} $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $ J $ is the $ 5 \\times 5 $ Jordan block with $ \\lambda = 0 $, find $ J^2 $ and count its eigenvectors, and find its Jordan form (two blocks)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "The text solved $ \\frac{du}{dt} = Ju $ for a $ 3 \\times 3 $ Jordan block $ J $. Add a fourth equation $ \\frac{dw}{dt} = 5w + x $. Follow the pattern of solutions for $ z, y, x $ to find $ w $."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "These Jordan matrices have eigenvalues 0, 0, 0, 0. They have two eigenvectors (find them). But the block sizes don\u2019t match and $ J $ is not similar to $ K $:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$ J = \\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix} $,"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$ K = \\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix} $.\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For any matrix $ M $, compare $ JM $ with $ MK $. If they are equal, show that $ M $ is not invertible. Then $ M^{-1} JM = K $ is impossible."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove in three steps that $A^T$ is always similar to $A$ (we know that the $\\lambda$'s are the same, the eigenvectors are the problem):\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Which pairs are similar? Choose $a, b, c, d$ to prove that the other pairs aren\u2019t:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\begin{bmatrix} b & a \\\\ d & c \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\begin{bmatrix} c & d \\\\ a & b \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$\\begin{bmatrix} d & c \\\\ b & a \\end{bmatrix}$\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "True or false, with a good reason:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that $AB$ has the same eigenvalues as $BA$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A$ is $6 \\times 4$ and $B$ is $4 \\times 6$, $AB$ and $BA$ have different sizes. Nevertheless,\n    \\begin{align*}\n        \\begin{bmatrix} I & -A \\\\ 0 & I \\end{bmatrix} \n        \\begin{bmatrix} AB & 0 \\\\ B & 0 \\end{bmatrix} \n        \\begin{bmatrix} I & A \\\\ 0 & I \\end{bmatrix} \n        = \n        \\begin{bmatrix} 0 & 0 \\\\ B & BA \\end{bmatrix} = G.\n    \\end{align*}\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Why is each of these statements true?\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors, and the diagonalizing matrix $S$, for\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$A = \\begin{bmatrix} 1 & 0 \\\\ 2 & 3 \\end{bmatrix}$"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "$B = \\begin{bmatrix} 7 & 2 \\\\ -15 & -4 \\end{bmatrix}$\n    \\end{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the determinants of $A$ and $A^{-1}$ if\n    \\[ A = S \\begin{bmatrix} \\lambda_1 & 2 \\\\ 0 & \\lambda_2 \\end{bmatrix} S^{-1}. \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A$ has eigenvalues 0 and 1, corresponding to the eigenvectors\n    \\[ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\quad \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}, \\]\n    how can you tell in advance that $A$ is symmetric? What are its trace and determinant? What is $A$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "In the previous problem, what will be the eigenvalues and eigenvectors of $A^2$? What is the relation of $A^2$ to $A$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Does there exist a matrix $A$ such that the entire family $A + cI$ is invertible for all complex numbers $c$? Find a real matrix with $A + rI$ invertible for all real $r$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Solve for both initial values and then find $e^{At}$:\n    \\[ \\frac{du}{dt} = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix} u, \\]\n    if $u(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ and if $u(0) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Would you prefer to have interest compounded quarterly at 40\\% per year, or annually at 50\\%?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "True or false (with counterexample if false):\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What happens to the Fibonacci sequence if we go backward in time, and how is $F_{-k}$ related to $F_k$? The law $F_{k+2} = F_{k+1} + F_k$ is still in force, so $F_{-1} = 1$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the general solution to $\\frac{du}{dt} = Au$ if\n    \\[ A = \\begin{bmatrix} 0 & -1 & 0 \\\\ 1 & 0 & -1 \\\\ 0 & 1 & 0 \\end{bmatrix}. \\]\n    Can you find a time $T$ at which the solution $u(T)$ is guaranteed to return to the initial value $u(0)$?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $P$ is the matrix that projects $\\mathbb{R}^n$ onto a subspace $S$, explain why every vector in $S$ is an eigenvector, and so is every vector in $S^{\\perp}$. What are the eigenvalues? (Note the connection to $P^2 = P$, which means that $\\lambda^2 = \\lambda$.)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Show that every matrix of order $> 1$ is the sum of two singular matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the eigenvalues of $A$ are $1$ and $3$ with eigenvectors $\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}$ and $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$, find the solutions to $\\frac{du}{dt} = Au$ and $u_{k+1} = Au_k$, starting from $u = \\begin{bmatrix} 9 \\\\ 4 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Find the eigenvalues and eigenvectors of \n    \\[\n    A = \\begin{bmatrix} 0 & -i & 0 \\\\ i & 1 & i \\\\ 0 & -i & 0 \\end{bmatrix}.\n    \\]\n    What property do you expect for the eigenvectors, and is it true?"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "By trying to solve \n    \\[\n    \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} = A\n    \\]\n    show that $A$ has no square root. Change the diagonal entries of $A$ to $4$ and find a square root."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "True or false, with reason if true and counterexample if false:\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $K$ is a skew-symmetric matrix, show that $Q = (I - K)(I + K)^{-1}$ is an orthogonal matrix. Find $Q$ if $K = \\begin{bmatrix} 0 & 2 \\\\ -2 & 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $K^H = -K$ (skew-Hermitian), the eigenvalues are imaginary and the eigenvectors are orthogonal.\n    \\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $M$ is the diagonal matrix with entries $d, d^2, d^3$, what is $M^{-1}AM$? What are its eigenvalues in the following case?\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $A^2 = -I$, what are the eigenvalues of $A$? If $A$ is a real $n \\times n$ matrix, show that $n$ must be even, and give an example."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If $Ax = \\lambda_1x$ and $A^T y = \\lambda_2y$ (all real), show that $x^T y = 0$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "A variation on the Fourier matrix is the \"sine matrix\":\n    \\[\n    S = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}\n    \\sin \\theta & \\sin 2\\theta & \\sin 3\\theta \\\\\n    \\sin 2\\theta & \\sin 4\\theta & \\sin 6\\theta \\\\\n    \\sin 3\\theta & \\sin 6\\theta & \\sin 9\\theta\n    \\end{bmatrix}\n    \\]\n    with $\\theta = \\frac{\\pi}{4}$. Verify that $S^T = S^{-1}$. (The columns are the eigenvectors of the tridiagonal matrix $-1, 2, -1$.)"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Suppose the first row of $A$ is 7, 6, and its eigenvalues are $i, -i$. Find $A$."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "If the vectors $x_1$ and $x_2$ are in the columns of $S$, what are the eigenvalues and eigenvectors of \n    \\[\n    A = S \\begin{bmatrix} 2 & 0 \\\\ 0 & 1 \\end{bmatrix} S^{-1}\n    \\quad \\text{and} \\quad B = S \\begin{bmatrix} 2 & 3 \\\\ 0 & 1 \\end{bmatrix} S^{-1}?\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "What is the limit as $k \\to \\infty$ (the Markov steady state) of\n    \\[\n    \\begin{bmatrix}\n    0.4 & 0.3 \\\\\n    0.6 & 0.7\n    \\end{bmatrix}^k\n    \\begin{bmatrix}\n    a \\\\\n    b\n    \\end{bmatrix}\n    ?\n    \\]"
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 4 & 1 \\\\ 2 & 3 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\). Determine if \\( A \\) and \\( B \\) are similar matrices. If they are, find the matrix \\( P \\) such that \\( P^{-1}AP = B \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Given the matrix \\( A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} \\), compute the eigenvalues and eigenvectors of \\( A \\), and verify if the matrix is diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 2 & 0 \\\\ 0 & 2 \\end{bmatrix} \\). Show that the two matrices are similar and compute the eigenvalues and eigenvectors of both matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "For the matrix \\( A = \\begin{bmatrix} 5 & 4 \\\\ 1 & 3 \\end{bmatrix} \\), find its eigenvalues and eigenvectors, and then find a similarity transformation that diagonalizes \\( A \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Prove that two similar matrices have the same eigenvalues. Provide an example using \\( A = \\begin{bmatrix} 2 & 1 \\\\ 0 & 2 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 3 & 0 \\\\ 0 & 3 \\end{bmatrix} \\), and compute their eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Given the matrix \\( A = \\begin{bmatrix} 3 & 4 \\\\ 4 & 3 \\end{bmatrix} \\), find its eigenvalues and eigenvectors. Then, determine if \\( A \\) is diagonalizable and find the matrix that diagonalizes it."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the matrix \\( A = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix} \\). Find its eigenvalues and eigenvectors and show that \\( A \\) is not diagonalizable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} \\) and \\( P = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\). Verify that \\( A \\) and \\( P^{-1}AP \\) are similar matrices. Then, compute the eigenvalues and eigenvectors of \\( P^{-1}AP \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 5 & 4 & 2 \\\\ 0 & 3 & 1 \\\\ 0 & 0 & 2 \\end{bmatrix} \\). Compute the Jordan canonical form of \\( A \\) and find the corresponding Jordan chains. Determine the eigenvalues, eigenvectors, and generalized eigenvectors of \\( A \\), and verify the completeness of the Jordan basis."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the matrix \\( A = \\begin{bmatrix} 2 & 1 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix} \\). Find the eigenvalues and eigenvectors of \\( A \\), and then use the algebraic and geometric multiplicities to determine whether \\( A \\) is diagonalizable. If it is not diagonalizable, compute its Jordan canonical form and the Jordan chains associated with each eigenvalue."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 4 & 1 & 0 & 0 \\\\ 0 & 4 & 1 & 0 \\\\ 0 & 0 & 4 & 1 \\\\ 0 & 0 & 0 & 4 \\end{bmatrix} \\). Find the eigenvalues of \\( A \\), and then compute the Jordan canonical form of \\( A \\). Determine whether \\( A \\) is diagonalizable, and if not, find the Jordan basis and describe the structure of the Jordan blocks."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the matrix \\( A = \\begin{bmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\). Find the Jordan canonical form of \\( A \\), and calculate the eigenvalues and eigenvectors of \\( A \\). Show that \\( A \\) is not diagonalizable and compute the generalized eigenvectors that complete the Jordan chains."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 2 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix} \\). Find the eigenvalues, eigenvectors, and generalized eigenvectors of \\( A \\), and compute its Jordan canonical form. Discuss the conditions under which a matrix has a unique Jordan form and the role of the Jordan chains in the diagonalization process. Analyze how the structure of the Jordan blocks affects the transformation properties of \\( A \\)."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the transition matrix \\( P = \\begin{bmatrix} 0.3 & 0.7 \\\\ 0.6 & 0.4 \\end{bmatrix} \\). Find the steady-state vector for this Markov chain by solving for the eigenvector corresponding to the eigenvalue \\( \\lambda = 1 \\). Verify that the steady-state vector is a probability distribution, and explain the significance of the steady-state distribution in the long-term behavior of the chain."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( P = \\begin{bmatrix} 0.5 & 0.5 & 0 \\\\ 0.2 & 0.3 & 0.5 \\\\ 0.3 & 0.2 & 0.5 \\end{bmatrix} \\) be a transition matrix of a Markov chain. Determine the steady-state vector \\( \\mathbf{v} \\) that satisfies \\( P \\mathbf{v} = \\mathbf{v} \\). Solve for the eigenvalue and eigenvector associated with the steady-state, and interpret the meaning of the result in the context of the long-term behavior of the chain."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider a Markov chain with the transition matrix \\( P = \\begin{bmatrix} 0.4 & 0.6 \\\\ 0.5 & 0.5 \\end{bmatrix} \\). Compute the eigenvalue and eigenvector associated with the steady-state solution of the chain. Show that the steady-state distribution is unique and explain how it relates to the long-term behavior of the chain. Additionally, compute the limit of the powers of \\( P \\) as \\( n \\to \\infty \\) and discuss the convergence to the steady state."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( P = \\begin{bmatrix} 0.8 & 0.2 \\\\ 0.1 & 0.9 \\end{bmatrix} \\) represent the transition matrix of a Markov chain. Compute the steady-state vector \\( \\mathbf{v} \\) that satisfies \\( P \\mathbf{v} = \\mathbf{v} \\), and determine the eigenvalue and eigenvector corresponding to this steady state. Analyze how the steady-state distribution evolves over multiple iterations and provide an explanation of the convergence process to the steady state."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the transition matrix \\( P = \\begin{bmatrix} 0.7 & 0.3 & 0 \\\\ 0.2 & 0.6 & 0.2 \\\\ 0 & 0.5 & 0.5 \\end{bmatrix} \\). Find the steady-state vector by solving \\( P \\mathbf{v} = \\mathbf{v} \\). Then, determine the eigenvalue associated with the steady-state and explain its significance. Discuss the convergence properties of the Markov chain and the long-term behavior of the system, including any transient states if applicable."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 4 & 1 & 2 \\\\ 1 & 5 & 3 \\\\ 2 & 3 & 6 \\end{bmatrix} \\) be a symmetric matrix. Compute the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) by finding an orthogonal matrix \\( Q \\) such that \\( Q^T A Q = D \\), where \\( D \\) is the diagonal matrix of eigenvalues. Show that the matrix \\( A \\) is diagonalizable and explain the significance of the orthogonal transformation."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the Hermitian matrix \\( A = \\begin{bmatrix} 3 & 2 - i \\\\ 2 + i & 4 \\end{bmatrix} \\). Find the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) by finding a unitary matrix \\( U \\) such that \\( U^\\dagger A U = D \\), where \\( D \\) is a diagonal matrix of eigenvalues. Discuss the properties of Hermitian matrices and the implications for the eigenvalues and eigenvectors."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 5 & 1 & 2 \\\\ 1 & 3 & 1 \\\\ 2 & 1 & 4 \\end{bmatrix} \\) be a symmetric matrix. Find the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) using the spectral theorem. Verify that the eigenvectors are orthogonal and explain why this orthogonality is a crucial property for diagonalization of symmetric matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the Hermitian matrix \\( A = \\begin{bmatrix} 7 & 3 + 2i \\\\ 3 - 2i & 5 \\end{bmatrix} \\). Find the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) by finding a unitary matrix \\( U \\) such that \\( U^\\dagger A U = D \\), where \\( D \\) is the diagonal matrix of eigenvalues. Discuss how the eigenvalues of a Hermitian matrix are always real and how this property affects the diagonalization process."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 6 & 2 & 1 \\\\ 2 & 5 & 4 \\\\ 1 & 4 & 3 \\end{bmatrix} \\) be a symmetric matrix. Find the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) using the Gram-Schmidt process to orthonormalize the eigenvectors. Verify that the matrix \\( A \\) is diagonalizable and discuss how the diagonalization relates to the spectral theorem for symmetric matrices."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 2 + i & 3 - 2i \\\\ 1 + i & 4 - i \\end{bmatrix} \\) be a complex matrix. Compute the eigenvalues and eigenvectors of \\( A \\), and determine whether \\( A \\) is diagonalizable. If it is diagonalizable, find a matrix \\( P \\) such that \\( P^{-1} A P \\) is diagonal. Discuss the geometric interpretation of the eigenvectors in the complex plane."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the complex matrix \\( A = \\begin{bmatrix} 1 & -i & 0 \\\\ i & 2 & -i \\\\ 0 & i & 3 \\end{bmatrix} \\). Find the characteristic polynomial of \\( A \\) and determine its eigenvalues. Compute the corresponding eigenvectors and check whether they form a linearly independent set. If the matrix is diagonalizable, explicitly construct the diagonalization."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Let \\( A = \\begin{bmatrix} 2 + i & 1 - i & 0 \\\\ 3 + 2i & 4 - i & 1 + i \\\\ 0 & 2 - i & 5 + i \\end{bmatrix} \\). Compute the eigenvalues and eigenvectors of \\( A \\), and determine whether the eigenvectors form an orthonormal basis with respect to the standard inner product in \\( \\mathbb{C}^3 \\). If not, apply the Gram-Schmidt process to obtain an orthonormal basis."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Given the complex matrix \\( A = \\begin{bmatrix} 0 & i & -1 \\\\ -i & 0 & i \\\\ 1 & -i & 0 \\end{bmatrix} \\), find its eigenvalues and eigenvectors. Show that \\( A \\) is a normal matrix by verifying \\( A A^\\dagger = A^\\dagger A \\). Using the Spectral Theorem, find a unitary matrix \\( U \\) such that \\( U^\\dagger A U \\) is diagonal. Discuss the significance of normal matrices in the context of diagonalization."
    },
    {
        "chapter": "Eigenvalues and Eigenvectors",
        "question": "Consider the complex matrix \\( A = \\begin{bmatrix} 1 + i & 2 \\\\ -i & 3 - i \\end{bmatrix} \\). Compute its eigenvalues and eigenvectors, and determine whether \\( A \\) is diagonalizable. If \\( A \\) is not diagonalizable, compute its Jordan form. Additionally, explain how the Jordan form helps in understanding the structure of non-diagonalizable complex matrices and their generalized eigenvectors."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Sketch the feasible set with constraints \\( x + 2y \\geq 6 \\), \\( 2x + y \\geq 6 \\), \\( x \\geq 0 \\), \\( y \\geq 0 \\). What points lie at the three ``corners'' of this set?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "On the preceding feasible set, what is the minimum value of the cost function \\( x + y \\)? Draw the line \\( x + y = \\text{constant} \\) that first touches the feasible set. What points minimize the cost functions \\( 3x + y \\) and \\( x - y \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that the feasible set constrained by \\( 2x + 5y \\leq 3 \\), \\( -3x + 8y \\leq -5 \\), \\( x \\geq 0 \\), \\( y \\geq 0 \\), is empty."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that the following problem is feasible but unbounded, so it has no optimal solution: Maximize \\( x + y \\), subject to \\( x \\geq 0 \\), \\( y \\geq 0 \\), \\( -3x + 2y \\leq -1 \\), \\( x - y \\leq 2 \\)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Add a single inequality constraint to \\( x \\geq 0 \\), \\( y \\geq 0 \\) such that the feasible set contains only one point."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What shape is the feasible set \\( x \\geq 0 \\), \\( y \\geq 0 \\), \\( z \\geq 0 \\), \\( x + y + z = 1 \\), and what is the maximum of \\( x + 2y + 3z \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the portfolio problem at the end of the preceding section."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In the feasible set for the General Motors problem, the nonnegativity \\( x, y, z \\geq 0 \\) leaves an eighth of three-dimensional space (the positive octant). How is this cut by the two planes from the constraints, and what shape is the feasible set? How do its corners show that, with only these two constraints, there will be only two kinds of cars in the optimal solution?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "(Transportation problem) Suppose Texas, California, and Alaska each produce a million barrels of oil; 800,000 barrels are needed in Chicago at a distance of 1000, 2000, and 3000 miles from the three producers, respectively; and 2,200,000 barrels are needed in New England 1500, 3000, and 3700 miles away. If shipments cost one unit for each barrel-mile, what linear program with five equality constraints must be solved to minimize the shipping cost?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Minimize $x_1 + x_2 - x_3$, subject to:\n    \\begin{align*}\n        2x_1 - 4x_2 + x_3 + x_4 &= 4, \\\\\n        3x_1 + 5x_2 + x_3 + x_5 &= 2.\n    \\end{align*}\n    Which of $x_1$, $x_2$, $x_3$ should enter the basis, and which of $x_4$, $x_5$ should leave? Compute the new pair of basic variables, and find the cost at the new corner."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "After the preceding simplex step, prepare for and decide on the next step."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In Example 3, suppose the cost is $3x + y$. With rearrangement, the cost vector is $c = (0,1,3,0)$. Show that $r \\geq 0$ and, therefore, that corner $P$ is optimal."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose the cost function in Example 3 is $x - y$, so that after rearrangement $c = (0,-1,1,0)$ at the corner $P$. Compute $r$ and decide which column $u$ should enter the basis. Then compute $B^{-1}u$ and show from its sign that you will never meet another corner. We are climbing the $y$-axis in Figure 8.3, and $x - y$ goes to $-\\infty$."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Again in Example 3, change the cost to $x + 3y$. Verify that the simplex method takes you from $P$ to $Q$ to $R$, and that the corner $R$ is optimal."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Phase I finds a basic feasible solution to $Ax = b$ (a corner). After changing signs to make $b \\geq 0$, consider the auxiliary problem of minimizing $w_1 + w_2 + \\cdots + w_m$, subject to $x \\geq 0$, $w \\geq 0$, $Ax + w = b$. Whenever $Ax = b$ has a nonnegative solution, the minimum cost in this problem will be zero\u2014with $w^* = 0$.\n    \\begin{itemize}"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If we wanted to maximize instead of minimize the cost (with $Ax = b$ and $x \\geq 0$), what would be the stopping test on $r$, and what rules would choose the column of $N$ to make basic and the column of $B$ to make free?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Minimize $2x_1 + x_2$, subject to $x_1 + x_2 \\geq 4$, $x_1 + 3x_2 \\geq 12$, $x_1 - x_2 \\geq 0$, $x \\geq 0$."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Verify the inverse in equation (5), and show that $BE$ has $Bv = u$ in its $k$th column. Then $BE$ is the correct basis matrix for the next step, $E^{-1}B^{-1}$ is its inverse, and $E^{-1}$ updates the basis matrix correctly."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose we want to minimize $cx = x_1 - x_2$, subject to:\n    \\begin{align*}\n        2x_1 - 4x_2 + x_3 &= 6, \\\\\n        3x_1 + 6x_2 + x_4 &= 12\n    \\end{align*}\n    (all $x_1, x_2, x_3, x_4 \\geq 0$). Starting from $x = (0,0,6,12)$, should $x_1$ or $x_2$ be increased from its current value of zero? How far can it be increased until the equations force $x_3$ or $x_4$ down to zero? At that point, what is the new $x$?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For the matrix $P = I - A^T (A A^T)^{-1} A$, show that if $x$ is in the nullspace of $A$, then $Px = x$. The nullspace stays unchanged under this projection."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "(a) Minimize the cost $c^T x = 5x_1 + 4x_2 + 8x_3$ on the plane $x_1 + x_2 + x_3 = 3$, by testing the vertices $P$, $Q$, $R$, where the triangle is cut off by the requirement $x \\geq 0$."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the dual of the following problem: Minimize \\( x_1 + x_2 \\), subject to \\( x_1 \\geq 0 \\),\n    \\( x_2 \\geq 0 \\), \\( 2x_1 \\geq 4 \\), \\( x_1 + 3x_2 \\geq 11 \\)? Find the solution to both this problem and its dual,\n    and verify that minimum equals maximum."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the dual of the following problem: Maximize \\( y_2 \\) subject to \\( y_1 \\geq 0 \\), \\( y_2 \\geq 0 \\),\n    \\( y_1 + y_2 \\leq 3 \\)? Solve both this problem and its dual."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose \\( A \\) is the identity matrix (so that \\( m = n \\)), and the vectors \\( b \\) and \\( c \\) are nonnegative. Explain why \\( x^* = b \\) is optimal in the minimum problem, find \\( y^* \\) in the maximum\n    problem, and verify that the two values are the same. If the first component of \\( b \\) is\n    negative, what are \\( x^* \\) and \\( y^* \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Construct a 1 by 1 example in which \\( Ax \\geq b \\), \\( x \\geq 0 \\) is unfeasible, and the dual problem\n    is unbounded."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Starting with the 2 by 2 matrix \\( A =\n    \\begin{pmatrix}\n    1 & 0 \\\\\n    0 & -1\n    \\end{pmatrix} \\), choose \\( b \\) and \\( c \\) so that both of the feasible\n    sets \\( Ax \\geq b \\), \\( x \\geq 0 \\) and \\( yA \\leq c \\), \\( y \\geq 0 \\) are empty."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If all entries of \\( A \\), \\( b \\), and \\( c \\) are positive, show that both the primal and the dual are\n    feasible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that \\( x = (1,1,1,0) \\) and \\( y = (1,1,0,1) \\) are feasible in the primal and dual, with\n    \\[\n    A =\n    \\begin{pmatrix}\n    0 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1 & 1 & 1 & 1 \\\\\n    1 & 0 & 0 & 1\n    \\end{pmatrix}\n    , \\quad\n    b =\n    \\begin{pmatrix}\n    1 \\\\\n    1 \\\\\n    1 \\\\\n    1\n    \\end{pmatrix}\n    , \\quad\n    c =\n    \\begin{pmatrix}\n    1 \\\\\n    1 \\\\\n    1 \\\\\n    3\n    \\end{pmatrix}\n    .\n    \\]\n    Then, after computing \\( cx \\) and \\( yb \\), explain how you know they are optimal."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the dual of the following problem: Minimize \\( x_1 + x_2 \\), subject to \\( x_1 \\geq 0 \\), \\( x_2 \\geq 0 \\), \\( 2x_1 \\geq 4 \\), \\( x_1 + 3x_2 \\geq 11 \\)? Find the solution to both this problem and its dual, and verify that minimum equals maximum."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the dual of the following problem: Maximize \\( y_2 \\) subject to \\( y_1 \\geq 0 \\), \\( y_2 \\geq 0 \\), \\( y_1 + y_2 \\leq 3 \\)? Solve both this problem and its dual."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose \\( A \\) is the identity matrix (so that \\( m = n \\)), and the vectors \\( b \\) and \\( c \\) are nonnegative. Explain why \\( x^* = b \\) is optimal in the minimum problem, find \\( y^* \\) in the maximum problem, and verify that the two values are the same. If the first component of \\( b \\) is negative, what are \\( x^* \\) and \\( y^* \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Construct a 1 by 1 example in which \\( Ax \\geq b \\), \\( x \\geq 0 \\) is unfeasible, and the dual problem is unbounded."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Starting with the 2 by 2 matrix \\( A = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} \\), choose \\( b \\) and \\( c \\) so that both of the feasible sets \\( Ax \\geq b \\), \\( x \\geq 0 \\) and \\( yA \\leq c \\), \\( y \\geq 0 \\) are empty."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If all entries of \\( A \\), \\( b \\), and \\( c \\) are positive, show that both the primal and the dual are feasible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that \\( x = (1,1,1,0) \\) and \\( y = (1,1,0,1) \\) are feasible in the primal and dual, with\n    \\[\n    A = \\begin{bmatrix}\n    0 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1 & 1 & 1 & 1 \\\\\n    1 & 0 & 0 & 1\n    \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix}\n    1 \\\\\n    1 \\\\\n    1 \\\\\n    1\n    \\end{bmatrix}, \\quad\n    c = \\begin{bmatrix}\n    1 \\\\\n    1 \\\\\n    1 \\\\\n    3\n    \\end{bmatrix}.\n    \\]\n    Then, after computing \\( cx \\) and \\( yb \\), explain how you know they are optimal."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Verify that the vectors in the previous exercise satisfy the complementary slackness conditions, and find the one slack inequality in both the primal and the dual."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose that \\( A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\), \\( b = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\), and \\( c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\). Find the optimal \\( x \\) and \\( y \\), and verify the complementary slackness conditions (as well as \\( yb = cx \\))."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If the primal problem is constrained by equations instead of inequalities\u2014Minimize \\( cx \\) subject to \\( Ax = b \\) and \\( x \\geq 0 \\)\u2014then the requirement \\( y \\geq 0 \\) is left out of the dual: Maximize \\( yb \\) subject to \\( yA \\leq c \\). Show that the one-sided inequality \\( yb \\leq cx \\) still holds. Why was \\( y \\geq 0 \\) needed in equation (1) but not here? This weak duality can be completed to full duality."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Without the simplex method, minimize the cost \\( 5x_1 + 3x_2 + 4x_3 \\), subject to \\( x_1 + x_2 + x_3 \\geq 1 \\), \\( x_1 \\geq 0 \\), \\( x_2 \\geq 0 \\), \\( x_3 \\geq 0 \\).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the shape of the feasible set?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the dual problem, and what is its solution \\( y \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If the primal has a unique optimal solution \\( x^* \\), and then \\( c \\) is changed a little, explain why \\( x^* \\) still remains the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Write the dual of the following problem: Maximize \\( x_1 + x_2 + x_3 \\) subject to \\( 2x_1 + x_2 \\leq 4 \\), \\( x_3 \\leq 6 \\). What are the optimal \\( x^* \\) and \\( y^* \\) (if they exist!)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If \\( A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\), describe the cone of nonnegative combinations of the columns. If \\( b \\) lies inside that cone, say \\( b = (3,2) \\), what is the feasible vector \\( x \\)? If \\( b \\) lies outside, say \\( b = (0,1) \\), what vector \\( y \\) will satisfy the alternative?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In three dimensions, can you find a set of six vectors whose cone of nonnegative combinations fills the whole space? What about four vectors?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Use the concept of alternatives to show that the following equation has no solution:\n    \\[\n    \\begin{bmatrix}\n    2 & 2 \\\\\n    4 & 4\n    \\end{bmatrix}\n    x =\n    \\begin{bmatrix}\n    1 \\\\\n    1\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Use the concept of alternatives to show that there is no solution \\( x \\geq 0 \\) for the system:\n    \\[\n    \\begin{bmatrix}\n    1 & 3 & -5 \\\\\n    1 & -4 & -7\n    \\end{bmatrix}\n    x =\n    \\begin{bmatrix}\n    2 \\\\\n    3\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If you could increase the capacity of any one pipe in the network above, which change would produce the largest increase in the maximal flow?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Draw a 5-node network with capacity $|i - j|$ between node $i$ and node $j$. Find the largest possible flow from node 1 to node 4."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a graph, the maximum number of paths from $s$ to $t$ with no common edges equals the minimum number of edges whose removal disconnects $s$ from $t$. Relate this to the max flow-min cut theorem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find a maximal set of marriages (a complete matching, if possible) for the following matrices:\n    \\[\n    A = \\begin{bmatrix}\n    0 & 0 & 1 & 0 & 0 \\\\\n    1 & 1 & 0 & 1 & 1 \\\\\n    0 & 1 & 1 & 0 & 1 \\\\\n    0 & 0 & 1 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 & 0\n    \\end{bmatrix}\n    \\]\n    \\[\n    B = \\begin{bmatrix}\n    1 & 1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 1 & 0 \\\\\n    0 & 0 & 1 & 0 & 1 \\\\\n    1 & 1 & 1 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0\n    \\end{bmatrix}\n    \\]\n    Sketch the network for $B$, with heavier lines on the edges in your matching."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For the matrix $A$ in Problem 4, which rows violate Hall\u2019s condition\u2014by having all their 1s in too few columns? Which $p \\times q$ submatrix of zeros has $p+q > n$?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How many lines (horizontal and vertical) are needed to cover all the 1s in $A$ in Problem 4? For any matrix, explain why weak duality is true: If $k$ marriages are possible, then it takes at least $k$ lines to cover all the 1s."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose every row and every column contains exactly two 1s. Prove that a complete matching is possible. (Show that the 1s cannot be covered by less than $n$ lines.)"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find an example with two or more 1s in each row and column, for which a complete matching is impossible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If a $7 \\times 7$ matrix has 15 1s, prove that it allows at least 3 marriages."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For infinite sets, a complete matching may be impossible even if Hall\u2019s condition is passed. If the first row is all 1s and then every $a_{i,i-1} = 1$, show that any $p$ rows have 1s in at least $p$ columns\u2014and yet there is no complete matching."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If you could increase the capacity of any one pipe in a network, which change would produce the largest increase in the maximal flow?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Draw a 5-node network with capacity $|i - j|$ between node $i$ and node $j$. Find the largest possible flow from node 1 to node 4."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a graph, the maximum number of paths from $s$ to $t$ with no common edges equals the minimum number of edges whose removal disconnects $s$ from $t$. Relate this to the max flow-min cut theorem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find a maximal set of marriages (a complete matching, if possible) for the matrix $A$:\n    \\[\n    A = \\begin{pmatrix}\n    0 & 0 & 1 & 0 & 0 \\\\\n    1 & 1 & 0 & 1 & 1 \\\\\n    0 & 1 & 1 & 0 & 1 \\\\\n    0 & 0 & 1 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 & 0\n    \\end{pmatrix}\n    \\]\n    and for the matrix $B$:\n    \\[\n    B = \\begin{pmatrix}\n    1 & 1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 1 & 0 \\\\\n    0 & 0 & 1 & 0 & 1 \\\\\n    1 & 1 & 1 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0\n    \\end{pmatrix}\n    \\]\n    Sketch the network for $B$, with heavier lines on the edges in your matching."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For the matrix $A$ in Problem 4, which rows violate Hall\u2019s condition by having all their 1s in too few columns? Which $p \\times q$ submatrix of zeros has $p + q > n$?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How many lines (horizontal and vertical) are needed to cover all the 1s in $A$ in Problem 4? For any matrix, explain why weak duality is true: If $k$ marriages are possible, then it takes at least $k$ lines to cover all the 1s."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose every row and every column contains exactly two 1s. Prove that a complete matching is possible. (Show that the 1s cannot be covered by less than $n$ lines.)"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find an example with two or more 1s in each row and column, for which a complete matching is impossible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If a $7 \\times 7$ matrix has 15 ones, prove that it allows at least 3 marriages."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For infinite sets, a complete matching may be impossible even if Hall\u2019s condition is passed. If the first row is all 1s and then every $a_{i, i-1} = 1$, show that any $p$ rows have 1s in at least $p$ columns\u2014and yet there is no complete matching."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If Figure 8.5 shows lengths instead of capacities, find the shortest path from $s$ to $t$, and a minimal spanning tree."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply algorithms 1 and 2 to find a shortest spanning tree for the network of Problem 2."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Why does the greedy algorithm work for the spanning tree problem?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show by example that the greedy algorithm could fail to find the shortest path from $s$ to $t$, by starting with the shortest edge."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If $A$ is the $5 \\times 5$ matrix with 1s just above and just below the main diagonal, find:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "a set of rows with 1s in too few columns."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "a set of columns with 1s in too few rows."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "a $p \\times q$ submatrix of zeros with $p + q > 5$."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "four lines that cover all the 1s."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "The maximal flow problem has slack variables $w_{ij} = c_{ij} - x_{ij}$ for the difference between capacities and flows. State the problem of Figure 8.5 as a linear program."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How will the optimal strategies in the game that opens this section be affected if the \\$20 is increased to \\$70? What is the value (the average win for X) of this new game?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "With payoff matrix $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$, explain the calculation by X of the maximin and by Y of the minimax. What strategies $x^*$ and $y^*$ are optimal?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If $a_{ij}$ is the largest entry in its row and the smallest in its column, why will X always choose column $j$ and Y always choose row $i$ (regardless of the rest of the matrix)? Show that the preceding problem had such an entry, and then construct an $A$ without one."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Compute Y's best strategy by weighting the rows of $A = \\begin{pmatrix} 3 & 4 & 1 \\\\ 2 & 0 & 3 \\end{pmatrix}$ with $y$ and $1 - y$. X will concentrate on the largest of the components $3y + 2(1 - y)$, $4y$, and $y + 3(1 - y)$. Find the largest of those three (depending on $y$) and then find the $y^*$ between 0 and 1 that makes this largest component as small as possible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "With the same $A$ as in Problem 4, find the best strategy for X. Show that X uses only the two columns (the first and third) that meet at the minimax point in the graph."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find both optimal strategies, and the value, if\n    \\[\n    A = \\begin{pmatrix}\n    1 & 0 & -1 \\\\\n    -2 & -1 & 2\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$. What weights $x_1$ and $1 - x_1$ will give a column of the form $\\begin{pmatrix} u \\\\ u \\end{pmatrix}$, and what weights $y_1$ and $1 - y_1$ on the two rows will give a new row $[v \\; v]$? \\\\ show that  v=u"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How will the optimal strategies in the game that opens this section be affected if the \\$20 is increased to \\$70? What is the value (the average win for X) of this new game?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "With payoff matrix \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\), explain the calculation by X of the maximin and by Y of the minimax. What strategies \\( x^* \\) and \\( y^* \\) are optimal?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If \\( a_{ij} \\) is the largest entry in its row and the smallest in its column, why will X always choose column j and Y always choose row i (regardless of the rest of the matrix)? Show that the preceding problem had such an entry, and then construct an \\( A \\) without one."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Compute Y\u2019s best strategy by weighting the rows of \\( A = \\begin{pmatrix} 3 & 4 & 1 \\\\ 2 & 0 & 3 \\end{pmatrix} \\) with \\( y \\) and \\( 1 - y \\). X will concentrate on the largest of the components \\( 3y + 2(1 - y) \\), \\( 4y \\), and \\( y + 3(1 - y) \\). Find the largest of those three (depending on \\( y \\)) and then find the \\( y^* \\) between 0 and 1 that makes this largest component as small as possible."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "With the same \\( A \\) as in Problem 4, find the best strategy for X. Show that X uses only the two columns (the first and third) that meet at the minimax point in the graph."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find both optimal strategies, and the value, if\n    \\[\n    A = \\begin{pmatrix} 1 & 0 & -1 \\\\ -2 & -1 & 2 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Suppose \\( A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\). What weights \\( x_1 \\) and \\( 1 - x_1 \\) will give a column of the form \\( \\begin{pmatrix} u \\\\ u \\end{pmatrix} \\), and what weights \\( y_1 \\) and \\( 1 - y_1 \\) on the two rows will give a new row \\( \\begin{pmatrix} v & v \\end{pmatrix} \\)?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find \\( x^* \\), \\( y^* \\), and the value \\( v \\) for\n    \\[\n    A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Compute\n    \\[\n    \\min_{y_i \\geq 0, y_1 + y_2 = 1} \\max_{x_1 \\geq 0, x_1 + x_2 = 1} (x_1 y_1 + x_2 y_2).\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain each of the inequalities in equation (5). Then, once the minimax theorem has turned them into equalities, derive (again in words) the saddle point equations (4)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that \\( x^* = \\left( \\frac{1}{2}, \\frac{1}{2}, 0, 0 \\right) \\) and \\( y^* = \\left( \\frac{1}{2}, \\frac{1}{2} \\right) \\) are optimal strategies in our simplified version of poker, by computing \\( y A x^* \\) and \\( y^* A x \\) and verifying the conditions (4) for a saddle point."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Has it been proved that no chess strategy always wins for black? This is certainly true when the players are given two moves at a time; if black had a winning strategy, white could move a knight out and back and then follow that strategy, leading to the impossible conclusion that both would win."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If X chooses a prime number and simultaneously Y guesses whether it is odd or even (with gain or loss of \\$1), who has the advantage?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "If X is a quarterback, with the choice of run or pass, and Y can defend against a run or a pass, suppose the payoff (in yards) is\n    \\[\n    A = \\begin{pmatrix} 2 & 8 \\\\ 6 & -6 \\end{pmatrix}\n    \\]\n    \\[\n    \\text{defense against run} \\quad \\text{defense against pass}\n    \\]\n    \\[\n    \\text{run} \\quad \\text{pass}\n    \\]\n    What are the optimal strategies and the average gain on each play?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define a linear inequality. Provide at least two examples of linear inequalities and discuss the significance of each example in linear programming."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How do linear inequalities serve as constraints in linear programming? Illustrate with an example where linear inequalities define a feasible region and explain how these inequalities limit the solution set."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of a feasible region in the context of linear inequalities. What geometric shape does this region take in two-dimensional space, and what are the implications for finding the optimal solution?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the system of inequalities, \\(x + 2y \\leq 5\\), \\(3x - y \\geq 4\\), and \\(x \\geq 0\\), graphically represent the feasible region and discuss how the feasible solutions are constrained by these inequalities."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the significance of slack and surplus variables in linear inequalities. How can they be used to convert inequality constraints into equality constraints for solving optimization problems?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove that the solution set of a system of linear inequalities is convex. Show this by considering a system with two variables and proving that any convex combination of two feasible points remains within the feasible region."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the conditions for a point to be inside the feasible region of a system of linear inequalities. What steps would you follow to check if a given point satisfies the system of inequalities?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove the fundamental theorem of linear programming that the optimal solution of a linear programming problem occurs at a vertex of the feasible region. Provide a proof using geometric arguments and linear inequalities."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a system of two linear inequalities \\(x + y \\leq 5\\) and \\(2x - y \\geq 3\\), solve the system graphically and identify the feasible region. Show all steps of the solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the graphical method, solve a system of linear inequalities and find the optimal solution. Specifically, consider the system \\(x + 2y \\leq 6\\), \\(3x + y \\geq 3\\), and \\(x \\geq 0\\), and determine the optimal values of \\(x\\) and \\(y\\) that maximize the objective function \\(z = 2x + 3y\\)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the steps involved in converting a linear inequality into an equation using slack variables. Provide a detailed example to illustrate this process, including the conversion of inequalities into equalities for optimization problems."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a word problem where a factory produces two products, A and B, subject to resource constraints such as machine hours and labor hours, formulate a system of linear inequalities that model the problem. Determine the feasible production levels for each product."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider a linear programming problem where you are asked to allocate resources between two projects, subject to budget constraints. Formulate the problem as a system of linear inequalities and discuss the feasibility of the solution space."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove that for any system of linear inequalities, the set of feasible solutions is a convex set. Include a discussion of the properties of convex sets and provide a formal proof using linear combinations of feasible points."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the system of inequalities \\(2x + 3y \\leq 10\\), \\(x - y \\geq 1\\), and \\(y \\geq 2\\), find the feasible region and determine if the point \\( (3, 4) \\) satisfies all the inequalities."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the role of linear inequalities in multi-objective optimization problems. How do these inequalities help in identifying a solution that balances multiple objectives? Provide an example."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the graphical method for solving two-variable linear inequalities. Use an example to show how the intersection of half-planes can help identify the feasible region."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In the context of a diet problem, formulate a set of linear inequalities to represent nutritional constraints such as calorie, protein, and fat intake. Solve the inequalities graphically to determine the feasible diet plan."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the interpretation of the optimal solution in linear programming. How does the feasible region relate to the optimal values of decision variables? Provide a graphical example to support your explanation."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show how to derive the feasible solution from a system of linear inequalities using the simplex method. Provide a detailed example that involves multiple inequalities and explain each step of the algorithm."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How do we use linear inequalities to model economic problems, such as profit maximization and cost minimization? Provide an example where linear inequalities are used to represent supply and demand constraints."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of the dual problem in linear programming. How can the dual of a system of linear inequalities help us understand the relationship between constraints and objective functions?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a system of linear inequalities graphically, and use it to determine the optimal solution for a linear programming problem with an objective function of the form \\(z = 4x + 5y\\)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a real-world scenario involving resource allocation in a manufacturing plant, formulate a system of linear inequalities to represent machine time, labor hours, and production constraints. Solve the system to find the feasible production plan."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show how linear inequalities can be used in network flow problems. Formulate a set of inequalities that describe the constraints of a network and solve for the optimal flow values."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a transportation problem, constraints are often expressed as linear inequalities. Formulate a system of inequalities for a transportation problem where the objective is to minimize shipping costs, given constraints on supply and demand."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the relationship between linear inequalities and convex polyhedra. Prove that the feasible region of a system of linear inequalities is a convex polyhedron, and explain how this result can be used in optimization problems."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the use of the graphical method for solving three-variable systems of linear inequalities. How can we extend the method used for two variables to higher dimensions, and what are the challenges involved?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain how linear inequalities can be applied to problems involving market equilibrium. Formulate a system of inequalities to represent supply and demand conditions, and determine the equilibrium price and quantity."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the graphical method, solve the following system of inequalities: \\(4x + y \\leq 12\\), \\(x - 2y \\geq 3\\), and \\(x \\geq 0\\). Identify the feasible region and determine the optimal solution for \\(z = 2x + 3y\\)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the importance of sensitivity analysis in linear programming. How can the feasible region and optimal solutions be affected by changes in the coefficients of the linear inequalities?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the significance of integer programming when solving systems of linear inequalities. Provide an example of a problem where integer solutions are required and explain how this modifies the solution process."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How can linear inequalities be used to model traffic flow in urban planning? Formulate a set of inequalities to represent traffic congestion constraints and determine the optimal traffic management plan."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a word problem involving the allocation of funds for multiple investment options, each with different returns and risk levels. Formulate the problem as a system of linear inequalities and find the feasible investment allocation that maximizes the return."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove that the optimal solution of a linear programming problem with a non-empty feasible region is always a vertex of the feasible region. Provide a detailed proof using the convexity of the feasible region."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a system of linear inequalities, explain how to interpret the results of a linear programming problem graphically. How can the objective function help in identifying the optimal solution within the feasible region?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss how to handle infeasible solutions in a linear programming problem. What methods can be used to identify and resolve infeasible solutions in systems of linear inequalities?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the simplex method, solve the following linear programming problem: maximize \\(z = 3x + 4y\\), subject to the constraints \\(x + 2y \\leq 6\\), \\(2x + y \\leq 6\\), and \\(x, y \\geq 0\\)."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the constraints \\(2x + y \\leq 8\\), \\(x + 3y \\geq 5\\), and \\(x \\leq 4\\), solve the system of linear inequalities algebraically to find the feasible region."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the geometric interpretation of the simplex method in the context of linear inequalities. How does the method move from one vertex of the feasible region to another to find the optimal solution?"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "How can linear inequalities be used to model transportation problems in logistics? Formulate a system of inequalities to represent supply and demand constraints and solve for the optimal transportation plan."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive a general procedure for converting a system of linear inequalities into a set of linear equations using slack variables. Provide a detailed example that demonstrates this procedure for a resource allocation problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain in detail the steps involved in the Simplex Method. Starting with a general linear programming problem in standard form, describe how the initial simplex tableau is constructed. Provide an example with a system of two constraints and explain how the tableau evolves after the first pivot operation."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What are the conditions for optimality in linear programming using the Simplex Method? Prove that if the solution is optimal, no further improvements can be made in terms of the objective function. Use an example involving a two-variable linear programming problem to demonstrate the application of these conditions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define a pivot in the context of the Simplex Method. Explain the role of the pivot operation in progressing towards the optimal solution. Provide a detailed example of how a pivot operation is carried out in a Simplex tableau and show the transformation of the tableau after the operation."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the difference between basic and non-basic variables in the Simplex Method? Discuss their roles in determining the solution to a linear programming problem. Explain how basic variables correspond to the current solution and how non-basic variables are used to find the next iteration in the Simplex Method."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the algorithm for the Simplex Method. Starting from the general linear programming problem, explain the sequence of steps involved in solving the problem. Discuss how the method transitions from one basic feasible solution to another and eventually reaches the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the linear programming problem: \n    \\[\n    \\text{Maximize } z = 3x + 2y\n    \\]\n    subject to the constraints\n    \\[\n    x + y \\leq 4, \\quad 2x + y \\leq 5, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    formulate the initial Simplex tableau and solve for the optimal solution using the Simplex Method. Show all steps involved, including identifying the entering and leaving variables."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider the linear programming problem: \n    \\[\n    \\text{Minimize } z = -2x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + 2y \\geq 4, \\quad 3x - y \\leq 5, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Solve this problem using the Simplex Method, starting from the initial tableau. Include all steps of the algorithm, including the pivoting process and optimality check."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of degeneracy in the Simplex Method. Provide an example where degeneracy occurs, and explain how to handle degenerate solutions during the pivoting process. Illustrate with a numerical example, such as the linear programming problem:\n    \\[\n    \\text{Maximize } z = 4x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + y \\leq 5, \\quad 2x + 2y \\leq 10, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Explain why degeneracy arises in this example and discuss the potential issues it causes in the Simplex Method."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a linear programming problem in standard form:\n    \\[\n    \\text{Maximize } z = x + 2y + 3z\n    \\]\n    subject to the constraints\n    \\[\n    x + y + z \\leq 4, \\quad 2x + y + 3z \\geq 6, \\quad x \\geq 0, \\quad y \\geq 0, \\quad z \\geq 0,\n    \\]\n    construct the initial Simplex tableau and solve the problem using the Simplex Method. Explain each step in detail, including the identification of entering and leaving variables and the pivoting procedure."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the role of duality in the Simplex Method. For a given linear programming problem, formulate its dual problem and solve both the primal and dual problems using the Simplex Method. Provide an example with the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 2x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + 2y \\leq 6, \\quad 3x + y \\leq 7, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Formulate the dual of this problem and solve both problems, showing the relationship between the primal and dual solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Describe in detail how the Simplex Method can be applied to a linear programming problem with more than two variables. Using a three-variable example, construct the initial Simplex tableau and demonstrate the steps involved in performing the pivot operations to solve for the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 5x + 4y\n    \\]\n    subject to the constraints\n    \\[\n    2x + y \\leq 8, \\quad x + 2y \\geq 6, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Solve this problem using the Simplex Method. Provide the initial tableau, pivot steps, and the final solution, including the interpretation of the basic and non-basic variables at each step."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the concept of a feasible region in the context of the Simplex Method. How does the Simplex Method navigate through the feasible region, and how does this relate to the movement from one basic feasible solution to another? Use a geometric example of a two-variable linear programming problem to illustrate the concept."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define degeneracy in the Simplex Method and explain its impact on the algorithm\u2019s efficiency. Provide a numerical example in which degeneracy causes cycling, and discuss the potential strategies to handle it, such as Bland's Rule."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the linear programming problem:\n    \\[\n    \\text{Maximize } z = 4x + 5y\n    \\]\n    subject to the constraints\n    \\[\n    3x + 2y \\leq 12, \\quad x + y \\geq 4, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    formulate the initial Simplex tableau, apply the Simplex Method to solve for the optimal solution, and interpret the results in the context of the problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove that the Simplex Method terminates after a finite number of iterations. Consider the case where the objective function coefficients are strictly positive, and explain why this ensures the algorithm will not cycle indefinitely. Illustrate the proof with a simple two-variable linear programming problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the Simplex Method:\n    \\[\n    \\text{Maximize } z = 2x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + y \\leq 4, \\quad x + 2y \\leq 6, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Construct the initial tableau and explain the steps for identifying the entering and leaving variables. Demonstrate the pivoting process and discuss the final optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain how artificial variables are used in the Simplex Method to handle linear programming problems that do not start with an initial basic feasible solution. Provide an example where artificial variables are required and explain how they are removed during the solution process."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 3x + 2y + 5z\n    \\]\n    subject to the constraints\n    \\[\n    x + y + z \\leq 7, \\quad x + 2y + 3z \\geq 8, \\quad x, y, z \\geq 0,\n    \\]\n    formulate the initial Simplex tableau and solve it using the Simplex Method. Discuss the process of performing the pivot operations and how the optimal solution is reached."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Describe the concept of the dual Simplex Method and explain how it differs from the regular Simplex Method. Provide an example where the dual Simplex Method is necessary and describe the procedure for solving the problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the linear programming problem:\n    \\[\n    \\text{Minimize } z = -4x + 6y\n    \\]\n    subject to the constraints\n    \\[\n    x + 2y \\geq 5, \\quad 2x + y \\leq 7, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    solve the problem using the Simplex Method. Include the formulation of the initial tableau, pivoting process, and final interpretation of the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the Simplex Method:\n    \\[\n    \\text{Maximize } z = 6x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    2x + y \\leq 6, \\quad x + 2y \\geq 3, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Formulate the initial Simplex tableau and solve for the optimal solution. Discuss how to handle situations where both constraints are active."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the relationship between the primal and dual linear programming problems. Given the following primal problem:\n    \\[\n    \\text{Minimize } z = 5x + 4y\n    \\]\n    subject to the constraints\n    \\[\n    x + 2y \\geq 6, \\quad 2x + y \\leq 8, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    formulate its dual problem, solve both the primal and dual problems using the Simplex Method, and explain the connection between their solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Describe the two-phase Simplex Method. Why is it used, and how does it help in solving linear programming problems that do not have an obvious basic feasible solution? Provide a detailed step-by-step application of the two-phase method to a sample problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the linear programming problem:\n    \\[\n    \\text{Maximize } z = 7x + 4y\n    \\]\n    subject to the constraints\n    \\[\n    3x + 2y \\leq 12, \\quad x + 3y \\geq 9, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    solve the problem using the Simplex Method. Discuss the interpretation of the basic and non-basic variables and explain how to identify the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the significance of the objective function's coefficients in the Simplex Method. What happens if one or more coefficients are negative or zero? Use a practical example to demonstrate how changes in the objective function can affect the solution process."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain how the Simplex Method handles unbounded solutions in linear programming. Provide an example where the solution is unbounded and discuss the steps that lead to this conclusion."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 2x + 5y\n    \\]\n    subject to the constraints\n    \\[\n    x + 3y \\leq 9, \\quad 2x + y \\geq 4, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    solve the problem using the Simplex Method. Include all steps from the formulation of the initial tableau to the final optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the role of the optimality test in the Simplex Method. At what point is the algorithm considered to have found an optimal solution? Illustrate this with a numerical example where the algorithm converges to the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the Simplex Method:\n    \\[\n    \\text{Maximize } z = 3x + 2y\n    \\]\n    subject to the constraints\n    \\[\n    2x + 3y \\leq 12, \\quad x + 2y \\geq 5, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Discuss the procedure for pivoting and the identification of the entering and leaving variables. Provide the optimal solution and interpret its meaning in the context of the problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the linear programming problem:\n    \\[\n    \\text{Maximize } z = 10x + 6y\n    \\]\n    subject to the constraints\n    \\[\n    x + y \\leq 7, \\quad 2x + 3y \\leq 12, \\quad x \\geq 0, \\quad y \\geq 0,\n    \\]\n    formulate the initial Simplex tableau and solve for the optimal solution. Explain the decision-making process during each pivot operation and the final interpretation of the results."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define the dual problem in linear programming. Provide a detailed explanation of how to derive the dual from a given primal linear programming problem. Demonstrate this by formulating the dual of the following primal problem:\n    \\[\n    \\text{Maximize } z = 5x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    2x_1 + x_2 \\leq 8, \\quad x_1 + 3x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the economic interpretation of the dual variables in the context of resource allocation? Provide a specific example, using a linear programming problem, and explain the role of dual variables in terms of shadow prices."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the relationship between the primal and dual problems in linear programming. Given the primal problem:\n    \\[\n    \\text{Minimize } z = 4x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\geq 3, \\quad x_1 + 2x_2 \\leq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0,\n    \\]\n    formulate the dual and discuss the connection between the primal and dual optimal solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the dual of the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 3x_1 + 2x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + 2x_2 \\leq 4, \\quad 2x_1 + x_2 \\geq 5, \\quad x_1, x_2 \\geq 0.\n    \\]\n    Explain the steps involved in deriving the dual problem and discuss the primal-dual relationships."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove the strong duality theorem in linear programming. Provide a detailed proof showing that if the primal problem has an optimal solution, then the dual problem also has an optimal solution, and vice versa."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the complementary slackness conditions for the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 4x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 5, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Explain the significance of the complementary slackness conditions and provide an interpretation in terms of the dual variables."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following primal linear programming problem:\n    \\[\n    \\text{Maximize } z = 5x_1 + 7x_2\n    \\]\n    subject to the constraints\n    \\[\n    3x_1 + 2x_2 \\leq 12, \\quad x_1 + 3x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0,\n    \\]\n    formulate the dual problem and solve the primal and dual problems simultaneously. Verify that the solutions satisfy the duality conditions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following primal-dual pair of problems:\n    \\[\n    \\text{Maximize } z = 4x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 6, \\quad 2x_1 + x_2 \\geq 5, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 6y_1 + 5y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + 2y_2 \\geq 4, \\quad y_1 + y_2 \\leq 3, \\quad y_1 \\geq 0, \\quad y_2 \\geq 0.\n    \\]\n    Verify the duality conditions and interpret the solutions in terms of the primal and dual variables."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the dual problem, interpret the shadow prices in the context of the following resource allocation problem:\n    \\[\n    \\text{Maximize } z = 3x_1 + 2x_2\n    \\]\n    subject to the constraints\n    \\[\n    2x_1 + x_2 \\leq 5, \\quad x_1 + 3x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Explain how the dual variables correspond to the shadow prices and how they reflect the impact of resource availability on the objective function."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Formulate the dual problem for the following linear programming model:\n    \\[\n    \\text{Maximize } z = 6x_1 + 5x_2\n    \\]\n    subject to the constraints\n    \\[\n    3x_1 + 2x_2 \\leq 12, \\quad x_1 + x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Explain the duality gap and how it relates to the primal and dual solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove the weak duality theorem in linear programming. Show that for any feasible solution to the primal and dual problems, the objective function value of the primal is always greater than or equal to the objective function value of the dual."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following primal problem:\n    \\[\n    \\text{Maximize } z = 8x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    3x_1 + x_2 \\leq 10, \\quad x_1 + 2x_2 \\geq 6, \\quad x_1, x_2 \\geq 0,\n    \\]\n    formulate the dual problem and explain how to solve both problems simultaneously. Discuss the primal-dual relationships."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the dual of the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 5x_1 + 2x_2\n    \\]\n    subject to the constraints\n    \\[\n    2x_1 + x_2 \\leq 7, \\quad x_1 + 3x_2 \\geq 9, \\quad x_1, x_2 \\geq 0.\n    \\]\n    Show the steps involved in the dual formulation and explain the dual variables and their interpretation."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of complementary slackness in linear programming. Provide an example of a linear programming problem and show how the complementary slackness conditions hold for the primal and dual solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider the following primal problem:\n    \\[\n    \\text{Minimize } w = 3x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + 2x_2 \\geq 5, \\quad 2x_1 + x_2 \\leq 7, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Derive the dual problem and solve the primal and dual problems. Verify the optimality conditions and interpret the solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show how the dual problem is related to the primal problem\u2019s sensitivity analysis. Use an example to illustrate how the dual variables represent the change in the objective value of the primal problem when the right-hand side of the constraints is modified."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following primal problem:\n    \\[\n    \\text{Minimize } z = 2x_1 + 5x_2\n    \\]\n    subject to the constraints\n    \\[\n    3x_1 + 4x_2 \\geq 10, \\quad x_1 + 2x_2 \\leq 6, \\quad x_1, x_2 \\geq 0,\n    \\]\n    formulate the dual problem and solve it. Compare the primal and dual optimal solutions and explain the duality gap."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Prove the strong duality theorem in linear programming and use it to explain why the optimal value of the primal problem equals the optimal value of the dual problem, assuming both problems have feasible solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the complementary slackness conditions and apply them to solve the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 6x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 4, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1, x_2 \\geq 0.\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following primal-dual pair of linear programming problems and verify the duality conditions:\n    \\[\n    \\text{Maximize } z = 7x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + 2x_2 \\leq 8, \\quad x_1 + 3x_2 \\geq 7, \\quad x_1, x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 8y_1 + 7y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + y_2 \\geq 7, \\quad 2y_1 + y_2 \\leq 7, \\quad y_1, y_2 \\geq 0.\n    \\]\n    Verify that the solutions satisfy the duality conditions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the dual of the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 5x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 4, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Interpret the dual variables and discuss how they affect the primal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the primal-dual relationships, solve the following pair of linear programming problems:\n    \\[\n    \\text{Maximize } z = 4x_1 + 2x_2\n    \\]\n    subject to the constraints\n    \\[\n    2x_1 + x_2 \\leq 6, \\quad x_1 + 3x_2 \\geq 4, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 6y_1 + 4y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + 2y_2 \\geq 4, \\quad y_1 + y_2 \\leq 3, \\quad y_1, y_2 \\geq 0.\n    \\]\n    Verify that the solutions satisfy the primal-dual relationships."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider the following primal linear programming problem:\n    \\[\n    \\text{Minimize } w = 3x_1 + 2x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + 2x_2 \\geq 5, \\quad 2x_1 + x_2 \\leq 7, \\quad x_1, x_2 \\geq 0.\n    \\]\n    Derive the dual problem and solve both the primal and dual problems. Verify the optimality conditions and discuss the economic interpretation of the dual variables."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show that the strong duality theorem holds for the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 7x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 6, \\quad x_1 + 3x_2 \\geq 5, \\quad x_1, x_2 \\geq 0.\n    \\]\n    Derive the dual problem and prove that the optimal values of the primal and dual problems are equal."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following primal and dual problems simultaneously and verify the duality conditions:\n    \\[\n    \\text{Maximize } z = 5x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 4, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1, x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 4y_1 + 6y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + 2y_2 \\geq 5, \\quad y_1 + y_2 \\leq 3, \\quad y_1, y_2 \\geq 0.\n    \\]\n    Verify that the primal-dual solutions satisfy the duality conditions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the transportation problem in the context of network models. Derive the equations representing the problem and explain how it can be solved using linear programming. Include a numerical example where transportation costs between various origins and destinations are given, and you need to minimize the total transportation cost."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the maximum flow problem and its relevance in network models. Derive the formulation of the maximum flow problem as a linear programming problem. Consider a flow network where the capacities of edges between nodes are provided. Solve for the maximum flow using the Ford-Fulkerson algorithm."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the minimum cost flow problem in network theory? Explain how this problem can be modeled using linear programming and its significance in real-world applications. Solve a numerical example where the demand and supply at various nodes are specified, and the transportation costs between nodes are given."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the transportation problem equations for a multi-commodity transportation problem. How can the simplex method be used to solve this? Illustrate with a numerical example involving multiple commodities and multiple origins and destinations."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a minimum cost flow problem using the network simplex method. Provide a detailed step-by-step solution to a numerical example where you are given a flow network with a set of supply and demand constraints, and each edge has a cost associated with it. Optimize the total cost of satisfying the demand."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Use Dijkstra\u2019s algorithm to solve the shortest path problem for a weighted directed graph. Provide a graph with 6 nodes and weighted edges, and use Dijkstra\u2019s algorithm to find the shortest path from a given source to all other nodes. Include the algorithm's step-by-step procedure."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the linear programming formulation for the maximum flow problem. Solve a network flow problem with 4 nodes and multiple directed edges where you need to maximize the flow from a source to a sink under capacity constraints. Use the Ford-Fulkerson method to determine the maximum flow."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of the minimum cut in a network flow problem. Provide a numerical example where you need to identify the minimum cut of a flow network and explain the relationship between the maximum flow and minimum cut according to the Max-Flow Min-Cut Theorem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a transportation problem using the modified distribution method (MODI method) with a given cost matrix, supply, and demand vectors. Explain the steps involved and derive the optimal solution that minimizes the total transportation cost. Provide a numerical example with 4 origins and 3 destinations."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the equations for the shortest path problem in a directed graph and solve it using Bellman-Ford's algorithm. Provide a graph with negative weight edges and use Bellman-Ford to find the shortest path from a specified source node to all other nodes."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a maximum flow problem with the Edmonds-Karp algorithm. Given a network with 5 nodes and capacity constraints on the edges, apply the Edmonds-Karp method to determine the maximum flow from the source to the sink. Explain each iteration of the algorithm in detail."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the differences between the primal and dual formulations of the transportation problem. Provide an example of a transportation problem and solve it using both formulations. Compare the results obtained and explain the significance of the dual variables in the context of the transportation problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using linear programming, derive the optimality conditions for the minimum cost flow problem. Solve a numerical example where the objective is to minimize the total cost of flowing goods through a network with multiple supply and demand nodes."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the application of the transportation problem in supply chain management. Formulate the problem as a linear programming problem, and solve a specific example where you are given transportation costs, supply at each source, and demand at each destination."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the formulation of the shortest path problem as a linear program. Solve a numerical example using the network flow approach to find the shortest path in a graph with weighted edges. Explain the relationship between the shortest path and the minimum cost flow problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the Ford-Fulkerson algorithm, solve a maximum flow problem in a network with 6 nodes and directed edges with specified capacities. Illustrate the steps involved and explain how the algorithm handles cycles and residual networks."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a transportation problem using the stepping-stone method. Provide a numerical example where you have supply, demand, and a cost matrix. Explain the method step-by-step and derive the optimal transportation plan that minimizes the total cost."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the equations for a transportation problem with constraints on the number of shipments that can be made along each route. Solve the problem using linear programming and explain how the constraints affect the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss how the concept of duality applies to the transportation problem. Provide a numerical example and formulate both the primal and dual problems. Solve both problems and verify the duality theorem by comparing the objective values."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the maximum flow problem in the context of a flow network with parallel edges. Solve a maximum flow problem where there are parallel edges between two nodes, and explain how the flow can be distributed across the edges while respecting capacity constraints."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Use the simplex method to solve a transportation problem with a non-degenerate solution. Provide a specific numerical example and explain the steps in the simplex algorithm, including the initialization of the basic feasible solution and the optimality condition."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Show how to formulate a shortest path problem as a network flow problem and solve it using linear programming. Provide a graph with multiple paths and demonstrate how network flow techniques can be applied to find the shortest path."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following transportation problem using the least cost method:\n    \\[\n    \\text{Minimize } Z = 4x_1 + 2x_2 + 3x_3 + 6x_4\n    \\]\n    subject to the constraints:\n    \\[\n    x_1 + x_2 + x_3 = 10, \\quad x_4 + x_2 = 5, \\quad x_3 + x_4 = 7\n    \\]\n    where \\(x_1, x_2, x_3, x_4\\) represent the amount of goods transported from four different sources to destinations with given supply and demand."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the minimum cost flow problem using the network simplex method for a given network with 5 nodes and multiple arcs. Derive the optimal flow and demonstrate the reduction in cost as the network adjusts."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a maximum flow problem with 4 nodes, where you are given the capacity of each edge and need to determine the maximum possible flow from the source to the sink. Use both the Ford-Fulkerson method and the Edmonds-Karp method to find the solution and compare their performance."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the equations for a transportation problem with multiple objectives. Solve the problem where you are given multiple cost matrices for different objectives, and you need to minimize the weighted sum of these objectives."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply Dijkstra's algorithm to find the shortest path from node A to node B in a graph with 7 nodes and weighted edges. Provide the step-by-step calculation and verify the correctness of the solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the significance of the dual variables in the context of the transportation problem. Provide a numerical example, solve the primal problem, and interpret the dual variables in terms of shadow prices for supply and demand constraints."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the conditions for optimality in the minimum cost flow problem. Solve the problem with 6 nodes and multiple supply and demand nodes, and verify the conditions using the dual variables."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the importance of the max-flow min-cut theorem in the context of network optimization. Solve a numerical example where you need to identify the maximum flow and the minimum cut of a network and show the connection between these two concepts."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a transportation problem with unbalanced supply and demand using the MODI method. Provide a numerical example where the supply does not equal the demand and show how to balance the system with dummy nodes."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply the Ford-Fulkerson method to a maximum flow problem where the capacity of each edge is an integer. Provide a flow network with 5 nodes and 6 edges, and solve for the maximum flow from the source to the sink."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a shortest path problem in a directed graph with negative edge weights using Bellman-Ford's algorithm. Provide a graph with 5 nodes and negative weights and solve for the shortest path from the source to all other nodes."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive and solve a transportation problem with fixed supply and demand quantities using the primal-dual method. Provide a specific example with supply, demand, and cost matrices, and show how the primal-dual method helps achieve the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the minimum cost flow problem using the primal-dual algorithm in a flow network. Provide a numerical example with 4 nodes and 5 edges, and show how the primal-dual method efficiently solves the flow optimization problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the difference between the simplex method and the network simplex method in solving the transportation problem. Provide a numerical example and demonstrate how both methods are applied to solve the same transportation problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the dual of the minimum cost flow problem and solve it using linear programming. Provide a flow network with supply and demand constraints and solve for the dual variables and the optimal flow distribution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a maximum flow problem with a multi-commodity flow network, where you are tasked with maximizing the flow of multiple commodities through a network. Provide a numerical example with 3 commodities and multiple flow constraints."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define a Nash equilibrium in the context of game theory. Discuss its significance and provide an example of a game where players have conflicting interests. Solve for the Nash equilibrium in a two-player game with a 3x3 payoff matrix, explaining the steps involved in the process."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "What is the difference between cooperative and non-cooperative games? Explain the concept of a cooperative game using the Shapley value and illustrate it with a real-world example. Contrast it with a non-cooperative game and discuss the implications for players' strategies."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the concept of a zero-sum game. Provide a mathematical formulation of a zero-sum game and derive the optimal strategies for both players in a two-player game. Solve for the equilibrium strategies using linear programming techniques."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the role of mixed strategies in game theory. Derive the mixed strategy Nash equilibrium for a simple game, such as the game of matching pennies, and explain the significance of randomization in players' strategies."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Using the concept of evolutionary game theory, explain how populations of individuals evolve in response to strategic interactions. Discuss the concepts of evolutionarily stable strategies (ESS) and their applications in biology, economics, and social sciences."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the conditions for a Nash equilibrium in a two-player game where both players have two strategies. Use a 2x2 matrix to demonstrate how to find the equilibrium and explain the conditions under which the game has a pure strategy Nash equilibrium."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain how the concept of Nash equilibrium can be extended to games with more than two players. Discuss the necessary conditions for a Nash equilibrium in multiplayer games and illustrate with an example from auction theory."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a zero-sum game using linear programming. Given a 3x3 payoff matrix, formulate the problem as a linear programming model and solve for the optimal strategies for both players. Discuss how the simplex method can be used to find the solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of a dominant strategy in game theory. Provide an example of a game where one player has a dominant strategy and explain how the existence of a dominant strategy affects the outcome of the game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define and explain the concept of a mixed strategy Nash equilibrium. Derive the mixed strategy Nash equilibrium for a 2x2 game matrix, where each player has two strategies. Provide a detailed step-by-step solution, including the probabilities associated with each strategy."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the application of game theory to pricing strategies in competitive markets. Solve a problem where two firms compete in setting prices for similar products and analyze the Nash equilibrium in this pricing game. Discuss the economic implications of the equilibrium prices."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the application of game theory in oligopolistic markets. Use the Cournot competition model to analyze the strategic interaction between two firms in an oligopoly. Solve for the Nash equilibrium output levels and discuss the implications for market prices."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium for a coordination game with two players. Provide a numerical example of a coordination game where the players can either cooperate or defect, and show the different possible Nash equilibria in this game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the Nash equilibrium in a 3x3 game matrix. Explain the steps involved in identifying the best responses for each player and show how the equilibrium can be found using dominated strategy elimination."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the concept of mixed strategy equilibria in zero-sum games. Derive the mixed strategy Nash equilibrium for a zero-sum game with two players, where each player has two strategies, and solve the corresponding linear programming problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of subgame perfect Nash equilibrium (SPNE) in dynamic games. Provide an example of a sequential game, such as the ultimatum game, and solve for the SPNE using backward induction."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a zero-sum game with a payoff matrix using the minimax theorem. Given a matrix with payoffs for two players, apply the minimax strategy and explain the reasoning behind the optimal strategy for each player."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply game theory to analyze a competitive advertising problem. Assume two firms must decide on their advertising strategies in a market, and analyze the Nash equilibrium of the game. Use a game matrix to solve for the equilibrium and discuss the strategic behavior of the firms."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Define the concept of evolutionary stability in game theory. Discuss the application of evolutionary game theory to the evolution of cooperation in social dilemmas, and derive the conditions under which a strategy becomes evolutionarily stable."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium in a 2x2 game with strictly dominated strategies. Use the concept of iterated elimination of strictly dominated strategies and show how it simplifies the process of finding the equilibrium in the game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a game theory problem involving mixed strategies where the players' payoffs depend on the actions of both players. Given a 2x2 game matrix, solve for the mixed strategy Nash equilibrium and explain the significance of the solution in the context of the game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium for a 2x2 zero-sum game using linear programming. Provide a numerical example where both players have two strategies and show the optimal strategies for both players using the simplex method."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the application of game theory in environmental policy-making. Analyze a game between a government and a corporation concerning pollution control, and solve for the Nash equilibrium in this context, discussing the economic and social implications of the outcome."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of the prisoners' dilemma in the context of game theory. Provide a detailed explanation of the game and solve for the Nash equilibrium. Analyze the social and economic consequences of the equilibrium strategy in a real-world scenario."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a competitive bidding problem using game theory. Given a situation where two firms submit bids for a contract, analyze the Nash equilibrium of the bidding game and determine the optimal bidding strategies for both players."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a mixed strategy game where both players have two strategies and the payoffs are non-symmetric. Use the linear programming method to derive the mixed strategy Nash equilibrium and explain the significance of each player's mixed strategy."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the application of game theory in political campaigns. Analyze a scenario where two candidates are competing for votes, and use game theory to solve for the Nash equilibrium in terms of campaign strategies."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the role of information asymmetry in game theory. Provide an example of a signaling game and derive the conditions under which one player will send a signal to another player. Solve for the equilibrium strategy in a game with asymmetric information."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium for a public goods game where players must decide how much to contribute to the provision of a public good. Explain the challenges of finding a cooperative solution in this game and discuss the implications for social welfare."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the concept of the centipede game and analyze its Nash equilibrium. Provide a detailed explanation of the game\u2019s structure, and derive the equilibrium strategies for both players in a finite version of the game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the solution to a zero-sum game with mixed strategies and explain how linear programming can be used to solve the game. Provide a specific 3x3 payoff matrix and solve for the mixed strategy equilibrium."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Analyze a game of chicken and derive the Nash equilibrium. Explain the strategic decisions involved in the game, and discuss the implications of the equilibrium in the context of decision-making under risk."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the Nash equilibrium in a sequential game using backward induction. Consider a game where two players move in turn, and each player must decide their strategy based on the previous player's move. Explain the process of backward induction to find the equilibrium strategy."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the application of game theory in auction theory. Analyze a sealed-bid auction and solve for the Nash equilibrium bidding strategy for the participants. Compare the equilibrium strategy to the strategy in an open-bid auction."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the Nash equilibrium in a game with incomplete information. Given a game where players have private information about their payoffs, use the Bayesian Nash equilibrium concept to derive the optimal strategies for each player."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply game theory to analyze the behavior of firms in a price war. Assume two firms are competing on prices, and use game theory to find the Nash equilibrium in the pricing game. Discuss how the equilibrium price affects both firms' profits."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium for a public goods game where players decide whether to contribute to a common fund. Explain the challenges of achieving the socially optimal outcome and the role of Nash equilibrium in this context."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the mixed strategy Nash equilibrium in a 2x2 game with unequal payoffs for both players. Use a mathematical approach to derive the probabilities of choosing each strategy and explain how the mixed strategy resolves the conflict between players."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Explain the concept of a weakly dominant strategy and solve for the Nash equilibrium in a game where one player has a weakly dominant strategy. Discuss how this affects the players' choices and the equilibrium outcome."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a zero-sum game using the minimax strategy. Given a game with two players and a 2x2 payoff matrix, apply the minimax theorem to determine the optimal strategies for both players and explain the reasoning behind the minimax solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Derive the Nash equilibrium for a game with three players, each of whom can either cooperate or defect. Use a payoff matrix to show how the players' strategies interact and determine the equilibrium outcomes."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve a real-world problem using evolutionary game theory. Consider a scenario in biology where two species are competing for resources. Use evolutionary game theory to model the interaction between the species and determine the evolutionarily stable strategies."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Discuss the concept of a mixed strategy Nash equilibrium in a zero-sum game with three strategies for each player. Use linear programming to derive the equilibrium strategies for both players and explain the solution process in detail."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following payoff matrix for a two-player game, where Player A chooses between strategies $S_1$ and $S_2$, and Player B chooses between strategies $T_1$ and $T_2$, find the Nash equilibrium of the game.\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (3, 2) & (1, 1) \\\\\n    S_2 & (0, 0) & (2, 3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider a game where two players can each choose between two actions, $A$ and $B$. The payoff matrix is given by:\n\n    \\[\n    \\begin{matrix}\n      & A & B \\\\\n    A & (4, 3) & (1, 4) \\\\\n    B & (2, 2) & (3, 1) \\\\\n    \\end{matrix}\n    \\]\n\n    Find the mixed strategy Nash equilibrium for this game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a zero-sum game with the following payoff matrix, where Player A and Player B both have two strategies, compute the optimal mixed strategy for Player A using linear programming:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (4, -4) & (-1, 1) \\\\\n    S_2 & (3, -3) & (2, -2) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following zero-sum game using the minimax theorem. Find the optimal strategy for both players:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (2, -2) & (3, -3) & (-1, 1) \\\\\n    S_2 & (0, 0) & (-2, 2) & (4, -4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For a game with the following payoff matrix, determine whether a pure strategy Nash equilibrium exists, and if so, find it:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (2, 3) & (3, 2) \\\\\n    S_2 & (1, 1) & (2, 3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the mixed strategy Nash equilibrium for the following game, where the players choose between strategies $X$ and $Y$:\n\n    \\[\n    \\begin{matrix}\n      & X & Y \\\\\n    X & (2, 1) & (1, 2) \\\\\n    Y & (3, 0) & (0, 3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a zero-sum game where Player A has strategies $S_1$, $S_2$, and $S_3$, and Player B has strategies $T_1$ and $T_2$, the payoff matrix is given by:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (5, -5) & (3, -3) \\\\\n    S_2 & (2, -2) & (4, -4) \\\\\n    S_3 & (1, -1) & (0, 0) \\\\\n    \\end{matrix}\n    \\]\n\n    Use linear programming to determine the optimal strategies for both players."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider a two-player game where Player A and Player B each have two strategies, $S_1$ and $S_2$. The payoff matrix is given by:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (4, 1) & (2, 3) \\\\\n    S_2 & (1, 2) & (3, 4) \\\\\n    \\end{matrix}\n    \\]\n\n    Find the Nash equilibrium for this game using the concept of best responses."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following game matrix, where the players choose between strategies $X$ and $Y$, compute the mixed strategy Nash equilibrium:\n\n    \\[\n    \\begin{matrix}\n      & X & Y \\\\\n    X & (1, 1) & (2, 3) \\\\\n    Y & (3, 2) & (0, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In the game represented by the following payoff matrix, where Player A has three strategies and Player B has two strategies, find the Nash equilibrium using linear programming:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (6, -6) & (1, -1) \\\\\n    S_2 & (2, -2) & (5, -5) \\\\\n    S_3 & (4, -4) & (3, -3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider a game where two players can choose between strategies $A$ and $B$. The following payoff matrix is given:\n\n    \\[\n    \\begin{matrix}\n      & A & B \\\\\n    A & (3, 2) & (0, 1) \\\\\n    B & (1, 0) & (2, 3) \\\\\n    \\end{matrix}\n    \\]\n\n    Find the mixed strategy Nash equilibrium for this game."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "For the following payoff matrix, determine whether a pure strategy Nash equilibrium exists:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (3, 2) & (1, 0) \\\\\n    S_2 & (0, 1) & (2, 3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the payoff matrix below, solve for the Nash equilibrium using the iterated elimination of strictly dominated strategies:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (5, 5) & (1, 0) \\\\\n    S_2 & (2, 1) & (4, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following game using the minimax strategy, and determine the optimal strategies for both players:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (2, -2) & (1, -1) & (0, 0) \\\\\n    S_2 & (4, -4) & (3, -3) & (5, -5) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find the mixed strategy Nash equilibrium for the following game, where Player A has strategies $S_1$, $S_2$, and $S_3$, and Player B has strategies $T_1$ and $T_2$:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (1, -1) & (3, -3) \\\\\n    S_2 & (4, -4) & (2, -2) \\\\\n    S_3 & (0, 0) & (5, -5) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following payoff matrix, find the Nash equilibrium of the game and analyze the strategies used by the players:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (5, 4) & (2, 1) & (1, 2) \\\\\n    S_2 & (3, 3) & (4, 5) & (2, 1) \\\\\n    S_3 & (2, 2) & (1, 3) & (5, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following game using linear programming to determine the optimal mixed strategy for Player A:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (4, -4) & (3, -3) & (2, -2) \\\\\n    S_2 & (1, -1) & (2, -2) & (3, -3) \\\\\n    S_3 & (5, -5) & (4, -4) & (3, -3) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a zero-sum game where both players choose between two strategies, find the mixed strategy Nash equilibrium for the following game:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (3, -3) & (1, -1) \\\\\n    S_2 & (2, -2) & (0, 0) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Find the Nash equilibrium for a game in which Player A can choose between $S_1$ and $S_2$, and Player B can choose between $T_1$ and $T_2$, with the following payoff matrix:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (2, 2) & (3, 1) \\\\\n    S_2 & (1, 3) & (4, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a strategic game with the following payoff matrix, compute the Nash equilibrium for the two players:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (2, 3) & (1, 1) & (4, 2) \\\\\n    S_2 & (3, 2) & (2, 4) & (5, 5) \\\\\n    S_3 & (4, 1) & (3, 3) & (1, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given a two-player game where the payoff matrix is as follows, solve for the Nash equilibrium using the concept of dominant strategies:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (4, 3) & (2, 1) \\\\\n    S_2 & (1, 2) & (3, 4) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Determine the mixed strategy Nash equilibrium for the following two-player game:\n\n    \\[\n    \\begin{matrix}\n      & A & B \\\\\n    A & (2, 3) & (1, 1) \\\\\n    B & (0, 1) & (3, 2) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "In a two-player game where the following payoff matrix is given, find the Nash equilibrium using the best response function:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 & T_3 \\\\\n    S_1 & (1, 2) & (3, 1) & (2, 3) \\\\\n    S_2 & (2, 1) & (4, 3) & (1, 2) \\\\\n    S_3 & (3, 2) & (1, 4) & (3, 1) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve for the Nash equilibrium using the concept of best responses for the following game:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (5, 6) & (2, 1) \\\\\n    S_2 & (3, 2) & (6, 5) \\\\\n    \\end{matrix}\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider the following linear programming problem:\n\n    Maximize \\( Z = 3x_1 + 2x_2 \\)\n\n    subject to the constraints:\n    \\[\n    2x_1 + x_2 \\leq 8\n    \\]\n    \\[\n    x_1 + 2x_2 \\geq 6\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]\n\n    Use the simplex method to find the optimal solution."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the duality theorem:\n\n    Minimize \\( Z = 4x_1 + 5x_2 \\)\n\n    subject to:\n    \\[\n    x_1 + 2x_2 \\geq 10\n    \\]\n    \\[\n    2x_1 + x_2 \\geq 8\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]\n    \n    Determine both the primal and dual optimal solutions."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following linear programming problem, use the method of linear programming with slack variables to convert it into standard form:\n\n    Maximize \\( Z = 6x_1 + 5x_2 \\)\n\n    subject to:\n    \\[\n    3x_1 + 2x_2 \\leq 12\n    \\]\n    \\[\n    x_1 + x_2 \\geq 4\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]\n\n    Then, solve the problem using the simplex method."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Formulate the following real-world problem as a linear programming problem: A company produces two products, \\( P_1 \\) and \\( P_2 \\). Each product requires time on two machines, Machine 1 and Machine 2. The time required for each product on each machine is given below:\n\n    \\[\n    \\text{Machine 1:} \\quad \\text{Product } P_1 \\text{ requires } 3 \\text{ hours}, \\text{ Product } P_2 \\text{ requires } 2 \\text{ hours}\n    \\]\n    \\[\n    \\text{Machine 2:} \\quad \\text{Product } P_1 \\text{ requires } 2 \\text{ hours}, \\text{ Product } P_2 \\text{ requires } 3 \\text{ hours}\n    \\]\n    \n    The company has a total of 12 hours available on Machine 1 and 15 hours available on Machine 2. The profit from each unit of \\( P_1 \\) is $4 and the profit from each unit of \\( P_2 \\) is $5. Formulate this as a linear programming problem to maximize profit."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the Simplex method:\n\n    Maximize \\( Z = 3x_1 + 2x_2 + x_3 \\)\n\n    subject to the constraints:\n    \\[\n    x_1 + x_2 + x_3 \\leq 6\n    \\]\n    \\[\n    2x_1 + x_2 \\geq 4\n    \\]\n    \\[\n    x_2 - x_3 \\leq 2\n    \\]\n    \\[\n    x_1, x_2, x_3 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Formulate the following transportation problem as a linear programming problem:\n\n    A company has 3 warehouses and 4 retailers. The supply at each warehouse and the demand at each retailer are given below, along with the cost per unit transported from each warehouse to each retailer:\n\n    \\[\n    \\text{Supply:} \\quad 50 \\text{ units at Warehouse 1}, 60 \\text{ units at Warehouse 2}, 40 \\text{ units at Warehouse 3}\n    \\]\n    \\[\n    \\text{Demand:} \\quad 40 \\text{ units at Retailer 1}, 50 \\text{ units at Retailer 2}, 30 \\text{ units at Retailer 3}, 30 \\text{ units at Retailer 4}\n    \\]\n    \\[\n    \\text{Cost matrix:} \\quad \\begin{matrix}\n    4 & 2 & 5 & 3 \\\\\n    3 & 4 & 1 & 2 \\\\\n    6 & 7 & 4 & 2\n    \\end{matrix}\n    \\]\n\n    Use linear programming to minimize the transportation cost."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following linear programming problem, apply the Big-M method to find the optimal solution:\n\n    Maximize \\( Z = 4x_1 + 3x_2 \\)\n\n    subject to:\n    \\[\n    x_1 + x_2 \\leq 8\n    \\]\n    \\[\n    x_1 - x_2 \\geq 2\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following integer linear programming problem using branch and bound method:\n\n    Maximize \\( Z = 5x_1 + 4x_2 \\)\n\n    subject to the constraints:\n    \\[\n    x_1 + 2x_2 \\leq 8\n    \\]\n    \\[\n    3x_1 + x_2 \\geq 6\n    \\]\n    \\[\n    x_1, x_2 \\text{ are integers, and } x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply the dual simplex method to solve the following linear programming problem:\n\n    Minimize \\( Z = 2x_1 + 3x_2 \\)\n\n    subject to the constraints:\n    \\[\n    2x_1 + x_2 \\geq 6\n    \\]\n    \\[\n    x_1 + 3x_2 \\geq 8\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using graphical methods:\n\n    Maximize \\( Z = x_1 + x_2 \\)\n\n    subject to the constraints:\n    \\[\n    x_1 + 2x_2 \\leq 8\n    \\]\n    \\[\n    3x_1 + x_2 \\leq 6\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Formulate the following problem as a linear programming problem: A company has 3 types of workers: Senior, Junior, and Trainee. Each worker can produce a certain number of units of a product per day as follows:\n\n    \\[\n    \\text{Senior:} \\quad 10 \\text{ units per day}\n    \\]\n    \\[\n    \\text{Junior:} \\quad 8 \\text{ units per day}\n    \\]\n    \\[\n    \\text{Trainee:} \\quad 5 \\text{ units per day}\n    \\]\n\n    The company needs to produce at least 300 units per day. Senior workers are paid $50 per day, Junior workers $30 per day, and Trainees $20 per day. The company wants to minimize the total cost while satisfying the production requirement. Formulate this as a linear programming problem."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Given the following primal linear programming problem, find the dual using the duality theorem:\n\n    Maximize \\( Z = 3x_1 + 2x_2 \\)\n\n    subject to the constraints:\n    \\[\n    2x_1 + x_2 \\leq 10\n    \\]\n    \\[\n    x_1 + 3x_2 \\leq 15\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Use the simplex method to solve the following linear programming problem:\n\n    Maximize \\( Z = 5x_1 + 4x_2 + 3x_3 \\)\n\n    subject to the constraints:\n    \\[\n    x_1 + x_2 + x_3 \\leq 10\n    \\]\n    \\[\n    3x_1 + 2x_2 \\geq 12\n    \\]\n    \\[\n    x_1, x_2, x_3 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the Simplex method:\n\n    Maximize \\( Z = 4x_1 + 5x_2 \\)\n\n    subject to the constraints:\n    \\[\n    x_1 + x_2 \\leq 10\n    \\]\n    \\[\n    2x_1 + 3x_2 \\geq 15\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Formulate the following real-world transportation problem as a linear programming problem: A retailer needs to transport goods from 3 suppliers to 4 customers. The supply, demand, and transportation costs are as follows:\n\n    \\[\n    \\text{Supplier 1:} 50 \\text{ units, Supplier 2:} 60 \\text{ units, Supplier 3:} 40 \\text{ units}\n    \\]\n    \\[\n    \\text{Customer 1:} 40 \\text{ units, Customer 2:} 50 \\text{ units, Customer 3:} 30 \\text{ units, Customer 4:} 30 \\text{ units}\n    \\]\n    \\[\n    \\text{Cost matrix:} \\quad \\begin{matrix}\n    4 & 6 & 8 & 5 \\\\\n    2 & 4 & 5 & 6 \\\\\n    7 & 9 & 5 & 3\n    \\end{matrix}\n    \\]\n\n    Minimize the total transportation cost."
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Apply the primal-dual interior-point method to solve the following linear programming problem:\n\n    Maximize \\( Z = 2x_1 + 3x_2 \\)\n\n    subject to:\n    \\[\n    3x_1 + 2x_2 \\leq 10\n    \\]\n    \\[\n    x_1 + 2x_2 \\geq 4\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Solve the following linear programming problem using the two-phase simplex method:\n\n    Maximize \\( Z = 5x_1 + 3x_2 \\)\n\n    subject to the constraints:\n    \\[\n    3x_1 + x_2 \\geq 8\n    \\]\n    \\[\n    x_1 + 4x_2 \\leq 10\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]"
    },
    {
        "chapter": "Linear Programming and Game Theory",
        "question": "Consider a game theory problem in which two players, Player 1 and Player 2, have the following payoff matrices:\n\n    Player 1's payoff matrix:\n    \\[\n    \\begin{matrix}\n    2 & -1 \\\\\n    4 & 3\n    \\end{matrix}\n    \\]\n\n    Player 2's payoff matrix:\n    \\[\n    \\begin{matrix}\n    3 & 2 \\\\\n    1 & -2\n    \\end{matrix}\n    \\]\n\n    Find the mixed strategy Nash equilibrium using linear programming. Determine the probabilities with which each player should choose their strategies to maximize their respective payoffs."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For the equations \\(x + y = 4\\), \\(2x - 2y = 4\\), draw the row picture (two intersecting\n          lines) and the column picture (combination of two columns equal to the column\n          vector \\((4,4)\\) on the right side)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve to find a combination of the columns that equals $b$ for the triangular system:\n    \\begin{align*}\n    u - v - w &= b_1 \\\\\n    v + w &= b_2 \\\\\n    w &= b_3.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Recommended) Describe the intersection of the three planes:\n    \\begin{align*}\n    u + v + w + z &= 6 \\\\\n    u + w + z &= 4 \\\\\n    u + w &= 2\n    \\end{align*}\n    (all in four-dimensional space). Is it a line, a point, or an empty set? What is the intersection if the fourth plane $u = -1$ is included? Find a fourth equation that leaves us with no solution."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Sketch these three lines and decide if the equations are solvable for the 3 by 2 system:\n    \\begin{align*}\n    x + 2y &= 2 \\\\\n    x - y &= 2 \\\\\n    y &= 1.\n    \\end{align*}\n    What happens if all right-hand sides are zero? Is there any nonzero choice of right-hand sides that allows the three lines to intersect at the same point?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find two points on the line of intersection of the three planes:\n    \\begin{align*}\n    t &= 0 \\\\\n    z &= 0 \\\\\n    x + y + z + t &= 1\n    \\end{align*}\n    in four-dimensional space."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "When $b = (2,5,7)$, find a solution $(u,v,w)$ to equation (4) different from the solution $(1,0,1)$ mentioned in the text."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Give two more right-hand sides in addition to $b = (2,5,7)$ for which equation (4) can be solved. Give two more right-hand sides in addition to $b = (2,5,6)$ for which it cannot be solved."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Explain why the system\n    \\begin{align*}\n    u + v + w &= 2 \\\\\n    u + 2v + 3w &= 1 \\\\\n    v + 2w &= 0\n    \\end{align*}\n    is singular by finding a combination of the three equations that adds up to $0 = 1$. What value should replace the last zero on the right side to allow the equations to have solutions\u2014and what is one of the solutions?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The column picture for the previous exercise (singular system) is\n    $$u \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} + v \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix} + w \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix} = b.$$\n    Show that the three columns on the left lie in the same plane by expressing the third column as a combination of the first two. What are all the solutions $(u,v,w)$ if $b$ is the zero vector $(0,0,0)$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Recommended) Under what condition on $y_1$, $y_2$, $y_3$ do the points $(0,y_1)$, $(1,y_2)$, $(2,y_3)$ lie on a straight line?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "These equations are certain to have the solution $x = y = 0$. For which values of $a$ is there a whole line of solutions?\n    \\begin{align*}\n    ax + 2y &= 0 \\\\\n    2x + ay &= 0\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Starting with $x + 4y = 7$, find the equation for the parallel line through $x = 0$, $y = 0$. Find the equation of another line that meets the first at $x = 3$, $y = 1$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Draw the two pictures in two planes for the equations $x - 2y = 0$ and $x + y = 6$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For two linear equations in three unknowns $x$, $y$, $z$, the row picture will show (2 or 3) (lines or planes) in (two or three)-dimensional space. The column picture is in (two or three)-dimensional space. The solutions normally lie on a \\_\\_\\_\\_\\_."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For four linear equations in two unknowns $x$ and $y$, the row picture shows four \\_\\_\\_\\_\\_. The column picture is in \\_\\_\\_\\_\\-dimensional space. The equations have no solution unless the vector on the right-hand side is a combination of \\_\\_\\_\\_\\_."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find a point with $z = 2$ on the intersection line of the planes $x + y + 3z = 6$ and $x - y + z = 4$. Find the point with $z = 0$ and a third point halfway between."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The first of these equations plus the second equals the third:\n    \\begin{align*}\n    x + y + z &= 2 \\\\\n    x + 2y + z &= 3 \\\\\n    2x + 3y + 2z &= 5.\n    \\end{align*}\n    The first two planes meet along a line. The third plane contains that line, because if $x$, $y$, $z$ satisfy the first two equations then they also \\_\\_\\_\\_\\_. The equations have infinitely many solutions (the whole line $L$). Find three solutions."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Move the third plane in Problem 17 to a parallel plane $2x + 3y + 2z = 9$. Now the three equations have no solution\u2014why not? The first two planes meet along the line $L$, but the third plane doesn\u2019t intersect that line."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "In Problem 17, the columns are $(1,1,2)$, $(1,2,3)$, and $(1,1,2)$. This is a \u201csingular case\u201d because the third column is \\_\\_\\_\\_\\_. Find two combinations of the columns that give $b = (2,3,5)$. This is only possible for $b = (4,6,c)$ if $c = \\_\\_\\_\\_\\_."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Normally, 4 \u201cplanes\u201d in four-dimensional space meet at a \\_\\_\\_\\_\\_. Normally, 4 column vectors in four-dimensional space can combine to produce \\(b$. What combination of $(1,0,0,0)$, $(1,1,0,0)$, $(1,1,1,0)$, $(1,1,1,1)$ produces $b = (3,3,3,2)$? What 4 equations for $x$, $y$, $z$, $t$ are you solving?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "When equation 1 is added to equation 2, which of these are changed: the planes in the row picture, the column picture, the coefficient matrix, the solution?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $(a,b)$ is a multiple of $(c,d)$ with $abcd \\neq 0$, show that $(a,c)$ is a multiple of $(b,d)$. This is surprisingly important: call it a challenge question. You could use numbers first to see how $a$, $b$, $c$, and $d$ are related. The question will lead to: If \n    $$A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$$\n    has dependent rows then it has dependent columns."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "In these equations, the third column (multiplying $w$) is the same as the right side $b$. The column form of the equations immediately gives what solution for $(u,v,w)$?\n    \\begin{align*}\n    6u + 7v + 8w &= 8 \\\\\n    4u + 5v + 9w &= 9 \\\\\n    2u - 2v + 7w &= 7.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What multiple $k$ of equation 1 should be subtracted from equation 2?\n    \\begin{align*}\n    2x + 3y &= 1 \\\\\n    10x + 9y &= 11.\n    \\end{align*}\n    After this elimination step, write down the upper triangular system and circle the two pivots. The numbers 1 and 11 have no influence on those pivots."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve the triangular system of Problem 1 by back-substitution, $y$ before $x$. Verify that $x$ times $(2,10)$ plus $y$ times $(3,9)$ equals $(1,11)$. If the right-hand side changes to $(4,44)$, what is the new solution?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What multiple $k$ of equation 2 should be subtracted from equation 3?\n    \\begin{align*}\n    2x - 4y &= 6 \\\\\n    -x + 5y &= 0.\n    \\end{align*}\n    After this elimination step, solve the triangular system. If the right-hand side changes to $(-6,0)$, what is the new solution?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What multiple $k$ of equation 1 should be subtracted from equation 2?\n    \\begin{align*}\n    ax + by &= f \\\\\n    cx + dy &= g.\n    \\end{align*}\n    The first pivot is $a$ (assumed nonzero). Elimination produces what formula for the second pivot? What is $y$? The second pivot is missing when $ad = bc$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Choose a right-hand side which gives no solution and another right-hand side which gives infinitely many solutions. What are two of those solutions?\n    \\begin{align*}\n    3x + 2y &= 10 \\\\\n    6x + 4y &= \\_\\_\\_\\_\\_.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Choose a coefficient $b$ that makes this system singular. Then choose a right-hand side $g$ that makes it solvable. Find two solutions in that singular case.\n    \\begin{align*}\n    2x + by &= 16 \\\\\n    4x + 8y &= g.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For which numbers $a$ does elimination break down (a) permanently, and (b) temporarily?\n    \\begin{align*}\n    ax + 3y &= -3 \\\\\n    4x + 6y &= 6.\n    \\end{align*}\n    Solve for $x$ and $y$ after fixing the second breakdown by a row exchange."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For which three numbers $k$ does elimination break down? Which is fixed by a row exchange? In each case, is the number of solutions $0$, $1$, or $\\infty$?\n    \\begin{align*}\n    kx + 3y &= 6 \\\\\n    3x + ky &= -6.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What test on $b_1$ and $b_2$ decides whether these two equations allow a solution? How many solutions will they have? Draw the column picture.\n    \\begin{align*}\n    3x - 2y &= b_1 \\\\\n    6x - 4y &= b_2.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Reduce this system to upper triangular form by two row operations:\n    \\begin{align*}\n    2x + 3y + z &= 8 \\\\\n    4x + 7y + 5z &= 20 \\\\\n    -2y + 2z &= 0.\n    \\end{align*}\n    Circle the pivots. Solve by back-substitution for $z$, $y$, $x$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Apply elimination (circle the pivots) and back-substitution to solve:\n    \\begin{align*}\n    2x - 3y &= 3 \\\\\n    4x - 5y + z &= 7 \\\\\n    2x - y - 3z &= 5.\n    \\end{align*}\n    List the three row operations: Subtract $k$ times row from row."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which number $d$ forces a row exchange, and what is the triangular system (not singular) for that $d$? Which $d$ makes this system singular (no third pivot)?\n    \\begin{align*}\n    2x + 5y + z &= 0 \\\\\n    4x + dy + z &= 2 \\\\\n    y - z &= 3.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which number $b$ leads later to a row exchange? Which $b$ leads to a missing pivot? In that singular case, find a nonzero solution $x$, $y$, $z$.\n    \\begin{align*}\n    x + by &= 0 \\\\\n    x - 2y - z &= 0 \\\\\n    y + z &= 0.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(a) Construct a $3 \\times 3$ system that needs two row exchanges to reach a triangular form and a solution.\n    \n    (b) Construct a $3 \\times 3$ system that needs a row exchange to keep going, but breaks down later."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If rows 1 and 2 are the same, how far can you get with elimination (allowing row exchange)? If columns 1 and 2 are the same, which pivot is missing?\n    \\begin{align*}\n    2x - y + z &= 0 \\\\\n    2x - y + z &= 0 \\\\\n    4x + y + z &= 2 \\\\\n    2x + 2y + z &= 0 \\\\\n    4x + 4y + z &= 0 \\\\\n    6x + 6y + z &= 2.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Construct a $3 \\times 3$ example that has 9 different coefficients on the left-hand side, but rows 2 and 3 become zero in elimination. How many solutions to your system with $b = (1,10,100)$ and how many with $b = (0,0,0)$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which number $q$ makes this system singular and which right-hand side $t$ gives it infinitely many solutions? Find the solution that has $z = 1$.\n    \\begin{align*}\n    x + 4y - 2z &= 1 \\\\\n    x + 7y - 6z &= 6 \\\\\n    3y + qz &= t.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Recommended) It is impossible for a system of linear equations to have exactly two solutions. Explain why.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $(x,y,z)$ and $(X,Y,Z)$ are two solutions, what is another one?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If 25 planes meet at two points, where else do they meet?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Three planes can fail to have an intersection point when no two planes are parallel. The system is singular if row 3 of $A$ is a linear combination of the first two rows. Find a third equation that can\u2019t be solved if $x+y+z = 0$ and $x-2y-z = 1$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the pivots and the solution for these four equations:\n    \\begin{align*}\n    2x + y &= 0 \\\\\n    x + 2y + z &= 0 \\\\\n    y + 2z + t &= 0 \\\\\n    z + 2t &= 5.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If you extend Problem 20 following the $1, 2, 1$ pattern or the $-1, 2, -1$ pattern, what is the fifth pivot? What is the $n$th pivot?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Apply elimination and back-substitution to solve:\n    \\begin{align*}\n    2u + 3v &= 0 \\\\\n    4u + 5v + w &= 3 \\\\\n    2u - v - 3w &= 5.\n    \\end{align*}\n    What are the pivots? List the three operations in which a multiple of one row is subtracted from another."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For the system\n    \\begin{align*}\n    u + v + w &= 2 \\\\\n    u + 3v + 3w &= 0 \\\\\n    u + 3v + 5w &= 2,\n    \\end{align*}\n    what is the triangular system after forward elimination, and what is the solution?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve the system and find the pivots when\n    \\begin{align*}\n    2u - v &= 0 \\\\\n    -u + 2v - w &= 0 \\\\\n    -v + 2w - z &= 0 \\\\\n    -w + 2z &= 5.\n    \\end{align*}\n    You may carry the right-hand side as a fifth column (and omit writing $u$, $v$, $w$, $z$ until the solution at the end)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Apply elimination to the system\n    \\begin{align*}\n    u + v + w &= -2 \\\\\n    3u + 3v - w &= 6 \\\\\n    u - v + w &= -1.\n    \\end{align*}\n    When a zero arises in the pivot position, exchange that equation for the one below it and proceed. What coefficient of $v$ in the third equation, in place of the present $-1$, would make it impossible to proceed\u2014and force elimination to break down?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve by elimination the system of two equations\n    \\begin{align*}\n    x - y &= 0 \\\\\n    3x + 6y &= 18.\n    \\end{align*}\n    Draw a graph representing each equation as a straight line in the $x-y$ plane; the lines intersect at the solution. Also, add one more line\u2014the graph of the new second equation which arises after elimination."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find three values of $ a $ for which elimination breaks down, temporarily or permanently, in the following system of equations:\n    \\begin{align*}\n        au + u &= 1 \\\\\n        4u + av &= 2.\n    \\end{align*}\n    Breakdown at the first step can be fixed by exchanging rows\u2014but not breakdown at the last step."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the third equation starts with a zero coefficient (it begins with $ 0u $), then no multiple of equation 1 will be subtracted from equation 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the third equation has zero as its second coefficient (it contains $ 0v $), then no multiple of equation 2 will be subtracted from equation 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the third equation contains $ 0u $ and $ 0v $, then no multiple of equation 1 or equation 2 will be subtracted from equation 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Very optional) Normally the multiplication of two complex numbers\n    $$(a+ib)(c+id) = (ac\u2212bd) +i(bc+ad)$$\n    involves the four separate multiplications $ ac, bd, bc, $ and $ ad $. Ignoring $ i $, can you compute $ ac\u2212bd $ and $ bc+ad $ with only three multiplications? (You may do additions, such as forming $ a+b $ before multiplying, without any penalty.)"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use elimination to solve the following systems:\n    \\begin{align*}\n        u + v + w &= 6 \\\\\n        u + 2v + 2w &= 11 \\\\\n        2u + 3v - 4w &= 3\n    \\end{align*}\n    and\n    \\begin{align*}\n        u + v + w &= 7 \\\\\n        u + 2v + 2w &= 10 \\\\\n        2u + 3v - 4w &= 3.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For which three numbers $ a $ will elimination fail to give three pivots in the following system?\n    $$ax + 2y + 3z = b_1 \\\\     ax + ay + 4z = b_2 \\\\     ax + ay + az = b_3.$$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find experimentally the average size (absolute value) of the first, second, and third pivots for MATLAB\u2019s $ \\text{lu}(\\text{rand}(3,3)) $. The average of the first pivot from $ \\text{abs}(A(1,1)) $ should be 0.5."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute the products:\n    $$\\begin{bmatrix}         4 & 0 & 1 \\\\         0 & 1 & 0 \\\\         4 & 0 & 1     \\end{bmatrix}     \\begin{bmatrix}         3 \\\\         4 \\\\         5     \\end{bmatrix}$$\n    and\n    $$\\begin{bmatrix}         1 & 0 & 0 \\\\         0 & 1 & 0 \\\\         0 & 0 & 1     \\end{bmatrix}     \\begin{bmatrix}         5 \\\\         -2 \\\\         3     \\end{bmatrix}$$\n    and\n    $$\\begin{bmatrix}         2 & 0 \\\\         1 & 3     \\end{bmatrix}     \\begin{bmatrix}         1 \\\\         1     \\end{bmatrix}.$$\n    For the third one, draw the column vectors $ (2,1) $ and $ (0,3) $. Multiplying by $ (1,1) $ just adds the vectors (do it graphically)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Working a column at a time, compute the products:\n    $$\\begin{bmatrix}         4 & 1 \\\\         5 & 1 \\\\         6 & 1     \\end{bmatrix}     \\begin{bmatrix}         1 \\\\         3     \\end{bmatrix}$$\n    and\n    $$\\begin{bmatrix}         1 & 2 & 3 \\\\         4 & 5 & 6 \\\\         7 & 8 & 9     \\end{bmatrix}     \\begin{bmatrix}         0 \\\\         1 \\\\         0     \\end{bmatrix}$$\n    and\n    $$\\begin{bmatrix}         4 & 3 \\\\         6 & 6 \\\\         8 & 9     \\end{bmatrix}     \\begin{bmatrix}         1 \\\\         2 \\\\         1 \\\\         3     \\end{bmatrix}.$$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find two inner products and a matrix product:\n    $$\\langle 1, -2, 7 \\rangle     \\begin{bmatrix}         1 \\\\         -2 \\\\         7     \\end{bmatrix}$$\n    and\n    $$\\langle 1, -2, 7 \\rangle     \\begin{bmatrix}         3 \\\\         5 \\\\         1     \\end{bmatrix}$$\n    and\n    $$\\begin{bmatrix}         1 \\\\         -2 \\\\         7     \\end{bmatrix}     \\langle 3, 5, 1 \\rangle.$$\n    The first gives the length of the vector (squared)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If an $ m \\times n $ matrix $ A $ multiplies an $ n $-dimensional vector $ x $, how many separate multiplications are involved? What if $ A $ multiplies an $ n \\times p $ matrix $ B $?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply $ Ax $ to find a solution vector $ x $ to the system $ Ax = \\text{zero vector} $. Can you find more solutions to $ Ax = 0 $?\n    $$Ax =      \\begin{bmatrix}         3 & -6 & 0 \\\\         0 & 2 & -2 \\\\         1 & -1 & -1     \\end{bmatrix}     \\begin{bmatrix}         2 \\\\         1 \\\\         1     \\end{bmatrix}.$$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down the $ 2 \\times 2 $ matrices $ A $ and $ B $ that have entries $ a_{ij} = i + j $ and $ b_{ij} = (-1)^{i+j} $.\n    Multiply them to find $ AB $ and $ BA $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Give $ 3 \\times 3 $ examples (not just the zero matrix) of:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "a diagonal matrix: $ a_{ij} = 0 $ if $ i \\neq j $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "a symmetric matrix: $ a_{ij} = a_{ji} $ for all $ i $ and $ j $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "an upper triangular matrix: $ a_{ij} = 0 $ if $ i > j $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "a skew-symmetric matrix: $ a_{ij} = -a_{ji} $ for all $ i $ and $ j $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Do these subroutines multiply $ Ax $ by rows or columns? Start with $ B(I) = 0 $:\n    \\begin{verbatim}\n    DO 10 I = 1, N\n        DO 10 J = 1, N\n            B(I) = B(I) + A(I,J) * X(J)\n    10 CONTINUE\n    \\end{verbatim}\n    and\n    \\begin{verbatim}\n    DO 10 J = 1, N\n        DO 10 I = 1, N\n            B(I) = B(I) + A(I,J) * X(J)\n    10 CONTINUE\n    \\end{verbatim}\n    The outputs $ Bx = Ax $ are the same. The second code is slightly more efficient in FORTRAN and much more efficient on a vector machine (the first changes single entries $ B(I) $, the second can update whole vectors)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the entries of $ A $ are $ a_{ij} $, use subscript notation to write:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "the first pivot."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "the multiplier $ m_{i1} $ of row 1 to be subtracted from row $ i $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "the new entry that replaces $ a_{ij} $ after that subtraction."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "the second pivot."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false? Give a specific counterexample when false.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If columns 1 and 3 of $ B $ are the same, so are columns 1 and 3 of $ AB $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If rows 1 and 3 of $ B $ are the same, so are rows 1 and 3 of $ AB $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If rows 1 and 3 of $ A $ are the same, so are rows 1 and 3 of $ AB $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ (AB)^2 = A^2B^2 $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The first row of $ AB $ is a linear combination of all the rows of $ B $. What are the coefficients in this combination, and what is the first row of $ AB $, if\n    $$A = \\begin{bmatrix}         2 & 1 & 4 \\\\         0 & -1 & 1     \\end{bmatrix}$$\n    and\n    $$B = \\begin{bmatrix}         1 & 1 \\\\         0 & 1 \\\\         1 & 0     \\end{bmatrix}?$$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The product of two lower triangular matrices is again lower triangular (all its entries above the main diagonal are zero). Confirm this with a $ 3 \\times 3 $ example, and then explain how it follows from the laws of matrix multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "By trial and error find examples of $ 2 \\times 2 $ matrices such that:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ A^2 = -I $, $ A $ having only real entries."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ B^2 = 0 $, although $ B \\neq 0 $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ CD = -DC $, not allowing the case $ CD = 0 $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ EF = 0 $, although no entries of $ E $ or $ F $ are zero."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Describe the rows of $ EA $ and the columns of $ AE $ if\n    $$E = \\begin{bmatrix}         1 & 7 \\\\         0 & 1     \\end{bmatrix}.$$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $ A $ commutes with every $ 2 \\times 2 $ matrix (i.e., $ AB = BA $), and in particular\n    $$A = \\begin{pmatrix}     a & b \\\\     c & d     \\end{pmatrix}$$\n    commutes with \n    $$B_1 = \\begin{pmatrix}     1 & 0 \\\\     0 & 0     \\end{pmatrix}$$\n    and \n    $$B_2 = \\begin{pmatrix}     0 & 1 \\\\     0 & 0     \\end{pmatrix}.$$\n    Show that $ a = d $ and $ b = c = 0 $. If $ AB = BA $ for all matrices $ B $, then $ A $ is a multiple of the identity."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $ x $ be the column vector $ (1, 0, \\ldots, 0)^T $. Show that the rule $ (AB)x = A(Bx) $ forces the first column of $ AB $ to equal $ A $ times the first column of $ B $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which of the following matrices are guaranteed to equal $ (A+B)^2 $?\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ A^2 + 2AB + B^2 $"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ A(A+B) + B(A+B) $"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ (A+B)(B+A) $"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ A^2 + AB + BA + B^2 $\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $ A $ and $ B $ are $ n \\times n $ matrices with all entries equal to 1, find $ (AB)_{ij} $. Summation notation turns the product $ AB $, and the law $ (AB)C = A(BC) $, into\n    $$(AB)_{ij} = \\sum_k a_{ik} b_{kj} \\quad \\text{and} \\quad \\sum_j \\left( \\sum_k a_{ik} b_{kj} \\right) c_{jl} = \\sum_k a_{ik} \\left( \\sum_j b_{kj} c_{jl} \\right).$$\n    Compute both sides if $ C $ is also $ n \\times n $, with every $ c_{jl} = 2 $."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A fourth way to multiply matrices is columns of $ A $ times rows of $ B $:\n    $$AB = (\\text{column 1})(\\text{row 1}) + \\cdots + (\\text{column } n)(\\text{row } n) = \\text{sum of simple matrices}.$$\n    Give a $ 2 \\times 2 $ example of this important rule for matrix multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The matrix that rotates the $ x-y $ plane by an angle $ \\theta $ is\n    $$A(\\theta) = \\begin{pmatrix}     \\cos \\theta & -\\sin \\theta \\\\     \\sin \\theta & \\cos \\theta     \\end{pmatrix}.$$\n    Verify that $ A(\\theta_1)A(\\theta_2) = A(\\theta_1 + \\theta_2) $ from the identities for $ \\cos(\\theta_1 + \\theta_2) $ and $ \\sin(\\theta_1 + \\theta_2) $. What is $ A(\\theta) $ times $ A(-\\theta) $?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the powers $ A^2, A^3 $ ($ A^2 \\times A $), $ B^2, B^3, C^2, C^3 $. What are $ A_k, B_k, $ and $ C_k $?\n    \\[\n    A = \\begin{pmatrix}\n    \\frac{1}{2} & \\frac{1}{2} \\\\\n    \\frac{1}{2} & \\frac{1}{2}\n    \\end{pmatrix}, \\quad\n    B = \\begin{pmatrix}\n    1 & 0 \\\\\n    0 & -1\n    \\end{pmatrix}, \\quad\n    C = AB = \\begin{pmatrix}       \n    \\frac{1}{2} & -\\frac{1}{2} \\\\\n    \\frac{1}{2} & -\\frac{1}{2}\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down the $3 \\times 3$ matrices that produce these elimination steps:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$E_{21}$ subtracts 5 times row 1 from row 2."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$E_{32}$ subtracts $-7$ times row 2 from row 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$P$ exchanges rows 1 and 2, then rows 2 and 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "In Problem 22, applying $E_{21}$ and then $E_{32}$ to the column $b = (1,0,0)$ gives $E_{32}E_{21}b =$ . Applying $E_{32}$ before $E_{21}$ gives $E_{21}E_{32}b =$ . When $E_{32}$ comes first, row \\_\\_\\_ feels no effect from row \\_\\_\\_."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which three matrices $E_{21}$, $E_{31}$, $E_{32}$ put $A$ into triangular form $U$?\n    \\[\n    A = \\begin{bmatrix} 1 & 1 & 0 \\\\ 4 & 6 & 1 \\\\ -2 & 2 & 0 \\end{bmatrix}\n    \\]\n    and $E_{32}E_{31}E_{21}A = U$. Multiply those $E$\u2019s to get one matrix $M$ that does elimination: $MA = U$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $a_{33} = 7$ and the third pivot is 5. If you change $a_{33}$ to 11, the third pivot is \\_\\_\\_. If you change $a_{33}$ to \\_\\_\\_, there is zero in the pivot position."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If every column of $A$ is a multiple of $(1,1,1)$, then $Ax$ is always a multiple of $(1,1,1)$. Do a $3 \\times 3$ example. How many pivots are produced by elimination?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What matrix $E_{31}$ subtracts 7 times row 1 from row 3? To reverse that step, $R_{31}$ should \\_\\_\\_ 7 times row \\_\\_\\_ to row \\_\\_\\_. Multiply $E_{31}$ by $R_{31}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$E_{21}$ subtracts row 1 from row 2 and then $P_{23}$ exchanges rows 2 and 3. What matrix $M = P_{23}E_{21}$ does both steps at once?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$P_{23}$ exchanges rows 2 and 3 and then $E_{31}$ subtracts row 1 from row 3. What matrix $M = E_{31}P_{23}$ does both steps at once? Explain why the $M$\u2019s are the same but the $E$\u2019s are different."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What $3 \\times 3$ matrix $E_{13}$ will add row 3 to row 1?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What matrix adds row 1 to row 3 and at the same time adds row 3 to row 1?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What matrix adds row 1 to row 3 and then adds row 3 to row 1?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply these matrices:\n    \\[\n    \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix}\n    \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}\n    \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\begin{bmatrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ -1 & 0 & 1 \\end{bmatrix}\n    \\begin{bmatrix} 1 & 2 & 3 \\\\ 1 & 3 & 1 \\\\ 1 & 4 & 0 \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "This $4 \\times 4$ matrix needs which elimination matrices $E_{21}$, $E_{32}$, and $E_{43}$?\n    \\[\n    A = \\begin{bmatrix} 2 & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 2 \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write these ancient problems in a 2 by 2 matrix form \\(Ax = b\\) and solve them:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(X\\) is twice as old as \\(Y\\) and their ages add to 39."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\((x, y) = (2, 5)\\) and \\((3, 7)\\) lie on the line \\(y = mx + c\\). Find \\(m\\) and \\(c\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The parabola \\(y = a + bx + cx^2\\) goes through the points \\((x, y) = (1, 4)\\), \\((2, 8)\\), and \\((3, 14)\\). Find and solve a matrix equation for the unknowns \\((a, b, c)\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply these matrices in the orders \\(EF\\) and \\(FE\\) and \\(E^2\\):\n    \\[\n    E = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    a & 1 & 0 \\\\\n    b & 0 & 1\n    \\end{bmatrix}, \\quad\n    F = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & c & 1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose all columns of \\(B\\) are the same. Then all columns of \\(EB\\) are the same, because each one is \\(E\\) times \\(\\dots\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose all rows of \\(B\\) are \\([1 \\ 2 \\ 4]\\). Show by example that all rows of \\(EB\\) are not \\([1 \\ 2 \\ 4]\\). It is true that those rows are \\(\\dots\\)"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(E\\) adds row 1 to row 2 and \\(F\\) adds row 2 to row 1, does \\(EF\\) equal \\(FE\\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The first component of $Ax$ is $\\sum a_{1j}x_j = a_{11}x_1 + \\dots + a_{1n}x_n$. Write formulas for:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The third component of $Ax$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The $(1,1)$ entry of $A^2$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $AB = I$ and $BC = I$, use the associative law to prove that $A = C$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A$ be a $3 \\times 5$ matrix, $B$ a $5 \\times 3$ matrix, $C$ a $5 \\times 1$ matrix, and $D$ a $3 \\times 1$ matrix, where all entries are $1$. Determine which of the following matrix operations are allowed and compute the results:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$BA$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$AB$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ABD$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$DBA$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$A(B+C)$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What rows or columns or matrices do you multiply to find:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The third column of $AB$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The first row of $AB$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The entry in row 3, column 4 of $AB$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The entry in row 1, column 1 of $CDE$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(For $3 \\times 3$ matrices) Choose the only $B$ such that for every matrix $A$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$BA = 4A$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$BA = 4B$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$BA$ has rows 1 and 3 of $A$ reversed and row 2 unchanged."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "All rows of $BA$ are the same as row 1 of $A$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A^2$ is defined then $A$ is necessarily square."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $AB$ and $BA$ are defined then $A$ and $B$ are square."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $AB$ and $BA$ are defined then $AB$ and $BA$ are square."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $AB = B$ then $A = I$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ is $m \\times n$, how many separate multiplications are involved when:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$A$ multiplies a vector $x$ with $n$ components?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$A$ multiplies an $n \\times p$ matrix $B$? Then $AB$ is $m \\times p$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$A$ multiplies itself to produce $A^2$? Here $m = n$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "To prove that $(AB)C = A(BC)$, use the column vectors $b_1, ..., b_n$ of $B$. First, suppose that $C$ has only one column $c$ with entries $c_1, ..., c_n$:\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$AB$ has columns $Ab_1, ..., Ab_n$, and $Bc$ has one column $c_1b_1 + \\cdots + c_n b_n$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Then $(AB)c = c_1 Ab_1 + \\cdots + c_n Ab_n$ equals $A(c_1 b_1 + \\cdots + c_n b_n) = A(Bc)$.\n    \\end{itemize}\n    Linearity gives equality of those two sums, and $(AB)c = A(Bc)$. The same is true for all other columns of $C$. Therefore, $(AB)C = A(BC)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply $AB$ using columns times rows:\n    \\[\n    AB = \\begin{bmatrix} 1 & 0 \\\\ 2 & 4 \\\\ 2 & 1 \\end{bmatrix} \\begin{bmatrix} 3 & 3 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}\n    \\]\n    Compute the result."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Block multiplication separates matrices into blocks (submatrices). If their shapes make block multiplication possible, then it is allowed. Replace these $x$'s by numbers and confirm that block multiplication succeeds:\n    \\[\n    \\begin{bmatrix} A & B \\end{bmatrix} \\begin{bmatrix} C \\\\ D \\end{bmatrix} = AC + BD\n    \\]\n    and \n    \\[\n    \\begin{bmatrix} x & x & x \\\\ x & x & x \\\\ x & x & x \\end{bmatrix} \\begin{bmatrix} x & x & x \\\\ x & x & x \\\\ x & x & x \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Draw the cuts in $A$ and $B$ and $AB$ to show how each of the four multiplication rules is really a block multiplication to find $AB$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Matrix $A$ times columns of $B$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Rows of $A$ times matrix $B$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Rows of $A$ times columns of $B$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Columns of $A$ times rows of $B$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Block multiplication says that elimination on column 1 produces:\n    \\begin{equation}\n        EA = \\begin{bmatrix} 1 & 0 \\\\ -c/a & I \\end{bmatrix} \\begin{bmatrix} a & b \\\\ c & D \\end{bmatrix} = \\begin{bmatrix} a & b \\\\ 0 & S \\end{bmatrix}.\n    \\end{equation}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Elimination for a $2 \\times 2$ block matrix: When $A^{-1}A = I$, multiply the first block row by $CA^{-1}$ and subtract from the second row to find the \\textit{Schur complement} $S$:\n    \\begin{equation}\n        \\begin{bmatrix} I & 0 \\\\ -CA^{-1} & I \\end{bmatrix} \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix} = \\begin{bmatrix} A & B \\\\ 0 & S \\end{bmatrix}.\n    \\end{equation}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "With $i^2 = -1$, the product $(A + iB)(x + iy)$ is given by:\n    \\begin{equation}\n        Ax + iBx + iAy - By.\n    \\end{equation}\n    Use blocks to separate the real part from the imaginary part that multiplies $i$:\n    \\begin{equation}\n        \\begin{bmatrix} A & -B \\\\ ? & ? \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} Ax - By \\\\ ? \\end{bmatrix}.\n    \\end{equation}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose you solve $Ax = b$ for three special right-hand sides $b$:\n    \\begin{align*}\n        Ax_1 &= \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, & Ax_2 &= \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, & Ax_3 &= \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n    \\end{align*}\n    If the solutions $x_1, x_2, x_3$ are the columns of a matrix $X$, what is $AX$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the three solutions in Question 51 are:\n    \\begin{align*}\n        x_1 &= (1,1,1), & x_2 &= (0,1,1), & x_3 &= (0,0,1),\n    \\end{align*}\n    solve $Ax = b$ when $b = (3,5,8)$. \\textbf{Challenge problem}: What is $A$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find all matrices \\( A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\) that satisfy \n    \\[\n    A \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} A.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If you multiply a northwest matrix \\( A \\) and a southeast matrix \\( B \\), what type of matrices are \\( AB \\) and \\( BA \\)? \n    \n    \\textit{Note: \u201cNorthwest\u201d and \u201csoutheast\u201d mean zeros below and above the antidiagonal going from \\((1,n)\\) to \\((n,1)\\).}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write the equation \\( 2x+3y+z+5t = 8 \\) as a matrix \\( A \\) (how many rows?) multiplying the column vector \\( (x,y,z,t) \\) to produce \\( b \\). \n    \n    \\textit{The solutions fill a plane in four-dimensional space. The plane is three-dimensional with no 4D volume.}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What \\( 2 \\times 2 \\) matrix \\( P_1 \\) projects the vector \\( (x,y) \\) onto the x-axis to produce \\( (x,0) \\)? What matrix \\( P_2 \\) projects onto the y-axis to produce \\( (0,y) \\)? \n    \n    \\textit{If you multiply \\((5,7)\\) by \\( P_1 \\) and then multiply by \\( P_2 \\), you get \\(( )\\) and \\(( )\\).}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write the inner product of \\( (1,4,5) \\) and \\( (x,y,z) \\) as a matrix multiplication \\( Ax \\). \\( A \\) has one row. \n    \n    \\textit{The solutions to \\( Ax = 0 \\) lie on a perpendicular to the vector. The columns of \\( A \\) are only in -dimensional space.}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "In MATLAB notation, write the commands that define the matrix \\( A \\) and the column vectors \\( x \\) and \\( b \\). What command would test whether or not \\( Ax = b \\)?\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad x = \\begin{bmatrix} 5 \\\\ -2 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 1 \\\\ 7 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The MATLAB commands \\texttt{A = eye(3)} and \\texttt{v = [3:5]'} produce the \\( 3 \\times 3 \\) identity matrix and the column vector \\( (3,4,5) \\). What are the outputs from \\( A * v \\) and \\( v' * v \\)? (Computer not needed!) If you ask for \\( v * A \\), what happens?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If you multiply the \\( 4 \\times 4 \\) all-ones matrix \\( A = \\texttt{ones(4,4)} \\) and the column \\( v = \\texttt{ones(4,1)} \\), what is \\( A * v \\)? (Computer not needed.) If you multiply \\( B = \\texttt{eye(4)} + \\texttt{ones(4,4)} \\) times \\( w = \\texttt{zeros(4,1)} + 2 * \\texttt{ones(4,1)} \\), what is \\( B * w \\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Invent a \\( 3 \\times 3 \\) magic matrix \\( M \\) with entries \\( 1,2,...,9 \\). All rows and columns and diagonals add to 15. The first row could be \\( 8, 3, 4 \\). What is \\( M \\) times \\( (1,1,1) \\)? What is the row vector \\( \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix} \\) times \\( M \\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "When is an upper triangular matrix nonsingular (a full set of pivots)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What multiple \\( m \\) of row 2 of \\( A \\) will elimination subtract from row 3 of \\( A \\)? Use the factored form:\n    \\[\n    A = \\begin{bmatrix} 1 & 0 & 0 \\\\ 2 & 1 & 0 \\\\ 1 & 4 & 1 \\end{bmatrix} \n    \\begin{bmatrix} 5 & 7 & 8 \\\\ 0 & 2 & 3 \\\\ 0 & 0 & 6 \\end{bmatrix}.\n    \\]\n    What will be the pivots? Will a row exchange be required?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply the matrix \\( L = E^{-1}F^{-1}G^{-1} \\) in equation (6) by \\( GFE \\) in equation (3):\n    \\[\n    \\begin{bmatrix} 1 & 0 & 0 \\\\ 2 & 1 & 0 \\\\ -1 & -1 & 1 \\end{bmatrix} \n    \\times \n    \\begin{bmatrix} 1 & 0 & 0 \\\\ -2 & 1 & 0 \\\\ -1 & 1 & 1 \\end{bmatrix}.\n    \\]\n    Multiply also in the opposite order. Why are the answers what they are?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Apply elimination to produce the factors \\( L \\) and \\( U \\) for:\n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 8 & 7 \\end{bmatrix},\n    \\quad A = \\begin{bmatrix} 3 & 1 & 1 \\\\ 1 & 3 & 1 \\\\ 1 & 1 & 3 \\end{bmatrix},\n    \\quad A = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 4 & 4 \\\\ 1 & 4 & 8 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Factor \\( A \\) into \\( LU \\), and write down the upper triangular system \\( Ux = c \\) which appears after elimination, for:\n    \\[\n    Ax = \\begin{bmatrix} 2 & 3 & 3 \\\\ 0 & 5 & 7 \\\\ 6 & 9 & 8 \\end{bmatrix} \n    \\begin{bmatrix} u \\\\ v \\\\ w \\end{bmatrix} = \n    \\begin{bmatrix} 2 \\\\ 2 \\\\ 5 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find \\( E^2 \\), \\( E^8 \\), and \\( E^{-1} \\) if:\n    \\[\n    E = \\begin{bmatrix} 1 & 0 \\\\ 6 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the products $FGH$ and $HGF$ if (with upper triangular zeros omitted):\n    \\[\n    F = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 2 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}, \\quad\n    G = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 2 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}, \\quad\n    H = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 2 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Second proof of $A = LU$) The third row of $U$ comes from the third row of $A$ by subtracting multiples of rows 1 and 2 (of $U$!):\n    \\[\n    \\text{row 3 of } U = \\text{row 3 of } A - \\ell_{31}(\\text{row 1 of } U) - \\ell_{32}(\\text{row 2 of } U).\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Why are rows of $U$ subtracted off and not rows of $A$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The equation above is the same as:\n        \\[\n        \\text{row 3 of } A = \\ell_{31}(\\text{row 1 of } U) + \\ell_{32}(\\text{row 2 of } U) + 1(\\text{row 3 of } U).\n        \\]\n        Which rule for matrix multiplication makes this row 3 of $L$ times $U$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(a) Under what conditions is the following product nonsingular?\n    \\[\n    A = \\begin{bmatrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 0 & -1 & 1 \\end{bmatrix}\n    \\begin{bmatrix} d_1 & 0 & 0 \\\\ 0 & d_2 & 0 \\\\ 0 & 0 & d_3 \\end{bmatrix}\n    \\begin{bmatrix} 1 & -1 & 0 \\\\ 0 & 1 & -1 \\\\ 0 & 0 & 1 \\end{bmatrix}.\n    \\]\n    (b) Solve the system $Ax = b$ starting with $Lc = b$:\n    \\[\n    \\begin{bmatrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 0 & -1 & 1 \\end{bmatrix}\n    \\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3 \\end{bmatrix} =\n    \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = b.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(a) Why does it take approximately $\\frac{n^2}{2}$ multiplication-subtraction steps to solve each of $Lc = b$ and $Ux = c$?\n    (b) How many steps does elimination use in solving 10 systems with the same $60 \\times 60$ coefficient matrix $A$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve as two triangular systems, without multiplying $LU$ to find $A$:\n    \\[\n    LUx = \\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & 1 & 0 \\\\ 1 & 0 & 1 \\end{bmatrix}\n    \\begin{bmatrix} 2 & 4 & 4 \\\\ 0 & 1 & 2 \\\\ 0 & 0 & 1 \\end{bmatrix}\n    \\begin{bmatrix} u \\\\ v \\\\ w \\end{bmatrix} =\n    \\begin{bmatrix} 2 \\\\ 0 \\\\ 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How could you factor $A$ into a product $UL$, upper triangular times lower triangular? Would they be the same factors as in $A = LU$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve by elimination, exchanging rows when necessary:\n    \\begin{align*}\n        u + 4v + 2w &= -2 \\\\\n        -2u - 8v + 3w &= 32 \\\\\n        v + w &= 1\n    \\end{align*}\n    and\n    \\begin{align*}\n        v + w &= 0 \\\\\n        u + v &= 0 \\\\\n        u + v + w &= 1.\n    \\end{align*}\n    Which permutation matrices are required?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down all six of the $3 \\times 3$ permutation matrices, including $P = I$. Identify their inverses, which are also permutation matrices. The inverses satisfy $PP^{-1} = I$ and are on the same list."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the $PA = LDU$ factorizations (and check them) for\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 1 \\\\ 1 & 0 & 1 \\\\ 2 & 3 & 4 \\end{bmatrix}\n    \\]\n    and\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 1 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find a $4 \\times 4$ permutation matrix that requires three row exchanges to reach the end of elimination (which is $U = I$)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The less familiar form $A = LPU$ exchanges rows only at the end:\n    \\[\n    A = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 3 \\\\ 2 & 5 & 8 \\end{bmatrix} \n    \\rightarrow L^{-1} A = \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 0 & 2 \\\\ 0 & 3 & 6 \\end{bmatrix} = PU = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix} \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 3 & 6 \\\\ 0 & 0 & 2 \\end{bmatrix}.\n    \\]\n    What is $L$ in this case? Comparing with $PA = LU$ in Box 1J, the multipliers now stay in place ($\\ell_{21}$ is 1 and $\\ell_{31}$ is 2 when $A = LPU$)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Decide whether the following systems are singular or nonsingular, and whether they have no solution, one solution, or infinitely many solutions:\n    \\begin{align*}\n        v - w &= 2 \\\\\n        u - v &= 2 \\\\\n        u - w &= 2\n    \\end{align*}\n    and\n    \\begin{align*}\n        v - w &= 0 \\\\\n        u - v &= 0 \\\\\n        u - w &= 0\n    \\end{align*}\n    and\n    \\begin{align*}\n        v + w &= 1 \\\\\n        u + v &= 1 \\\\\n        u + w &= 1.\n    \\end{align*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which numbers \\( a \\), \\( b \\), \\( c \\) lead to row exchanges? Which make the matrix singular?\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 0 \\\\\n    a & 8 & 3 \\\\\n    0 & b & 5\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    A = \\begin{bmatrix}\n    c & 2 \\\\\n    6 & 4\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Forward elimination changes\n    \\[\n    \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 2\n    \\end{bmatrix}\n    x = b \\quad \\text{to a triangular} \\quad\n    \\begin{bmatrix}\n    1 & 1 \\\\\n    0 & 1\n    \\end{bmatrix}\n    x = c:\n    \\]\n    \\[\n    \\text{Step 1: } x + y = 5, \\quad x + 2y = 7 \\quad \\longrightarrow \\quad x + y = 5, \\quad y = 2\n    \\]\n    \\[\n    \\begin{bmatrix}\n    1 & 1 & 5 \\\\\n    1 & 2 & 7\n    \\end{bmatrix}\n    \\quad \\longrightarrow \\quad\n    \\begin{bmatrix}\n    1 & 1 & 5 \\\\\n    0 & 1 & 2\n    \\end{bmatrix}\n    \\]\n    That step subtracted \\( 2 \\times \\) row 1 from row 2. The reverse step adds \\( 2 \\times \\) row 1 to row 2. The matrix for that reverse step is \\( L \\). Multiply this \\( L \\) times the triangular system\n    \\[\n    \\begin{bmatrix}\n    1 & 1 \\\\\n    0 & 1\n    \\end{bmatrix}\n    x =\n    \\begin{bmatrix}\n    5 \\\\\n    2\n    \\end{bmatrix}\n    \\quad \\text{to get} \\quad\n    \\begin{bmatrix}\n    \\cdots\n    \\end{bmatrix}\n    \\]\n    In letters, \\( L \\) multiplies \\( Ux = c \\) to give \\( \\cdots \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Move to 3 by 3) Forward elimination changes \\( Ax = b \\) to a triangular \\( Ux = c \\):\n    \\[\n    x + y + z = 5\n    \\]\n    \\[\n    x + 2y + 3z = 7\n    \\]\n    \\[\n    x + 3y + 6z = 11\n    \\quad \\longrightarrow \\quad\n    x + y + z = 5\n    \\]\n    \\[\n    y + 2z = 2 \\quad\n    2y + 5z = 6\n    \\]\n    \\[\n    x + y + z = 5\n    \\]\n    \\[\n    y + 2z = 2 \\quad\n    z = 2\n    \\]\n    The equation \\( z = 2 \\) in \\( Ux = c \\) comes from the original \\( x + 3y + 6z = 11 \\) in \\( Ax = b \\) by subtracting \\( 3 \\times \\) equation 1 and \\( 2 \\times \\) equation 2.\n    Reverse that to recover:\n    \\[\n    [1, 3, 6, 11] \\quad \\text{in} \\quad [A, b]\n    \\quad \\text{from the final} \\quad\n    [1, 1, 1, 5], \\quad [0, 1, 2, 2], \\quad [0, 0, 1, 2]\n    \\quad \\text{in} \\quad [U, c]\n    \\]\n    Row 3 of \\( A, b \\) is:\n    \\[\n    (\\lambda_{31} \\, \\text{Row 1} + \\lambda_{32} \\, \\text{Row 2} + \\text{Row 3}) \\quad \\text{of} \\quad [U, c].\n    \\]\n    In matrix notation, this is multiplication by \\( L \\). So \\( A = LU \\) and \\( b = Lc \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What are the 3 by 3 triangular systems \\( Lc = b \\) and \\( Ux = c \\) from Problem 21? Check that \\( c = (5, 2, 2) \\) solves the first one. Which \\( x \\) solves the second one?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What two elimination matrices \\( E_{21} \\) and \\( E_{32} \\) put \\( A \\) into upper triangular form \\( E_{32} E_{21} A = U \\)? Multiply by \\( E_{31}^{-1} \\) and \\( E_{21}^{-1} \\) to factor \\( A \\) into \\( LU = E_{21}^{-1} E_{32}^{-1} U \\):\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    2 & 4 & 5 \\\\\n    0 & 4 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What three elimination matrices \\( E_{21} \\), \\( E_{31} \\), \\( E_{32} \\) put \\( A \\) into upper triangular form \\( E_{32} E_{31} E_{21} A = U \\)? Multiply by \\( E_{32}^{-1} \\), \\( E_{31}^{-1} \\), and \\( E_{21}^{-1} \\) to factor \\( A \\) into \\( LU \\), where \\( L = E_{21}^{-1} E_{31}^{-1} E_{32}^{-1} \\). Find \\( L \\) and \\( U \\):\n    \\[\n    A = \\begin{bmatrix}\n    1 & 0 & 1 \\\\\n    2 & 2 & 2 \\\\\n    3 & 4 & 5\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "When zero appears in a pivot position, A = LU is not possible! (We need nonzero pivots \\( d, f, i \\) in \\( U \\).) Show directly why these are both impossible:\n    \\[\n    \\begin{bmatrix}\n    0 & 1 \\\\\n    2 & 3\n    \\end{bmatrix}\n    = \n    \\begin{bmatrix}\n    1 & 0 \\\\\n    \\ell & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    d & e & g \\\\\n    f & h & i\n    \\end{bmatrix}.\n    \\]\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    1 & 1 & 2 \\\\\n    1 & 2 & 1\n    \\end{bmatrix}\n    = \n    \\begin{bmatrix}\n    1 & \\ell & m \\\\\n    1 & n & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    d & e & g \\\\\n    f & h & i\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which number \\( c \\) leads to zero in the second pivot position? A row exchange is needed and \\( A = LU \\) is not possible. Which \\( c \\) produces zero in the third pivot position? Then a row exchange can't help and elimination fails:\n    \\[\n    A = \\begin{bmatrix}\n    1 & c & 0 \\\\\n    2 & 4 & 1 \\\\\n    3 & 5 & 1\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What are \\( L \\) and \\( D \\) for this matrix \\( A \\)? What is \\( U \\) in \\( A = LU \\) and what is the new \\( U \\) in \\( A = LDU \\)?\n    \\[\n    A = \\begin{bmatrix}\n    2 & 4 & 8 \\\\\n    0 & 3 & 9 \\\\\n    0 & 0 & 7\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A and B are symmetric across the diagonal (because \\( 4 = 4 \\)). Find their triple factorizations \\( LDU \\) and say how \\( U \\) is related to \\( L \\) for these symmetric matrices:\n    \\[\n    A = \\begin{bmatrix}\n    2 & 4 \\\\\n    4 & 11\n    \\end{bmatrix},\n    \\quad\n    B = \\begin{bmatrix}\n    1 & 4 & 0 \\\\\n    4 & 12 & 4 \\\\\n    0 & 4 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Recommended) Compute \\( L \\) and \\( U \\) for the symmetric matrix\n    \\[\n    A = \\begin{bmatrix}\n    a & a & a & a \\\\\n    a & b & b & b \\\\\n    a & b & c & c \\\\\n    a & b & c & d\n    \\end{bmatrix}.\n    \\]\n    Find four conditions on \\( a, b, c, d \\) to get \\( A = LU \\) with four pivots."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find \\( L \\) and \\( U \\) for the nonsymmetric matrix\n    \\[\n    A = \\begin{bmatrix}\n    a & r & r & r \\\\\n    a & b & s & s \\\\\n    a & b & c & t \\\\\n    a & b & c & d\n    \\end{bmatrix}.\n    \\]\n    Find the four conditions on \\( a, b, c, d, r, s, t \\) to get \\( A = LU \\) with four pivots."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Tridiagonal matrices have zero entries except on the main diagonal and the two adjacent diagonals. Factor these into \\( A = LU \\) and \\( A = LDV \\):\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    1 & 2 & 1 \\\\\n    0 & 1 & 2\n    \\end{bmatrix},\n    \\quad\n    A = \\begin{bmatrix}\n    a & a & 0 \\\\\n    a & a+b & b \\\\\n    0 & b & b+c\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve the triangular system \\( Lc = b \\) to find \\( c \\). Then solve \\( Ux = c \\) to find \\( x \\):\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 \\\\\n    4 & 1\n    \\end{bmatrix},\n    \\quad\n    U = \\begin{bmatrix}\n    2 & 4 \\\\\n    0 & 1\n    \\end{bmatrix},\n    \\quad\n    b = \\begin{bmatrix}\n    2 \\\\\n    11\n    \\end{bmatrix}.\n    \\]\n    For safety, find \\( A = LU \\) and solve \\( Ax = b \\) as usual. Circle \\( c \\) when you see it."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve \\( Lc = b \\) to find \\( c \\). Then solve \\( Ux = c \\) to find \\( x \\). What was \\( A \\)?\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    1 & 1 & 0 \\\\\n    1 & 1 & 1\n    \\end{bmatrix},\n    \\quad\n    U = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    0 & 1 & 1 \\\\\n    0 & 0 & 1\n    \\end{bmatrix},\n    \\quad\n    b = \\begin{bmatrix}\n    4 \\\\\n    5 \\\\\n    6\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A \\) and \\( B \\) have nonzeros in the positions marked by \\( x \\), which zeros are still zero in their factors \\( L \\) and \\( U \\)?\n    \\[\n    A = \\begin{bmatrix}\n    x & x & x & x \\\\\n    x & x & x & 0 \\\\\n    0 & x & x & x \\\\\n    0 & 0 & x & x\n    \\end{bmatrix},\n    \\quad\n    B = \\begin{bmatrix}\n    x & x & x & 0 \\\\\n    x & x & 0 & x \\\\\n    x & 0 & x & x \\\\\n    0 & x & x & x\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Important) If \\( A \\) has pivots 2, 7, 6 with no row exchanges, what are the pivots for the upper left 2 by 2 submatrix \\( B \\) (without row 3 and column 3)? Explain why."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Starting from a 3 by 3 matrix \\( A \\) with pivots 2, 7, 6, add a fourth row and column to produce \\( M \\). What are the first three pivots for \\( M \\), and why? What fourth row and column are sure to produce 9 as the fourth pivot?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use \\( \\text{chol}(\\text{pascal}(5)) \\) to find the triangular factors of MATLAB\u2019s \\( \\text{pascal}(5) \\). Row exchanges in \\( [L, U] = \\text{lu}(\\text{pascal}(5)) \\) spoil Pascal\u2019s pattern!"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Review) For which numbers \\( c \\) is \\( A = LU \\) impossible\u2014with three pivots?\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 0 \\\\\n    3 & c & 1 \\\\\n    0 & 1 & 1\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Estimate the time difference for each new right-hand side \\( b \\) when \\( n = 800 \\). Create \\( A = \\text{rand}(800) \\) and \\( b = \\text{rand}(800,1) \\) and \\( B = \\text{rand}(800,9) \\). Compare the times from\n    \\[\n    \\text{tic}; A \\backslash b; \\text{toc}\n    \\]\n    and\n    \\[\n    \\text{tic}; A \\backslash B; \\text{toc}\n    \\]\n    (which solves for 9 right sides)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "There are 12 \u201ceven\u201d permutations of \\( (1,2,3,4) \\), with an even number of exchanges. Two of them are \\( (1,2,3,4) \\) with no exchanges and \\( (4,3,2,1) \\) with two exchanges. List the other ten. Instead of writing each 4 by 4 matrix, use the numbers 4, 3, 2, 1 to give the position of the 1 in each row."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How many exchanges will permute \\( (5,4,3,2,1) \\) back to \\( (1,2,3,4,5) \\)? How many exchanges to change \\( (6,5,4,3,2,1) \\) to \\( (1,2,3,4,5,6) \\)? One is even and the other is odd. For \\( (n, \\ldots, 1) \\) to \\( (1, \\ldots, n) \\), show that \\( n = 100 \\) and 101 are even, \\( n = 102 \\) and 103 are odd."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( P_1 \\) and \\( P_2 \\) are permutation matrices, so is \\( P_1P_2 \\). This still has the rows of \\( I \\) in some order. Give examples with \\( P_1P_2 \\neq P_2P_1 \\) and \\( P_3P_4 = P_4P_3 \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Try this question.) Which permutation makes \\( PA \\) upper triangular? Which permutations make \\( P_1AP_2 \\) lower triangular? Multiplying \\( A \\) on the right by \\( P_2 \\) exchanges the rows of \\( A \\).\n    \\[\n    A = \\begin{bmatrix}\n    0 & 0 & 6 \\\\\n    1 & 2 & 3 \\\\\n    0 & 4 & 5\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find a 3 by 3 permutation matrix with \\( P^3 = I \\) (but not \\( P = I \\)). Find a 4 by 4 permutation \\( P_b \\) with \\( P_b^4 \\neq I \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If you take powers of a permutation, why is some \\( P^k \\) eventually equal to \\( I \\)? Find a 5 by 5 permutation \\( P \\) so that the smallest power to equal \\( I \\) is \\( P^6 \\). (This is a challenge question. Combine a 2 by 2 block with a 3 by 3 block.)"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The matrix \\( P \\) that multiplies \\( (x,y,z) \\) to give \\( (z,x,y) \\) is also a rotation matrix. Find \\( P \\) and \\( P^3 \\). The rotation axis \\( a = (1,1,1) \\) doesn\u2019t move, it equals \\( Pa \\). What is the angle of rotation from \\( v = (2,3,-5) \\) to \\( Pv = (-5,2,3) \\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( P \\) is any permutation matrix, find a nonzero vector \\( x \\) so that \\( (I - P)x = 0 \\). (This will mean that \\( I - P \\) has no inverse, and has determinant zero.)"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( P \\) has 1s on the antidiagonal from \\( (1,n) \\) to \\( (n,1) \\), describe \\( PAP \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the inverses (no special system required) of\n    \\[\n    A_1 = \\begin{bmatrix} 0 & 2 \\\\ 3 & 0 \\end{bmatrix}, \\quad A_2 = \\begin{bmatrix} 2 & 0 \\\\ 4 & 2 \\end{bmatrix}, \\quad A_3 = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the inverses of the permutation matrices\n        \\[\n        P_1 = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix} \\quad \\text{and} \\quad P_2 = \\begin{bmatrix} 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Explain for permutations why \\( P^{-1} \\) is always the same as \\( P^T \\). Show that the 1s are in the right places to give \\( P P^T = I \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "From \\( AB = C \\), find a formula for \\( A^{-1} \\). Also find \\( A^{-1} \\) from \\( PA = LU \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A \\) is invertible and \\( AB = AC \\), prove quickly that \\( B = C \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} \\), find an example with \\( AB = AC \\) but \\( B \\neq C \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the inverse of \\( A^2 \\) is \\( B \\), show that the inverse of \\( A \\) is \\( AB \\). (Thus \\( A \\) is invertible whenever \\( A^2 \\) is invertible.)"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use the Gauss-Jordan method to invert\n    \\[\n    A_1 = \\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad\n    A_2 = \\begin{bmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{bmatrix}, \\quad\n    A_3 = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find three 2 by 2 matrices, other than \\( A = I \\) and \\( A = -I \\), that are their own inverses: \\( A^2 = I \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that \\( A = \\begin{bmatrix} 1 & 1 \\\\ 3 & 3 \\end{bmatrix} \\) has no inverse by solving \\( Ax = 0 \\), and by failing to solve\n    \\[\n    \\begin{bmatrix} 1 & 1 \\\\ 3 & 3 \\end{bmatrix} \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose elimination fails because there is no pivot in column 3:\n    \\[\n    A = \\begin{bmatrix} \n    2 & 1 & 4 & 6 \\\\\n    0 & 3 & 8 & 5 \\\\\n    0 & 0 & 0 & 7 \\\\\n    0 & 0 & 0 & 9\n    \\end{bmatrix}.\n    \\]\n    Show that \\( A \\) cannot be invertible. The third row of \\( A^{-1} \\), multiplying \\( A \\), should give the third row \\( \\begin{bmatrix} 0 & 0 & 1 & 0 \\end{bmatrix} \\) of \\( A^{-1}A = I \\). Why is this impossible?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the inverses (in any legal way) of\n    \\[\n    A_1 = \\begin{bmatrix} \n    0 & 0 & 0 & 1 \\\\\n    0 & 0 & 2 & 0 \\\\\n    0 & 3 & 0 & 0 \\\\\n    4 & 0 & 0 & 0\n    \\end{bmatrix}, \\quad\n    A_2 = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    -\\frac{1}{2} & 1 & 0 & 0 \\\\\n    0 & -\\frac{2}{3} & 1 & 0 \\\\\n    0 & 0 & -\\frac{3}{4} & 1\n    \\end{bmatrix}, \\quad\n    A_3 = \\begin{bmatrix}\n    a & b & 0 & 0 \\\\\n    c & d & 0 & 0 \\\\\n    0 & 0 & a & b \\\\\n    0 & 0 & c & d\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Give examples of \\( A \\) and \\( B \\) such that\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\( A + B \\) is not invertible although \\( A \\) and \\( B \\) are invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\( A + B \\) is invertible although \\( A \\) and \\( B \\) are not invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "All of \\( A \\), \\( B \\), and \\( A + B \\) are invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "In the last case, use \\( A^{-1}(A+B)B^{-1} = B^{-1} + A^{-1} \\) to show that \\( C = B^{-1} + A^{-1} \\) is also invertible\u2014and find a formula for \\( C^{-1} \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A \\) is invertible, which properties of \\( A \\) remain true for \\( A^{-1} \\)?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\( A \\) is triangular."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\( A \\) is symmetric."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\( A \\) is tridiagonal."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "All entries are whole numbers."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "All entries are fractions (including numbers like \\( \\frac{3}{1} \\))."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} \\), compute \\( A^T B \\), \\( B^T A \\), \\( AB^T \\), and \\( BA^T \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( B \\) is square, show that \\( A = B + B^T \\) is always symmetric and \\( K = B - B^T \\) is always skew-symmetric\u2014which means that \\( K^T = -K \\). Find these matrices \\( A \\) and \\( K \\) when\n    \\[\n    B = \\begin{bmatrix} 1 & 3 \\\\ 1 & 1 \\end{bmatrix},\n    \\]\n    and write \\( B \\) as the sum of a symmetric matrix and a skew-symmetric matrix."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How many entries can be chosen independently in a symmetric matrix of order \\( n \\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How many entries can be chosen independently in a skew-symmetric matrix \\( (K^T = -K) \\) of order \\( n \\)? The diagonal of \\( K \\) is zero!"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A = LDU \\), with 1s on the diagonals of \\( L \\) and \\( U \\), what is the corresponding factorization of \\( A^T \\)? Note that \\( A \\) and \\( A^T \\) (square matrices with no row exchanges) share the same pivots."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What triangular systems will give the solution to \\( A^T y = b \\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A = L_1 D_1 U_1 \\) and \\( A = L_2 D_2 U_2 \\), prove that \\( L_1 = L_2 \\), \\( D_1 = D_2 \\), and \\( U_1 = U_2 \\). If \\( A \\) is invertible, the factorization is unique.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Derive the equation \\( L_1^{-1} L_2 D_2 = D_1 U_1 U_2^{-1} \\), and explain why one side is lower triangular and the other side is upper triangular."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compare the main diagonals and then compare the off-diagonals."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Under what conditions on their entries are $A$ and $B$ invertible?\n    \\[\n    A = \\begin{bmatrix} \n    a & b & c \\\\\n    d & e & 0 \\\\\n    f & 0 & 0\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} \n    a & b & 0 \\\\\n    c & d & 0 \\\\\n    0 & 0 & e\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute the symmetric $LDL^T$ factorization of\n    \\[\n    A = \\begin{bmatrix} \n    1 & 3 & 5 \\\\\n    3 & 12 & 18 \\\\\n    5 & 18 & 30 \n    \\end{bmatrix}\n    \\]\n    and \n    \\[\n    A = \\begin{bmatrix} a & b \\\\ b & d \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the inverse of\n    \\[\n    A = \\begin{bmatrix} \n    1 & 0 & 0 & 0 \\\\\n    \\frac{1}{4} & 1 & 0 & 0 \\\\\n    \\frac{1}{3} & \\frac{1}{3} & 1 & 0 \\\\\n    \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} & 1\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ and $B$ are square matrices, show that $I - BA$ is invertible if $I - AB$ is invertible. Start from\n    \\[\n    B(I - AB) = (I - BA)B.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the inverses (directly or from the $2 \\times 2$ formula) of $A$, $B$, $C$:\n    \\[\n    A = \\begin{bmatrix} 0 & 3 \\\\ 4 & 6 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} a & b \\\\ b & 0 \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix} 3 & 4 \\\\ 5 & 7 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve for the columns of $A^{-1}$:\n    \\[\n    A^{-1} = \\begin{bmatrix} x & t \\\\ y & z \\end{bmatrix}.\n    \\]\n    Solve:\n    \\[\n    \\begin{bmatrix} 10 & 20 \\\\ 20 & 50 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\n    \\]\n    \\[\n    \\begin{bmatrix} 10 & 20 \\\\ 20 & 50 \\end{bmatrix} \\begin{bmatrix} t \\\\ z \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that \\(\n    \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\end{bmatrix}\n    \\) has no inverse by trying to solve for the column \\((x,y)\\):\n    \\[\n    \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\end{bmatrix} \\begin{bmatrix} x & t \\\\ y & z \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ has row 1 + row 2 = row 3, show that $A$ is not invertible:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Explain why $Ax = (1,0,0)$ cannot have a solution."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which right-hand sides $(b_1, b_2, b_3)$ might allow a solution to $Ax = b$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What happens to row 3 in elimination?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ has column 1 + column 2 = column 3, show that $A$ is not invertible:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find a nonzero solution $x$ to $Ax = 0$. The matrix is $3 \\times 3$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Elimination keeps column 1 + column 2 = column 3. Explain why there is no third pivot."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $A$ is invertible and you exchange its first two rows to reach $B$. Is the new matrix $B$ invertible? How would you find $B^{-1}$ from $A^{-1}$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the product $M = ABC$ of three square matrices is invertible, then $A, B, C$ are invertible. Find a formula for $B^{-1}$ that involves $M^{-1}$ and $A$ and $C$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Prove that a matrix with a column of zeros cannot have an inverse."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ times $\\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}$. What is the inverse of each matrix if $ad \\neq bc$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What matrix $E$ has the same effect as these three steps? Subtract row 1 from row 2, subtract row 1 from row 3, then subtract row 2 from row 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What single matrix $L$ has the same effect as these three reverse steps? Add row 2 to row 3, add row 1 to row 3, then add row 1 to row 2."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the numbers $a$ and $b$ that give the inverse of $5 \\cdot I_4 - \\mathbf{1}_{4 \\times 4}$:\n    \\[\n    \\begin{bmatrix}\n        4 & -1 & -1 & -1 \\\\\n        -1 & 4 & -1 & -1 \\\\\n        -1 & -1 & 4 & -1 \\\\\n        -1 & -1 & -1 & 4 \n    \\end{bmatrix}^{-1} = \n    \\begin{bmatrix}\n        a & b & b & b \\\\\n        b & a & b & b \\\\\n        b & b & a & b \\\\\n        b & b & b & a\n    \\end{bmatrix}\n    \\]\n    What are $a$ and $b$ in the inverse of $6 \\cdot I_5 - \\mathbf{1}_{5 \\times 5}$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that $A = 4 \\cdot I_4 - \\mathbf{1}_{4 \\times 4}$ is not invertible: Multiply $A \\cdot \\mathbf{1}_{4 \\times 1}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "There are sixteen $2 \\times 2$ matrices whose entries are 1s and 0s. How many of them are invertible?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Change $I$ into $A^{-1}$ as you reduce $A$ to $I$ (by row operations):\n    \\[\n    \\left[ A \\mid I \\right] = \\begin{bmatrix} 1 & 3 & | & 1 & 0 \\\\ 2 & 7 & | & 0 & 1 \\end{bmatrix}\n    \\]\n    and\n    \\[\n    \\left[ A \\mid I \\right] = \\begin{bmatrix} 1 & 4 & | & 1 & 0 \\\\ 3 & 9 & | & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Follow the 3 by 3 text example but with plus signs in $A$. Eliminate above and below the pivots to reduce $[A \\mid I]$ to $[I \\mid A^{-1}]$:\n    \\[\n    \\left[ A \\mid I \\right] = \\begin{bmatrix}\n        2 & 1 & 0 & | & 1 & 0 & 0 \\\\\n        1 & 2 & 1 & | & 0 & 1 & 0 \\\\\n        0 & 1 & 2 & | & 0 & 0 & 1\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $A$ is invertible and you exchange its first two rows to reach $B$. Is the new matrix $B$ invertible? How would you find $B^{-1}$ from $A^{-1}$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If the product $M = ABC$ of three square matrices is invertible, then $A, B, C$ are invertible. Find a formula for $B^{-1}$ that involves $M^{-1}$ and $A$ and $C$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Prove that a matrix with a column of zeros cannot have an inverse."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Multiply $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ by $\\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}$. What is the inverse of each matrix if $ad \\neq bc$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What matrix $E$ has the same effect as these three steps? Subtract row 1 from row 2, subtract row 1 from row 3, then subtract row 2 from row 3."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What single matrix $L$ has the same effect as these three reverse steps? Add row 2 to row 3, add row 1 to row 3, then add row 1 to row 2."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the numbers $a$ and $b$ that give the inverse of $5 \\cdot I_4 - \\mathbf{1}_{4,4}$:\n    \\[\n    \\begin{bmatrix} 4 & -1 & -1 & -1 \\\\ -1 & 4 & -1 & -1 \\\\ -1 & -1 & 4 & -1 \\\\ -1 & -1 & -1 & 4 \\end{bmatrix}^{-1} = \n    \\begin{bmatrix} a & b & b & b \\\\ b & a & b & b \\\\ b & b & a & b \\\\ b & b & b & a \\end{bmatrix}\n    \\]\n    What are $a$ and $b$ in the inverse of $6 \\cdot I_5 - \\mathbf{1}_{5,5}$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that $A = 4 \\cdot I_4 - \\mathbf{1}_{4,4}$ is not invertible: Multiply $A \\cdot \\mathbf{1}_{4,1}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "There are sixteen $2 \\times 2$ matrices whose entries are 1s and 0s. How many of them are invertible?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Change $I$ into $A^{-1}$ as you reduce $A$ to $I$ (by row operations):\n    \\[\n    \\begin{bmatrix} 1 & 3 & 1 & 0 \\\\ 2 & 7 & 0 & 1 \\end{bmatrix}, \\quad \n    \\begin{bmatrix} 1 & 4 & 1 & 0 \\\\ 3 & 9 & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Follow the 3 by 3 text example but with plus signs in $A$. Eliminate above and below the pivots to reduce $[A \\ I]$ to $[I \\ A^{-1}]$:\n    \\[\n    \\begin{bmatrix} 2 & 1 & 0 & 1 & 0 & 0 \\\\ 1 & 2 & 1 & 0 & 1 & 0 \\\\ 0 & 1 & 2 & 0 & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use Gauss-Jordan elimination on $[A \\ I]$ to solve $AA^{-1} = I$:\n    \\[\n    \\begin{bmatrix} 1 & a & b \\\\ 0 & 1 & c \\\\ 0 & 0 & 1 \\end{bmatrix} \n    \\begin{bmatrix} x_1 & x_2 & x_3 \\end{bmatrix} = \n    \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Invert these matrices $A$ by the Gauss-Jordan method starting with $[A \\ I]$:\n    \\[\n    A = \\begin{bmatrix} 1 & 0 & 0 \\\\ 2 & 1 & 3 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 2 & 3 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Exchange rows and continue with Gauss-Jordan to find $A^{-1}$:\n    \\[\n    \\begin{bmatrix} 0 & 2 & 1 & 0 \\\\ 2 & 2 & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false (with a counterexample if false and a reason if true):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A $4 \\times 4$ matrix with a row of zeros is not invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A matrix with $I$s down the main diagonal is invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ is invertible then $A^{-1}$ is invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A^T$ is invertible then $A$ is invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For which three numbers $c$ is this matrix not invertible, and why not?\n    \\[\n    A = \\begin{bmatrix} 2 & c & c \\\\ c & c & c \\\\ 8 & 7 & c \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Prove that $A$ is invertible if $a \\neq 0$ and $a \\neq b$ (find the pivots and $A^{-1}$):\n    \\[\n    A = \\begin{bmatrix} a & b & b \\\\ a & a & b \\\\ a & a & a \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "This matrix has a remarkable inverse. Find $A^{-1}$ by elimination on $[A \\ I]$. Extend to a $5 \\times 5$ \u201calternating matrix\u201d and guess its inverse:\n    \\[\n    A = \\begin{bmatrix} 1 & -1 & 1 & -1 \\\\ 0 & 1 & -1 & 1 \\\\ 0 & 0 & 1 & -1 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $B$ has the columns of $A$ in reverse order, solve $(A - B)x = 0$ to show that $A - B$ is not invertible. An example will lead you to $x$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find and check the inverses (assuming they exist) of these block matrices:\n    \\begin{equation*}\n    \\begin{bmatrix} I & 0 \\\\ C & I \\end{bmatrix}\n    \\begin{bmatrix} A & 0 \\\\ C & D \\end{bmatrix}\n    \\begin{bmatrix} 0 & I \\\\ I & D \\end{bmatrix}.\n    \\end{equation*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use \\texttt{inv(S)} to invert MATLAB\u2019s $4 \\times 4$ symmetric matrix $S = \\texttt{pascal(4)}$. Create Pascal\u2019s lower triangular matrix $A = \\texttt{abs(pascal(4,1))}$ and test $\\texttt{inv(S) = inv(A') * inv(A)}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A = \\texttt{ones}(4,4)$ and $b = \\texttt{rand}(4,1)$, how does MATLAB tell you that $Ax = b$ has no solution? If $b = \\texttt{ones}(4,1)$, which solution to $Ax = b$ is found by $A \\backslash b$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$M^{-1}$ shows the change in $A^{-1}$ (useful to know) when a matrix is subtracted from $A$. Check part 3 by carefully multiplying $MM^{-1}$ to get $I$:\n    \n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$M = I - uv^T$ and $M^{-1} = I + uv^T/(1 - v^T u)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$M = A - uv^T$ and $M^{-1} = A^{-1} + A^{-1} uv^T A^{-1}/(1 - v^T A^{-1} u)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$M = I - UV$ and $M^{-1} = I_n + U(I_m - VU)^{-1} V$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$M = A - UW^{-1}V$ and $M^{-1} = A^{-1} + A^{-1} U(W - V A^{-1} U)^{-1} V A^{-1}$.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find $A^T$, $A^{-1}$, $(A^{-1})^T$, and $(A^T)^{-1}$ for:\n    \\begin{equation*}\n    A = \\begin{bmatrix} 1 & 0 \\\\ 9 & 3 \\end{bmatrix} \\quad \\text{and} \\quad A = \\begin{bmatrix} 1 & c \\\\ c & 0 \\end{bmatrix}.\n    \\end{equation*}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Verify that $(AB)^T = B^T A^T$ but that these are different from $A^T B^T$:\n    \\begin{equation*}\n    A = \\begin{bmatrix} 1 & 0 \\\\ 2 & 1 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 1 & 3 \\\\ 0 & 1 \\end{bmatrix}, \\quad AB = \\begin{bmatrix} 1 & 3 \\\\ 2 & 7 \\end{bmatrix}.\n    \\end{equation*}\n    In case $AB = BA$ (not generally true!), how do you prove that $B^T A^T = A^T B^T$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that $A^2 = 0$ is possible but $A^T A = 0$ is not possible (unless $A$ is the zero matrix)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The row vector $x^T$ times $A$ times the column $y$ produces what number?\n        \\[ x^T A y = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = . \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "This is the row $x^T A =$ times the column $y = (0,1,0)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "This is the row $x^T = [0 \\ 1]$ times the column $Ay = .$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "When you transpose a block matrix $M = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}$, the result is $M^T = $. Test it. Under what conditions on $A, B, C, D$ is the block matrix symmetric?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Explain why the inner product of $x$ and $y$ equals the inner product of $Px$ and $Py$. Then $(Px)^T(Py) = x^T y$ says that $P^T P = I$ for any permutation. With $x = (1,2,3)$ and $y = (1,4,2)$, choose $P$ to show that $(Px)^T y$ is not always equal to $x^T (P^T y)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A = A^T$ and $B = B^T$, which of these matrices are certainly symmetric?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$A^2 - B^2$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$(A+B)(A-B)$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ABA$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$ABAB$"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A = A^T$ needs a row exchange, then it also needs a column exchange to stay symmetric. In matrix language, $PA$ loses the symmetry of $A$ but recovers the symmetry."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How many entries of $A$ can be chosen independently, if $A = A^T$ is $5 \\times 5$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How do $L$ and $D$ ($5 \\times 5$) give the same number of choices in $LDL^T$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $R$ is rectangular ($m \\times n$) and $A$ is symmetric ($m \\times m$).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Transpose $R^T A R$ to show its symmetry. What shape is this matrix?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show why $R^T R$ has no negative numbers on its diagonal."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Factor these symmetric matrices into $A = LDL^T$. The matrix $D$ is diagonal:\n    \\[ A = \\begin{bmatrix} 1 & 3 \\\\ 3 & 2 \\end{bmatrix}, \\quad A = \\begin{bmatrix} 1 & b \\\\ b & c \\end{bmatrix}, \\quad A = \\begin{bmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{bmatrix}. \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Wires go between Boston, Chicago, and Seattle. Those cities are at voltages $x_B, x_C, x_S$. With unit resistances between cities, the three currents are in $y$:\n    \\[\n    y = A x = \\begin{bmatrix} y_{BC} \\\\ y_{CS} \\\\ y_{BS} \\end{bmatrix} = \\begin{bmatrix} 1 & -1 & 0 \\\\ 0 & 1 & -1 \\\\ 1 & 0 & -1 \\end{bmatrix} \\begin{bmatrix} x_B \\\\ x_C \\\\ x_S \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the total currents $A^T y$ out of the three cities."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Verify that $(Ax)^T y$ agrees with $x^T (A^T y)$\u2014six terms in both."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Producing $x_1$ trucks and $x_2$ planes requires $x_1 + 50x_2$ tons of steel, $40x_1 + 1000x_2$ pounds of rubber, and $2x_1+50x_2$ months of labor. If the unit costs $y_1, y_2, y_3$ are \\$700 per ton, \\$3 per pound, and \\$3000 per month:\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What are the values of one truck and one plane? Those are the components of $A^T y$.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "$Ax$ gives the amounts of steel, rubber, and labor to produce $x$ in Problem 62. \n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find $A$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Then $(Ax)^T y$ is the cost of inputs while $x^T (A^T y)$ is the value of the outputs.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A new factorization of $A$ into triangular and symmetric matrices:\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Start from $A = LDU$. Then $A$ equals $L(U^T)^{-1} U^T D U$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Why is $L(U^T)^{-1}$ triangular? Its diagonal is all 1s."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Why is $U^T D U$ symmetric?\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A group of matrices includes $AB$ and $A^{-1}$ if it includes $A$ and $B$. \u201cProducts and inverses stay in the group.\u201d\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Which of these sets are groups? Lower triangular matrices $L$ with ones on the diagonal, symmetric matrices $S$, positive matrices $M$, diagonal invertible matrices $D$, permutation matrices $P$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Invent two more matrix groups.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If every row of a $4 \\times 4$ matrix contains the numbers $0, 1, 2, 3$ in some order:\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Can the matrix be symmetric?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Can it be invertible?\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Prove that no reordering of rows and reordering of columns can transpose a typical matrix."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A square northwest matrix $B$ is zero in the southeast corner, below the antidiagonal that connects $(1,n)$ to $(n,1)$. \n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Will $B^T$ and $B^2$ be northwest matrices?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Will $B^{-1}$ be northwest or southeast?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What is the shape of $BC$ if $B$ is northwest and $C$ is southeast?\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compare \\texttt{tic; inv(A); toc} for $A = \\texttt{rand}(500)$ and $A = \\texttt{rand}(1000)$. \n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The $n^3$ count suggests that computing time (measured by \\texttt{tic; toc}) should multiply by 8 when $n$ is doubled. Do you expect these random $A$ to be invertible?\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Given $I = \\texttt{eye}(1000)$, $A = \\texttt{rand}(1000)$, and $B = \\texttt{triu}(A)$ producing a random triangular matrix $B$:\n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compare the times for \\texttt{inv(B)} and \\texttt{B\\I}."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compare also \\texttt{inv(A)} and \\texttt{A\\I} for the full matrix $A$.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Show that $L^{-1}$ has entries $j/i$ for $i \\leq j$ for the given matrix $L$:\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    -\\frac{1}{2} & 1 & 0 & 0 \\\\\n    0 & -\\frac{2}{3} & 1 & 0 \\\\\n    0 & 0 & -\\frac{3}{4} & 1\n    \\end{bmatrix}\n    \\]\n    \n    \\[\n    L^{-1} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    \\frac{1}{2} & 1 & 0 & 0 \\\\\n    \\frac{1}{3} & \\frac{2}{3} & 1 & 0 \\\\\n    \\frac{1}{4} & \\frac{2}{4} & \\frac{3}{4} & 1\n    \\end{bmatrix}\n    \\]\n    \n    \\begin{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Test this pattern for \\texttt{L = eye(5) - diag(1:5)\\diag(1:4,-1)} and \\texttt{inv(L)}.\n    \\end{itemize}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write out the $LDU = LDL^T$ factors of $A$ in equation (6) when $n = 4$. Find the determinant as the product of the pivots in $D$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Modify $a_{11}$ in equation (6) from $a_{11} = 2$ to $a_{11} = 1$, and find the $LDU$ factors of this new tridiagonal matrix."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the $5 \\times 5$ matrix $A_0$ ($h = \\frac{1}{6}$) that approximates \n    \\[\n        -\\frac{d^2 u}{dx^2} = f(x), \\quad \\frac{du}{dx}(0) = \\frac{du}{dx}(1) = 0,\n    \\]\n    replacing these boundary conditions by $u_0 = u_1$ and $u_6 = u_5$. Check that your $A_0$ times the constant vector $(C, C, C, C, C)$ yields zero; $A_0$ is singular. Analogously, if $u(x)$ is a solution of the continuous problem, then so is $u(x) + C$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down the $3 \\times 3$ finite-difference matrix equation ($h = \\frac{1}{4}$) for\n    \\[\n        -\\frac{d^2 u}{dx^2} + u = x, \\quad u(0) = u(1) = 0.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "With $h = \\frac{1}{4}$ and $f(x) = 4\\pi^2 \\sin 2\\pi x$, the difference equation (5) is\n    \\[\n        \\begin{bmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{bmatrix}\n        \\begin{bmatrix} u_1 \\\\ u_2 \\\\ u_3 \\end{bmatrix} = \\pi^2 4\n        \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}.\n    \\]\n    Solve for $u_1, u_2, u_3$ and find their error in comparison with the true solution $u = \\sin 2\\pi x$ at $x = \\frac{1}{4}, x = \\frac{1}{2},$ and $x = \\frac{3}{4}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What $5 \\times 5$ system replaces (6) if the boundary conditions are changed to $u(0) = 1, u(1) = 0$?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute $H^{-1}$ in two ways for the $3 \\times 3$ Hilbert matrix:\n    \\begin{equation*}\n        H = \\begin{bmatrix}\n            1 & \\frac{1}{2} & \\frac{1}{3} \\\\\n            \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{4} \\\\\n            \\frac{1}{3} & \\frac{1}{4} & \\frac{1}{5}\n        \\end{bmatrix}\n    \\end{equation*}\n    First, compute the exact inverse. Second, round off each number to three significant figures and compute again. Discuss the impact of rounding errors on the results."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For the same matrix $H$, compare the right-hand sides of $Hx = b$ when the solutions are $x = (1,1,1)$ and $x = (0.6,-3.6)$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve $Hx = b$ with $b = (1,0,\\dots,0)^T$ for the $10 \\times 10$ Hilbert matrix with $h_{ij} = \\frac{1}{i+j-1}$, using any computational method for solving linear systems. Then, change one entry of $b$ by $0.0001$ and compare the solutions."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compare the pivots in direct elimination to those with partial pivoting for the matrix:\n    \\begin{equation*}\n        A = \\begin{bmatrix} 0.001 & 0 \\\\ 1 & 1000 \\end{bmatrix}.\n    \\end{equation*}\n    Discuss the effects of scaling on numerical stability."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Explain why partial pivoting produces multipliers $\\ell_{ij}$ in $L$ that satisfy $|\\ell_{ij}| \\leq 1$. Can you construct a $3 \\times 3$ example where all $|a_{ij}| \\leq 1$ but the last pivot is $4$? Discuss why this is the worst case, considering how each entry is at most doubled when $|\\ell_{ij}| \\leq 1$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down the 3 by 3 matrices with entries\n        \\[\n        a_{ij} = i - j \\quad \\text{and} \\quad b_{ij} = \\frac{i}{j}.\n        \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute the products \\(AB\\), \\(BA\\), and \\(A^2\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For the matrices \n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 2 & 1 \\end{bmatrix} \\quad \\text{and} \\quad B = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix},\n    \\]\n    compute \\(AB\\), \\(BA\\), \\(A^{-1}\\), \\(B^{-1}\\), and \\((AB)^{-1}\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find examples of 2 by 2 matrices with \\(a_{12} = \\frac{1}{2}\\) for which:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(A^2 = I\\),"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(A^{-1} = A^T\\),"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(A^2 = A\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve by elimination and back-substitution:\n    \\[\n    u + w = 4 \\quad\n    u + v = 3 \\quad\n    u + v + w = 6\n    \\]\n    and\n    \\[\n    v + w = 0 \\quad\n    u + w = 0 \\quad\n    u + v = 6.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Factor the preceding matrices into \\(A = LU\\) or \\(PA = LU\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "There are sixteen 2 by 2 matrices whose entries are 1s and 0s. How many are invertible?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(Much harder!) If you put 1s and 0s at random into the entries of a 10 by 10 matrix, is it more likely to be invertible or singular?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "There are sixteen 2 by 2 matrices whose entries are 1s and \u22121s. How many are invertible?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How are the rows of \\(EA\\) related to the rows of \\(A\\) in the following cases?\n    \\[\n    E = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    0 & 2 & 0 \\\\\n    4 & 0 & 1 \n    \\end{bmatrix}\n    \\]\n    or\n    \\[\n    E = \\begin{bmatrix} \n    1 & 1 & 1 \\\\\n    0 & 0 & 0 \n    \\end{bmatrix}\n    \\]\n    or\n    \\[\n    E = \\begin{bmatrix} \n    0 & 0 & 1 \\\\\n    0 & 1 & 0 \\\\\n    1 & 0 & 0 \n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down a 2 by 2 system with infinitely many solutions."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find inverses if they exist, by inspection or by Gauss-Jordan:\n    \\[\n    A = \\begin{bmatrix} \n    1 & 0 & 1 \\\\\n    1 & 1 & 0 \\\\\n    0 & 1 & 1 \n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix} \n    2 & 1 & 0 \\\\\n    1 & 2 & 1 \\\\\n    0 & 1 & 2 \n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix} \n    1 & 1 & -2 \\\\\n    1 & -2 & 1 \\\\\n    -2 & 1 & 1 \n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(E\\) is 2 by 2 and it adds the first equation to the second, what are \\(E^2\\), \\(E^8\\), and \\(8E\\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false, with reason if true or counterexample if false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(A\\) is invertible and its rows are in reverse order in \\(B\\), then \\(B\\) is invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(A\\) and \\(B\\) are symmetric then \\(AB\\) is symmetric."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(A\\) and \\(B\\) are invertible then \\(BA\\) is invertible."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Every nonsingular matrix can be factored into the product \\(A = LU\\) of a lower triangular \\(L\\) and an upper triangular \\(U\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve \\(Ax = b\\) by solving the triangular systems \\(Lc = b\\) and \\(Ux = c\\):\n    \\[\n    A = LU = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    4 & 1 & 0 \\\\\n    1 & 0 & 1 \n    \\end{bmatrix} \n    \\begin{bmatrix} \n    2 & 2 & 4 \\\\\n    0 & 1 & 3 \\\\\n    0 & 0 & 1 \n    \\end{bmatrix}, \\quad \n    b = \\begin{bmatrix} \n    0 \\\\\n    0 \\\\\n    1 \n    \\end{bmatrix}.\n    \\]\n    What part of \\(A^{-1}\\) have you found, with this particular \\(b\\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If possible, find 3 by 3 matrices \\(B\\) such that:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(BA = 2A\\) for every \\(A\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(BA = 2B\\) for every \\(A\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(BA\\) has the first and last rows of \\(A\\) reversed."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\(BA\\) has the first and last columns of \\(A\\) reversed."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the value for \\(c\\) in the following \\(n\\) by \\(n\\) inverse:\n    \\[\n    A = \\begin{bmatrix} \n    n & -1 & \\cdots & -1 \\\\\n    -1 & n & \\cdots & -1 \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    -1 & -1 & \\cdots & n \n    \\end{bmatrix}, \\quad \n    A^{-1} = \\frac{1}{n+1} \\begin{bmatrix} \n    c & 1 & \\cdots & 1 \\\\\n    1 & c & \\cdots & 1 \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    1 & 1 & \\cdots & c \n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "For which values of \\(k\\) does the system:\n    \\[\n    kx + y = 1 \\\\\n    x + ky = 1\n    \\]\n    have no solution, one solution, or infinitely many solutions?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find the symmetric factorization \\(A = LDL^T\\) of:\n    \\[\n    A = \\begin{bmatrix} \n    1 & 2 & 0 \\\\\n    2 & 6 & 4 \\\\\n    0 & 4 & 11 \n    \\end{bmatrix}, \\quad \n    A = \\begin{bmatrix} \n    a & b \\\\\n    b & c \n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose \\(A\\) is the 4 by 4 identity matrix except for a vector \\(v\\) in column 2:\n    \\[\n    A = \\begin{bmatrix} \n    1 & v_1 & 0 & 0 \\\\\n    0 & v_2 & 0 & 0 \\\\\n    0 & v_3 & 1 & 0 \\\\\n    0 & v_4 & 0 & 1 \n    \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Factor \\(A\\) into \\(LU\\), assuming \\(v_2 \\neq 0\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find \\(A^{-1}\\), which has the same form as \\(A\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve by elimination, or show that there is no solution:\n    \\[\n    u + v + w = 0 \\\\\n    u + 2v + 3w = 0 \\\\\n    3u + 5v + 7w = 1\n    \\]\n    and\n    \\[\n    u + v + w = 0 \\\\\n    u + u + 3w = 0 \\\\\n    3u + 5v + 7w = 1.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The \\(n \\times n\\) permutation matrices are an important example of a \u201cgroup.\u201d If you multiply them you stay inside the group; they have inverses in the group; the identity is in the group; and the law \\(P_1(P_2P_3) = (P_1P_2)P_3\\) is true\u2014because it is true for all matrices.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "How many members belong to the groups of \\(4 \\times 4\\) and \\(n \\times n\\) permutation matrices?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Find a power \\(k\\) so that all \\(3 \\times 3\\) permutation matrices satisfy \\(P^k = I\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Describe the rows of \\(DA\\) and the columns of \\(AD\\) if \\(D = \\begin{bmatrix} 2 & 0 \\\\ 0 & 5 \\end{bmatrix}\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(A\\) is invertible, what is the inverse of \\(A^T\\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\(A\\) is also symmetric, what is the transpose of \\(A^{-1}\\)?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Illustrate both formulas when \\(A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 1 \\end{bmatrix}\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "By experiment with \\(n = 2\\) and \\(n = 3\\), find:\n    \\[\n    \\begin{bmatrix} 2 & 3 \\\\ 0 & 0 \\end{bmatrix}^n, \\quad \n    \\begin{bmatrix} 2 & 3 \\\\ 0 & 1 \\end{bmatrix}^n, \\quad\n    \\begin{bmatrix} 2 & 3 \\\\ 0 & 1 \\end{bmatrix}^{-1}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Starting with a first plane \\(u + 2v - w = 6\\), find the equation for:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "The parallel plane through the origin."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A second plane that also contains the points \\((6, 0, 0)\\) and \\((2, 2, 0)\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "A third plane that meets the first and second in the point \\((4, 1, 0)\\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "What multiple of row 2 is subtracted from row 3 in forward elimination of \\(A\\)?\n    \\[\n    A = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    2 & 1 & 0 \\\\\n    0 & 5 & 1 \n    \\end{bmatrix} \\quad\n    \\begin{bmatrix} \n    1 & 2 & 0 \\\\\n    0 & 1 & 5 \\\\\n    0 & 0 & 1 \n    \\end{bmatrix}.\n    \\]\n    How do you know (without multiplying those factors) that \\(A\\) is invertible, symmetric, and tridiagonal? What are its pivots?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "(a) What vector \\( x \\) will make \\( Ax = \\text{column 1 of } A + 2(\\text{column 3}) \\), for a \\( 3 \\times 3 \\) matrix \\( A \\)?\n\n    (b) Construct a matrix that has \\( \\text{column 1} + 2(\\text{column 3}) = 0 \\). Check that \\( A \\) is singular (fewer than 3 pivots) and explain why that must be the case."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "True or false, with reason if true and counterexample if false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( L_1U_1 = L_2U_2 \\) (upper triangular \\( U \\)\u2019s with nonzero diagonal, lower triangular \\( L \\)\u2019s with unit diagonal), then \\( L_1 = L_2 \\) and \\( U_1 = U_2 \\). The LU factorization is unique."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If \\( A^2 + A = I \\), then \\( A^{-1} = A + I \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If all diagonal entries of \\( A \\) are zero, then \\( A \\) is singular."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "By experiment or the Gauss-Jordan method, compute:\n    \\[\n    \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    ` & 1 & 0 \\\\\n    m & 0 & 1 \n    \\end{bmatrix}^n,\n    \\quad\n    \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    ` & 1 & 0 \\\\\n    m & 0 & 1 \n    \\end{bmatrix}^{-1},\n    \\quad\n    \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    ` & 1 & 0 \\\\\n    0 & m & 1 \n    \\end{bmatrix}^{-1}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Write down the \\( 2 \\times 2 \\) matrices that:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Reverse the direction of every vector."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Project every vector onto the \\( x_2 \\)-axis."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Turn every vector counterclockwise through 90\u00b0."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Reflect every vector through the 45\u00b0 line \\( x_1 = x_2 \\)."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A$ be an $n \\times n$ real symmetric matrix. Prove that $A$ is always diagonalizable and that its eigenvalues are real."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $A$ is a real symmetric matrix. Show that there exists an orthogonal matrix $Q$ such that $A = Q \\Lambda Q^T$, where $\\Lambda$ is a diagonal matrix. What does this decomposition tell us about the geometric and algebraic multiplicities of eigenvalues?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Consider the symmetric matrix $A = \\begin{bmatrix} 4 & 1 & 2 \\\\ 1 & 3 & 0 \\\\ 2 & 0 & 5 \\end{bmatrix}$. Compute its eigenvalues and eigenvectors, and verify the spectral decomposition $A = Q \\Lambda Q^T$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A$ be a positive definite symmetric matrix. Show that there exists a unique lower triangular matrix $L$ with positive diagonal entries such that $A = LL^T$ (Cholesky decomposition). Prove that this decomposition is unique."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "If $A$ is a symmetric matrix, prove that $A$ can be written as $A = U D U^T$ where $U$ is an orthogonal matrix and $D$ is a diagonal matrix. Explain how this factorization is related to the principal component analysis (PCA) in data science."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A$ be an $n \\times n$ invertible matrix with integer entries. Show that if all entries of $A^{-1}$ are also integers, then $\\det(A) = \\pm 1$. Use the Gauss-Jordan method to justify your argument."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Given an arbitrary $3 \\times 3$ matrix $A$, derive conditions on its entries such that the Gauss-Jordan method fails to produce an inverse. Provide an example of such a matrix and justify your reasoning."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $A$ is an $n \\times n$ matrix with rational entries, and the Gauss-Jordan elimination process involves only rational row operations. Prove that if $A$ is invertible, then $A^{-1}$ has only rational entries. How does this result relate to field properties?"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A = \\begin{bmatrix} 1 & a & b \\\\ 0 & 1 & c \\\\ 0 & 0 & 1 \\end{bmatrix}$ be an upper triangular matrix. Use the Gauss-Jordan method to find $A^{-1}$ explicitly in terms of $a, b,$ and $c$, and determine necessary conditions for its existence."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Consider an $n \\times n$ matrix $A$ whose entries are chosen randomly from $\\{0,1\\}$. Show that the probability of $A$ being invertible is nonzero. Use properties of the Gauss-Jordan method to discuss how random row operations affect invertibility."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let $A$ be a $3 \\times 3$ matrix with distinct nonzero entries. Prove that if $A$ can be factored as $A = LU$ with $L$ a lower triangular matrix and $U$ an upper triangular matrix, then $A$ must be nonsingular. Provide a counterexample if $A$ is singular."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute the $LU$ and $LDU$ factorizations for the matrix $A = \\begin{bmatrix} 4 & 3 & -1 \\\\ 2 & 1 & 3 \\\\ -6 & 2 & 5 \\end{bmatrix}$, and verify your result by matrix multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Suppose $A$ is an $n \\times n$ matrix with an $LU$ decomposition where $L$ is unit lower triangular and $U$ is upper triangular. Show that if $A$ is invertible, then $L$ and $U$ are also invertible, and express $A^{-1}$ in terms of $L^{-1}$ and $U^{-1}$."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Given a symmetric positive definite matrix $A$, prove that its $LU$ decomposition satisfies $L = U^T$. Show how this leads to the Cholesky decomposition $A = LL^T$, and compare it to the $LDU$ factorization."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Consider the permutation matrix $P$ obtained by row interchanges during Gaussian elimination. Show that for certain matrices $A$, an $LU$ decomposition may not exist without row exchanges, leading to a $PA = LU$ factorization instead. Provide an example and justify why row exchanges are necessary."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve the following system of linear equations using Gaussian elimination:\n    \\[\n    \\begin{aligned}\n    2x + y - 3z &= 9, \\\\\n    4x + 3y + 2z &= 20, \\\\\n    -x + 2y + z &= 2.\n    \\end{aligned}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use back substitution to solve the following upper triangular system:\n    \\[\n    \\begin{aligned}\n    x + 2y + 3z &= 9, \\\\\n    0x + 4y + 5z &= 20, \\\\\n    0x + 0y + 7z &= 14.\n    \\end{aligned}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Given the augmented matrix for a system of linear equations:\n    \\[\n    \\left[\\begin{array}{ccc|c}\n    1 & 2 & -1 & 3 \\\\\n    2 & 4 & -1 & 7 \\\\\n    1 & 3 & 2 & 6\n    \\end{array}\\right],\n    \\]\n    use Gaussian elimination to find the solution to the system."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Solve the following system of equations using Gaussian elimination and back substitution:\n    \\[\n    \\begin{aligned}\n    3x - y + 2z &= 5, \\\\\n    2x + 4y - 3z &= 7, \\\\\n    x - 2y + 3z &= 4.\n    \\end{aligned}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Use elimination to solve the following system of equations:\n    \\[\n    \\begin{aligned}\n    x + 3y - z &= 2, \\\\\n    2x + 5y + 3z &= 3, \\\\\n    3x + 2y - 4z &= 5.\n    \\end{aligned}\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Compute the product of the following column and row vectors:\n    \\[\n    \\begin{bmatrix} 1 \\\\ 3 \\\\ 5 \\end{bmatrix} \\cdot \\begin{bmatrix} 2 & 4 & 6 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 10 \\\\ 11 \\\\ 12 \\end{bmatrix} \\). Compute the matrix product \\( AB \\) using column-row multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Consider the block matrix multiplication of the following matrices:\n    \\[\n    A = \\begin{bmatrix} \n    1 & 2 \\\\ \n    3 & 4 \n    \\end{bmatrix}, \n    B = \\begin{bmatrix} \n    5 & 6 \\\\ \n    7 & 8 \n    \\end{bmatrix}.\n    \\]\n    Compute the product \\( AB \\) using block matrix multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 3 & 5 \\\\ 2 & 4 & 6 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 7 \\\\ 8 \\\\ 9 \\end{bmatrix} \\). Perform the column-row multiplication \\( AB \\) and provide the resulting vector."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Given the block matrices \\( A = \\begin{bmatrix} A_1 & A_2 \\\\ A_3 & A_4 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} B_1 & B_2 \\\\ B_3 & B_4 \\end{bmatrix} \\), where each \\( A_i \\) and \\( B_i \\) are \\( 2 \\times 2 \\) matrices, compute the product \\( AB \\) using block matrix multiplication."
    },
    {
        "chapter": "Matrices and Gaussian Elimination",
        "question": "Let \\( A = \\begin{bmatrix} 1 & 2 & 3 & 4 \\\\ 5 & 6 & 7 & 8 \\\\ 9 & 10 & 11 & 12 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix} \\). Compute the matrix product \\( AB \\) using column-row multiplication, and discuss the result in terms of linear transformations."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the lengths and the inner product of $x = (1,4,0,2)$ and $y = (2,-2,1,3)$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Give an example in $\\mathbb{R}^2$ of linearly independent vectors that are not orthogonal. Also, give an example of orthogonal vectors that are not independent."
    },
    {
        "chapter": "Orthogonality",
        "question": "Two lines in the plane are perpendicular when the product of their slopes is $-1$. Apply this to the vectors $x = (x_1, x_2)$ and $y = (y_1, y_2)$, whose slopes are $\\frac{x_2}{x_1}$ and $\\frac{y_2}{y_1}$, to derive again the orthogonality condition $x^T y = 0$."
    },
    {
        "chapter": "Orthogonality",
        "question": "How do we know that the $i$th row of an invertible matrix $B$ is orthogonal to the $j$th column of $B^{-1}$, if $i \\neq j$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Determine which pairs are orthogonal among the vectors:\n    \\begin{align*}\n        v_1 &= \\begin{bmatrix} 1 \\\\ 2 \\\\ -2 \\\\ 1 \\end{bmatrix}, \\quad\n        v_2 = \\begin{bmatrix} 4 \\\\ 0 \\\\ 4 \\\\ 0 \\end{bmatrix}, \\\\ \n        v_3 &= \\begin{bmatrix} 1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{bmatrix}, \\quad\n        v_4 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find all vectors in $\\mathbb{R}^3$ that are orthogonal to $(1,1,1)$ and $(1,-1,0)$. Produce an orthonormal basis from these vectors (mutually orthogonal unit vectors)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a vector $x$ orthogonal to the row space of $A$, a vector $y$ orthogonal to the column space, and a vector $z$ orthogonal to the null space of:\n    \\begin{equation*}\n        A = \\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 3 \\\\ 3 & 6 & 4 \\end{bmatrix}.\n    \\end{equation*}"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $V$ and $W$ are orthogonal subspaces, show that the only vector they have in common is the zero vector: $V \\cap W = \\{0\\}$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the orthogonal complement of the plane spanned by the vectors $(1,1,2)$ and $(1,2,3)$, by taking these to be the rows of $A$ and solving $Ax = 0$. Remember that the complement is a whole line."
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct a homogeneous equation in three unknowns whose solutions are the linear combinations of the vectors $(1,1,2)$ and $(1,2,3)$. This is the reverse of the previous exercise, but the two problems are really the same."
    },
    {
        "chapter": "Orthogonality",
        "question": "The fundamental theorem is often stated in the form of Fredholm\u2019s alternative: For any $A$ and $b$, one and only one of the following systems has a solution:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "$Ax = b$."
    },
    {
        "chapter": "Orthogonality",
        "question": "$A^T y = 0$, $y^T b \\neq 0$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a basis for the orthogonal complement of the row space of $A$:\n    \\[\n        A = \\begin{bmatrix} 1 & 0 & 2 \\\\ 1 & 1 & 4 \\end{bmatrix}.\n    \\]\n    Split $x = (3,3,3)$ into a row space component $x_r$ and a null space component $x_n$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Illustrate the action of $A^T$ by a picture corresponding to Figure 3.4, sending $C(A)$ back to the row space and the left null space to zero."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that $x - y$ is orthogonal to $x + y$ if and only if $\\|x\\| = \\|y\\|$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a matrix whose row space contains $(1,2,1)$ and whose null space contains $(1,-2,1)$, or prove that there is no such matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find all vectors that are perpendicular to $(1,4,4,1)$ and $(2,9,8,2)$."
    },
    {
        "chapter": "Orthogonality",
        "question": "If $V$ is the orthogonal complement of $W$ in $\\mathbb{R}^n$, is there a matrix with row space $V$ and null space $W$? Starting with a basis for $V$, construct such a matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "If $S = \\{0\\}$ is the subspace of $\\mathbb{R}^4$ containing only the zero vector, what is $S^\\perp$? If $S$ is spanned by $(0,0,0,1)$, what is $S^\\perp$? What is $(S^\\perp)^\\perp$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Why are these statements false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $V$ is orthogonal to $W$, then $V^\\perp$ is orthogonal to $W^\\perp$."
    },
    {
        "chapter": "Orthogonality",
        "question": "$V$ orthogonal to $W$ and $W$ orthogonal to $Z$ makes $V$ orthogonal to $Z$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let $S$ be a subspace of $\\mathbb{R}^n$. Explain what $(S^\\perp)^\\perp = S$ means and why it is true."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let $P$ be the plane in $\\mathbb{R}^3$ with equation $x + 2y - z = 0$. Find a vector perpendicular to $P$. What matrix has the plane $P$ as its null space, and what matrix has $P$ as its row space?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Let $S$ be the subspace of $\\mathbb{R}^4$ containing all vectors with $x_1 + x_2 + x_3 + x_4 = 0$. Find a basis for the space $S^\\perp$, containing all vectors orthogonal to $S$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct an unsymmetric $2 \\times 2$ matrix of rank $1$. Copy Figure 3.4 and put one vector in each subspace. Which vectors are orthogonal?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Redraw Figure 3.4 for a $3 \\times 2$ matrix of rank $r = 2$. Which subspace is $Z$ (zero vector only)? The nullspace part of any vector $x$ in $\\mathbb{R}^2$ is $x_n =$ ."
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct a matrix with the required property or say why that is impossible.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Column space contains $\\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\end{bmatrix}$ and $\\begin{bmatrix} 2 \\\\ -3 \\\\ 5 \\end{bmatrix}$, nullspace contains $\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Row space contains $\\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\end{bmatrix}$ and $\\begin{bmatrix} 2 \\\\ -3 \\\\ 5 \\end{bmatrix}$, nullspace contains $\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Orthogonality",
        "question": "$Ax = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$ has a solution and $A^T \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Every row is orthogonal to every column ($A$ is not the zero matrix)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The columns add up to a column of 0s, the rows add to a row of 1s."
    },
    {
        "chapter": "Orthogonality",
        "question": "If $AB = 0$ then the columns of $B$ are in the of $A$. The rows of $A$ are in the of $B$. Why can\u2019t $A$ and $B$ be $3 \\times 3$ matrices of rank $2$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $Ax = b$ has a solution and $A^T y = 0$, then $y$ is perpendicular to ."
    },
    {
        "chapter": "Orthogonality",
        "question": "If $A^T y = c$ has a solution and $Ax = 0$, then $x$ is perpendicular to ."
    },
    {
        "chapter": "Orthogonality",
        "question": "This is a system of equations $Ax = b$ with no solution:\n    \\begin{align*}\n        x + 2y + 2z &= 5 \\\\\n        2x + 2y + 3z &= 5 \\\\\n        3x + 4y + 5z &= 9.\n    \\end{align*}\n    Find numbers $y_1, y_2, y_3$ to multiply the equations so they add to $0 = 1$. You have found a vector $y$ in which subspace? The inner product $y^T b$ is 1."
    },
    {
        "chapter": "Orthogonality",
        "question": "In Figure 3.4, how do we know that $Ax_r$ is equal to $Ax$? How do we know that this vector is in the column space? If $A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$ and $x = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ what is $x_r$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $Ax$ is in the nullspace of $A^T$ then $Ax = 0$. Reason: $Ax$ is also in the of $A$ and the spaces are . Conclusion: $A^T A$ has the same nullspace as $A$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose $A$ is a symmetric matrix ($A^T = A$).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Why is its column space perpendicular to its nullspace?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $Ax = 0$ and $Az = 5z$, which subspaces contain these \u201ceigenvectors\u201d $x$ and $z$? Symmetric matrices have perpendicular eigenvectors (see Section 5.5)."
    },
    {
        "chapter": "Orthogonality",
        "question": "(Recommended) Draw Figure 3.4 to show each subspace for\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 1 & 0 \\\\ 3 & 0 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the pieces $x_r$ and $x_n$, and draw Figure 3.4 properly, if\n    \\[\n    A = \\begin{bmatrix} 1 & -1 \\\\ 0 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad x = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Put bases for the orthogonal subspaces $V$ and $W$ into the columns of matrices $V$ and $W$. Why does $V^T W = 0$ matrix? This matches $v^T w = 0$ for vectors."
    },
    {
        "chapter": "Orthogonality",
        "question": "The floor and the wall are not orthogonal subspaces because they share a nonzero vector (along the line where they meet). Two planes in $\\mathbb{R}^3$ cannot be orthogonal! Find a vector in both column spaces $C(A)$ and $C(B)$:\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 1 & 3 \\\\ 1 & 2 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 5 & 4 \\\\ 6 & 3 \\\\ 5 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Extend Problem 35 to a $p$-dimensional subspace $V$ and a $q$-dimensional subspace $W$ of $\\mathbb{R}^n$. What inequality on $p+q$ guarantees that $V$ intersects $W$ in a nonzero vector? These subspaces cannot be orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that every $y$ in $N(A^T)$ is perpendicular to every $Ax$ in the column space, using the matrix shorthand of equation (8). Start from $A^T y = 0$."
    },
    {
        "chapter": "Orthogonality",
        "question": "If $S$ is the subspace of $\\mathbb{R}^3$ containing only the zero vector, what is $S^\\perp$? If $S$ is spanned by $(1,1,1)$, what is $S^\\perp$? If $S$ is spanned by $(2,0,0)$ and $(0,0,3)$, what is $S^\\perp$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose $S$ only contains $(1,5,1)$ and $(2,2,2)$ (not a subspace). Then $S^\\perp$ is the nullspace of the matrix $A = \\cdots$. $S^\\perp$ is a subspace even if $S$ is not."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose $L$ is a one-dimensional subspace (a line) in $\\mathbb{R}^3$. Its orthogonal complement $L^\\perp$ is the perpendicular to $L$. Then $(L^\\perp)^\\perp$ is a perpendicular to $L^\\perp$. In fact, $(L^\\perp)^\\perp$ is the same as $\\cdots$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose $V$ is the whole space $\\mathbb{R}^4$. Then $V^\\perp$ contains only the vector $\\cdots$. Then $(V^\\perp)^\\perp$ is $\\cdots$. So $(V^\\perp)^\\perp$ is the same as $\\cdots$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose $S$ is spanned by the vectors $(1,2,2,3)$ and $(1,3,3,2)$. Find two vectors that span $S^\\perp$. This is the same as solving $Ax = 0$ for which $A$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $P$ is the plane of vectors in $\\mathbb{R}^4$ satisfying $x_1 + x_2 + x_3 + x_4 = 0$, write a basis for $P^\\perp$. Construct a matrix that has $P$ as its nullspace."
    },
    {
        "chapter": "Orthogonality",
        "question": "If a subspace $S$ is contained in a subspace $V$, prove that $S^\\perp$ contains $V^\\perp$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose an \\(n \\times n\\) matrix is invertible: \\(AA^{-1} = I\\). Then the first column of \\(A^{-1}\\) is orthogonal to the space spanned by which rows of \\(A\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find \\(A^T A\\) if the columns of \\(A\\) are unit vectors, all mutually perpendicular."
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct a \\(3 \\times 3\\) matrix \\(A\\) with no zero entries whose columns are mutually perpendicular. Compute \\(A^T A\\). Why is it a diagonal matrix?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The lines \\(3x + y = b_1\\) and \\(6x + 2y = b_2\\) are the same line if... In that case \\((b_1, b_2)\\) is perpendicular to the vector... The nullspace of the matrix is the line \\(3x + y = \\). One particular vector in that nullspace is..."
    },
    {
        "chapter": "Orthogonality",
        "question": "Why is each of these statements false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "\\((1, 1, 1)\\) is perpendicular to \\((1, 1, -2)\\), so the planes \\(x + y + z = 0\\) and \\(x + y - 2z = 0\\) are orthogonal subspaces."
    },
    {
        "chapter": "Orthogonality",
        "question": "The subspace spanned by \\((1, 1, 0, 0, 0)\\) and \\((0, 0, 0, 1, 1)\\) is the orthogonal complement of the subspace spanned by \\((1, -1, 0, 0, 0)\\) and \\((2, -2, 3, 4, -4)\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Two subspaces that meet only in the zero vector are orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a matrix with \\(v = (1, 2, 3)\\) in the row space and column space. Find another matrix with \\(v\\) in the nullspace and column space. Which pairs of subspaces can \\(v\\) not be in?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose \\(A\\) is \\(3 \\times 4\\), \\(B\\) is \\(4 \\times 5\\), and \\(AB = 0\\). Prove \\(\\text{rank}(A) + \\text{rank}(B) \\leq 4\\).\n    \\\\item The command \\(N = \\text{null}(A)\\) will produce a basis for the nullspace of \\(A\\). Then the command \\(B = \\text{null}(N')\\) will produce a basis for the \\rule{3cm}{0.5pt} of \\(A\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) Given any two positive numbers \\(x\\) and \\(y\\), choose the vector \\(\\mathbf{b} = (\\sqrt{x}, \\sqrt{y})\\), and choose \\(\\mathbf{a} = (\\sqrt{y}, \\sqrt{x})\\). Apply the Schwarz inequality to compare the arithmetic mean \\(\\frac{1}{2}(x + y)\\) with the geometric mean \\(\\sqrt{xy}\\).\n    \n    (b) Suppose we start with a vector from the origin to the point \\(\\mathbf{x}\\), and then add a vector of length \\(\\|\\mathbf{y}\\|\\) connecting \\(\\mathbf{x}\\) to \\(\\mathbf{x} + \\mathbf{y}\\). The third side of the triangle goes from the origin to \\(\\mathbf{x} + \\mathbf{y}\\). The triangle inequality asserts that this distance cannot be greater than the sum of the first two:\n    \\[\n    \\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|.\n    \\]\n    After squaring both sides, and expanding \\((\\mathbf{x} + \\mathbf{y})^T(\\mathbf{x} + \\mathbf{y})\\), reduce this to the Schwarz inequality."
    },
    {
        "chapter": "Orthogonality",
        "question": "Verify that the length of the projection in Figure 3.7 is \\(\\|\\mathbf{p}\\| = \\|\\mathbf{b}\\|\\cos\\theta\\), using formula (5)."
    },
    {
        "chapter": "Orthogonality",
        "question": "What multiple of \\(\\mathbf{a} = (1,1,1)\\) is closest to the point \\(\\mathbf{b} = (2,4,4)\\)? Find also the point closest to \\(\\mathbf{a}\\) on the line through \\(\\mathbf{b}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Explain why the Schwarz inequality becomes an equality in the case that \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) lie on the same line through the origin, and only in that case. What if they lie on opposite sides of the origin?"
    },
    {
        "chapter": "Orthogonality",
        "question": "In \\(n\\) dimensions, what angle does the vector \\((1, 1, \\dots, 1)\\) make with the coordinate axes? What is the projection matrix \\(P\\) onto that vector?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The Schwarz inequality has a one-line proof if \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) are normalized ahead of time to be unit vectors:\n    \\[\n    |\\mathbf{a}^T \\mathbf{b}| = \\left| \\sum a_j b_j \\right| \\leq \\sum |a_j| |b_j| \\leq \\sum |a_j|^2 + |b_j|^2 = \\frac{1}{2} + \\frac{1}{2} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\|.\n    \\]\n    Which previous problem justifies the middle step?"
    },
    {
        "chapter": "Orthogonality",
        "question": "By choosing the correct vector \\(\\mathbf{b}\\) in the Schwarz inequality, prove that\n    \\[\n    \\left( a_1 + \\cdots + a_n \\right)^2 \\leq n \\left( a_1^2 + \\cdots + a_n^2 \\right).\n    \\]\n    When does equality hold?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The methane molecule \\(\\text{CH}_4\\) is arranged as if the carbon atom were at the center of a regular tetrahedron with four hydrogen atoms at the vertices. If vertices are placed at \\((0,0,0)\\), \\((1,1,0)\\), \\((1,0,1)\\), and \\((0,1,1)\\)\u2014note that all six edges have length \\(\\sqrt{2}\\), so the tetrahedron is regular\u2014what is the cosine of the angle between the rays going from the center \\(\\left(\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}\\right)\\) to the vertices? (The bond angle itself is about 109.5\u00b0, an old friend of chemists.)"
    },
    {
        "chapter": "Orthogonality",
        "question": "Square the matrix \\(P = \\frac{\\mathbf{a}\\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\), which projects onto a line, and show that \\(P^2 = P\\).\n    (Note the number \\(\\mathbf{a}^T \\mathbf{a}\\) in the middle of the matrix \\(\\frac{\\mathbf{a}\\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\).)"
    },
    {
        "chapter": "Orthogonality",
        "question": "Is the projection matrix \\(P\\) invertible? Why or why not?"
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) Find the projection matrix \\(P_1\\) onto the line through \\(\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix}\\) and also the matrix \\(P_2\\) that projects onto the line perpendicular to \\(\\mathbf{a}\\).\n    \n    (b) Compute \\(P_1 + P_2\\) and \\(P_1 P_2\\) and explain."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the matrix that projects every point in the plane onto the line \\(x + 2y = 0\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that the trace of \\(P = \\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\)\u2014which is the sum of its diagonal entries\u2014always equals 1."
    },
    {
        "chapter": "Orthogonality",
        "question": "What matrix \\(P\\) projects every point in \\(\\mathbb{R}^3\\) onto the line of intersection of the planes \\(x + y + t = 0\\) and \\(x - t = 0\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the length of \\(\\mathbf{A} \\mathbf{x}\\) equals the length of \\(\\mathbf{A}^T \\mathbf{x}\\) if \\(\\mathbf{A}\\mathbf{A}^T = \\mathbf{A}^T \\mathbf{A}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose \\(P\\) is the projection matrix onto the line through \\(\\mathbf{a}\\).\n    (a) Why is the inner product of \\(\\mathbf{x}\\) with \\(P\\mathbf{y}\\) equal to the inner product of \\(P\\mathbf{x}\\) with \\(\\mathbf{y}\\)?\n    \n    (b) Are the two angles the same? Find their cosines if \\(\\mathbf{a} = (1, 1, -1)\\), \\(\\mathbf{x} = (2, 0, 1)\\), \\(\\mathbf{y} = (2, 1, 2)\\).\n    \n    (c) Why is the inner product of \\(P\\mathbf{x}\\) with \\(P\\mathbf{y}\\) again the same? What is the angle between those two?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Project the vector \\(\\mathbf{b}\\) onto the line through \\(\\mathbf{a}\\). Check that \\(\\mathbf{e}\\) is perpendicular to \\(\\mathbf{a}\\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) \\(\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix}\\) and \\(\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "(b) \\(\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix}\\) and \\(\\mathbf{a} = \\begin{bmatrix} -1 \\\\ -3 \\\\ -1 \\end{bmatrix}\\).\n    \\end{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Draw the projection of \\(\\mathbf{b}\\) onto \\(\\mathbf{a}\\) and also compute it from \\(\\mathbf{p} = x \\mathbf{a} \\mathbf{b} \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) \\(\\mathbf{b} = \\begin{bmatrix} \\cos \\theta \\\\ \\sin \\theta \\end{bmatrix}\\) and \\(\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "(b) \\(\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) and \\(\\mathbf{a} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\).\n    \\end{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "In Problem 17, find the projection matrix \\(P = \\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\) onto the line through each vector \\(\\mathbf{a}\\). Verify in both cases that \\(P^2 = P\\). Multiply \\(\\mathbf{P} \\mathbf{b}\\) in each case to compute the projection \\(\\mathbf{p}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct the projection matrices \\(P_1\\) and \\(P_2\\) onto the lines through the \\(\\mathbf{a}\\)'s in Problem 18. Is it true that \\((P_1 + P_2)^2 = P_1 + P_2\\)? This would be true if \\(P_1 P_2 = 0\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Compute the projection matrices \\(\\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\) onto the lines through \\(\\mathbf{a_1} = (-1, 2, 2)\\) and \\(\\mathbf{a_2} = (2, 2, -1)\\). Multiply those projection matrices and explain why their product \\(P_1 P_2\\) is what it is."
    },
    {
        "chapter": "Orthogonality",
        "question": "Project \\(\\mathbf{b} = (1, 0, 0)\\) onto the lines through \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\) in Problem 21 and also onto \\(\\mathbf{a_3} = (2, -1, 2)\\). Add the three projections \\(\\mathbf{p_1} + \\mathbf{p_2} + \\mathbf{p_3}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Continuing Problems 21\u201322, find the projection matrix \\(P_3\\) onto \\(\\mathbf{a_3} = (2, -1, 2)\\). Verify that \\(P_1 + P_2 + P_3 = I\\). The basis \\(\\mathbf{a_1}, \\mathbf{a_2}, \\mathbf{a_3}\\) is orthogonal!"
    },
    {
        "chapter": "Orthogonality",
        "question": "Project the vector \\(\\mathbf{b} = (1, 1)\\) onto the lines through \\(\\mathbf{a_1} = (1, 0)\\) and \\(\\mathbf{a_2} = (1, 2)\\). Draw the projections \\(\\mathbf{p_1}\\) and \\(\\mathbf{p_2}\\) and add \\(\\mathbf{p_1} + \\mathbf{p_2}\\). The projections do not add to \\(\\mathbf{b}\\) because the \\(\\mathbf{a}\\)'s are not orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "In Problem 24, the projection of \\(\\mathbf{b}\\) onto the plane of \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\) will equal \\(\\mathbf{b}\\). Find \\(P = A(A^T A)^{-1} A^T\\) for \\(A = \\begin{bmatrix} \\mathbf{a_1} & \\mathbf{a_2} \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\ 0 & 2 \\end{bmatrix}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Project \\(\\mathbf{a_1} = (1, 0)\\) onto \\(\\mathbf{a_2} = (1, 2)\\). Then project the result back onto \\(\\mathbf{a_1}\\). Draw these projections and multiply the projection matrices \\(P_1 P_2\\). Is this a projection?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the best least-squares solution \\(\\mathbf{x}_b\\) to:\n    \\[\n    3x = 10, \\quad 4x = 5.\n    \\]\n    What error \\(E^2\\) is minimized? Check that the error vector \\((10 - 3\\mathbf{x}_b, 5 - 4\\mathbf{x}_b)\\) is perpendicular to the column \\((3, 4)\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose the values \\(b_1 = 1\\) and \\(b_2 = 7\\) at times \\(t_1 = 1\\) and \\(t_2 = 2\\) are fitted by a line \\(\\mathbf{b} = D\\mathbf{t}\\) through the origin. Solve \\(D = 1\\) and \\(2D = 7\\) by least squares, and sketch the best line."
    },
    {
        "chapter": "Orthogonality",
        "question": "Solve \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) by least squares, and find \\(\\mathbf{p} = \\mathbf{A}\\mathbf{x}_b\\) if\n    \\[\n    \\mathbf{A} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}.\n    \\]\n    Verify that the error \\(\\mathbf{b} - \\mathbf{p}\\) is perpendicular to the columns of \\(\\mathbf{A}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Write out \\(E^2 = \\| \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\|^2\\) and set to zero its derivatives with respect to \\(u\\) and \\(v\\), if\n    \\[\n    \\mathbf{A} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}, \\quad \\mathbf{x} = \\begin{bmatrix} u \\\\ v \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 4 \\end{bmatrix}.\n    \\]\n    Compare the resulting equations with \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x}_b = \\mathbf{A}^T \\mathbf{b}\\), confirming that calculus as well as geometry gives the normal equations. Find the solution \\(\\mathbf{x}_b\\) and the projection \\(\\mathbf{p} = \\mathbf{A}\\mathbf{x}_b\\). Why is \\(\\mathbf{p} = \\mathbf{b}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The following system has no solution:\n    \\[\n    \\mathbf{A} \\mathbf{x} = \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} C \\\\ D \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 5 \\\\ 9 \\end{bmatrix} = \\mathbf{b}.\n    \\]\n    Sketch and solve a straight-line fit that leads to the minimization of the quadratic\n    \\[\n    (C - D - 4)^2 + (C - 5)^2 + (C + D - 9)^2.\n    \\]\n    What is the projection of \\(\\mathbf{b}\\) onto the column space of \\(\\mathbf{A}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the projection of \\(\\mathbf{b}\\) onto the column space of \\(\\mathbf{A}\\):\n    \\[\n    \\mathbf{A} = \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ -2 & 4 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 7 \\end{bmatrix}.\n    \\]\n    Split \\(\\mathbf{b}\\) into \\(\\mathbf{p} + \\mathbf{q}\\), with \\(\\mathbf{p}\\) in the column space and \\(\\mathbf{q}\\) perpendicular to that space. Which of the four subspaces contains \\(\\mathbf{q}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the projection matrix \\(\\mathbf{P}\\) onto the space spanned by \\(\\mathbf{a_1} = (1, 0, 1)\\) and \\(\\mathbf{a_2} = (1, 1, -1)\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\(\\mathbf{P}\\) is the projection matrix onto a \\(k\\)-dimensional subspace \\(S\\) of the whole space \\(\\mathbb{R}^n\\), what is the column space of \\(\\mathbf{P}\\) and what is its rank?"
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) If \\(\\mathbf{P} = \\mathbf{P}^T\\), show that \\(\\mathbf{P}\\) is a projection matrix.\n    (b) What subspace does the matrix \\(\\mathbf{P} = 0\\) project onto?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If the vectors \\(\\mathbf{a_1}\\), \\(\\mathbf{a_2}\\), and \\(\\mathbf{b}\\) are orthogonal, what are \\(\\mathbf{A}^T \\mathbf{A}\\) and \\(\\mathbf{A}^T \\mathbf{b}\\)? What is the projection of \\(\\mathbf{b}\\) onto the plane of \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose \\(\\mathbf{P}\\) is the projection matrix onto the subspace \\(\\mathbf{S}\\) and \\(\\mathbf{Q}\\) is the projection onto the orthogonal complement \\(\\mathbf{S}^\\perp\\). What are \\(\\mathbf{P} + \\mathbf{Q}\\) and \\(\\mathbf{P}\\mathbf{Q}\\)? Show that \\(\\mathbf{P} - \\mathbf{Q}\\) is its own inverse."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\(\\mathbf{V}\\) is the subspace spanned by \\((1, 1, 0, 1)\\) and \\((0, 0, 1, 0)\\), find:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "A basis for the orthogonal complement \\(\\mathbf{V}^\\perp\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The projection matrix \\(\\mathbf{P}\\) onto \\(\\mathbf{V}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The vector in \\(\\mathbf{V}\\) closest to the vector \\(\\mathbf{b} = (0, 1, 0, -1)\\) in \\(\\mathbf{V}^\\perp\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the best straight-line fit (least squares) to the measurements \\(\\mathbf{b} = 4\\) at \\(t = -2\\), \\(\\mathbf{b} = 3\\) at \\(t = -1\\), \\(\\mathbf{b} = 1\\) at \\(t = 0\\), and \\(\\mathbf{b} = 0\\) at \\(t = 2\\). Then, find the projection of \\(\\mathbf{b} = (4, 3, 1, 0)\\) onto the column space of\n    \\[\n    \\mathbf{A} = \\begin{bmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "The vectors \\(\\mathbf{a_1} = (1, 1, 0)\\) and \\(\\mathbf{a_2} = (1, 1, 1)\\) span a plane in \\(\\mathbb{R}^3\\). Find the projection matrix \\(\\mathbf{P}\\) onto the plane, and find a nonzero vector \\(\\mathbf{b}\\) that is projected to zero."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\(\\mathbf{P}\\) is the projection matrix onto a line in the x-y plane, draw a figure to describe the effect of the \u201creflection matrix\u201d \\(\\mathbf{H} = \\mathbf{I} - 2\\mathbf{P}\\). Explain both geometrically and algebraically why \\(\\mathbf{H}^2 = \\mathbf{I}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that if \\(\\mathbf{u}\\) has unit length, then the rank-1 matrix \\(\\mathbf{P} = \\mathbf{u}\\mathbf{u}^T\\) is a projection matrix. It has properties (i) and (ii) in 3N. By choosing \\(\\mathbf{u} = \\frac{\\mathbf{a}}{\\|\\mathbf{a}\\|}\\), \\(\\mathbf{P}\\) becomes the projection onto the line through \\(\\mathbf{a}\\), and \\(\\mathbf{P}\\mathbf{b}\\) is the point \\(\\mathbf{p} = x_{ab}\\). Rank-1 projections correspond exactly to least-squares problems in one unknown."
    },
    {
        "chapter": "Orthogonality",
        "question": "What 2 by 2 matrix projects the x-y plane onto the \\(-45^\\circ\\) line \\(x + y = 0\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "We want to fit a plane \\(y = C + Dt + Ez\\) to the four points:\n    \\[\n    y = 3 \\text{ at } t = 1, z = 1, \\quad y = 6 \\text{ at } t = 0, z = 3, \\quad y = 5 \\text{ at } t = 2, z = 1, \\quad y = 0 \\text{ at } t = 0, z = 0.\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find 4 equations in 3 unknowns to pass a plane through the points (if there is such a plane)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find 3 equations in 3 unknowns for the best least-squares solution."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\(\\mathbf{P_C} = \\mathbf{A}(\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\\) is the projection onto the column space of \\(\\mathbf{A}\\), what is the projection \\(\\mathbf{P_R}\\) onto the row space? (It is not \\(\\mathbf{P_C}^T\\)!)"
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\(\\mathbf{P}\\) is the projection onto the column space of \\(\\mathbf{A}\\), what is the projection onto the left nullspace?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose \\(L_1\\) is the line through the origin in the direction of \\(\\mathbf{a_1}\\) and \\(L_2\\) is the line through \\(\\mathbf{b}\\) in the direction of \\(\\mathbf{a_2}\\). To find the closest points \\(\\mathbf{x_1a_1}\\) and \\(\\mathbf{b} + \\mathbf{x_2a_2}\\) on the two lines, write the two equations for \\(\\mathbf{x_1}\\) and \\(\\mathbf{x_2}\\) that minimize \\(\\|\\mathbf{x_1a_1} - \\mathbf{x_2a_2} - \\mathbf{b}\\|\\). Solve for \\(\\mathbf{x}\\) if \\(\\mathbf{a_1} = (1, 1, 0)\\), \\(\\mathbf{a_2} = (0, 1, 0)\\), and \\(\\mathbf{b} = (2, 1, 4)\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the best line \\(C + Dt\\) to fit \\(\\mathbf{b} = (4, 2, -1, 0, 0)\\) at times \\(t = -2, -1, 0, 1, 2\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the best least-squares fit to a set of measurements \\(y_1, \\dots, y_m\\) by a horizontal line (a constant function \\(y = C\\)) is their average\n    \\[\n    C = \\frac{y_1 + \\dots + y_m}{m}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the best straight-line fit to the following measurements, and sketch your solution:\n    \\[\n    y = 2 \\text{ at } t = -1, \\quad y = 0 \\text{ at } t = 0, \\quad y = -3 \\text{ at } t = 1, \\quad y = -5 \\text{ at } t = 2.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose that instead of a straight line, we fit the data in Problem 24 by a parabola: \\(y = C + Dt + Et^2\\). In the inconsistent system \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) that comes from the four measurements, what are the coefficient matrix \\(\\mathbf{A}\\), the unknown vector \\(\\mathbf{x}\\), and the data vector \\(\\mathbf{b}\\)? You need not compute \\(\\mathbf{x_b}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "A middle-aged man was stretched on a rack to lengths \\(L = 5, 6, 7\\) feet under applied forces of \\(F = 1, 2, 4\\) tons. Assuming Hooke\u2019s law \\(L = a + bF\\), find his normal length \\(a\\) by least squares."
    },
    {
        "chapter": "Orthogonality",
        "question": "(Recommended) This problem projects \\(\\mathbf{b} = (b_1, \\dots, b_m)\\) onto the line through \\(\\mathbf{a} = (1, \\dots, 1)\\). We solve \\(m\\) equations \\(\\mathbf{a}^T \\mathbf{x} = \\mathbf{b}\\) in one unknown (by least squares).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Solve \\(\\mathbf{a}^T \\mathbf{a} \\mathbf{x_b} = \\mathbf{a}^T \\mathbf{b}\\) to show that \\(\\mathbf{x_b}\\) is the mean (the average) of the \\(b\\)\u2019s."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find \\(\\mathbf{e} = \\mathbf{b} - \\mathbf{a} \\mathbf{x_b}\\), the variance \\(\\|\\mathbf{e}\\|^2\\), and the standard deviation \\(\\|\\mathbf{e}\\|\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The horizontal line \\(\\mathbf{b_b} = 3\\) is closest to \\(\\mathbf{b} = (1, 2, 6)\\). Check that \\(\\mathbf{p} = (3, 3, 3)\\) is perpendicular to \\(\\mathbf{e}\\) and find the projection matrix \\(\\mathbf{P}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "First assumption behind least squares: Each measurement error has mean zero. Multiply the 8 error vectors \\(\\mathbf{b} - \\mathbf{A}\\mathbf{x} = (\\pm1, \\pm1, \\pm1)\\) by \\((\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T\\) to show that the 8 vectors \\(\\mathbf{x_b} - \\mathbf{x}\\) also average to zero. The estimate \\(\\mathbf{x_b}\\) is unbiased."
    },
    {
        "chapter": "Orthogonality",
        "question": "Second assumption behind least squares: The \\(m\\) errors \\(e_i\\) are independent with variance \\(\\sigma^2\\), so the average of \\((\\mathbf{b} - \\mathbf{A}\\mathbf{x})(\\mathbf{b} - \\mathbf{A}\\mathbf{x})^T\\) is \\(\\sigma^2 \\mathbf{I}\\). Multiply on the left by \\((\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T\\) and on the right by \\(\\mathbf{A} (\\mathbf{A}^T \\mathbf{A})^{-1}\\) to show that the average of \\((\\mathbf{x_b} - \\mathbf{x})(\\mathbf{x_b} - \\mathbf{x})^T\\) is \\(\\sigma^2 (\\mathbf{A}^T \\mathbf{A})^{-1}\\). This is the all-important covariance matrix for the error in \\(\\mathbf{x_b}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "A doctor takes four readings of your heart rate. The best solution to \\(\\mathbf{x} = \\mathbf{b_1}, \\dots, \\mathbf{x} = \\mathbf{b_4}\\) is the average \\(\\mathbf{x_b}\\) of \\(\\mathbf{b_1}, \\dots, \\mathbf{b_4}\\). The matrix \\(\\mathbf{A}\\) is a column of 1s. Problem 29 gives the expected error \\((\\mathbf{x_b} - \\mathbf{x})^2\\) as \\(\\sigma^2 (\\mathbf{A}^T \\mathbf{A})^{-1} = \\dots\\). By averaging, the variance drops from \\(\\sigma^2\\) to \\(\\sigma^2 / 4\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If you know the average \\(\\mathbf{x_b_9}\\) of 9 numbers \\(\\mathbf{b_1}, \\dots, \\mathbf{b_9}\\), how can you quickly find the average \\(\\mathbf{x_b_{10}}\\) with one more number \\(\\mathbf{b_{10}}\\)? The idea of recursive least squares is to avoid adding 10 numbers. What coefficient of \\(\\mathbf{x_b_9}\\) correctly gives \\(\\mathbf{x_b_{10}}\\)?\n    \\[\n    \\mathbf{x_b_{10}} = \\frac{1}{10} \\left( b_1 + \\dots + b_{10} \\right) = \\frac{1}{10} \\mathbf{b_{10}} + \\mathbf{x_b_9}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "With \\(\\mathbf{b} = (0, 8, 8, 20)\\) at \\(t = 0, 1, 3, 4\\), set up and solve the normal equations \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x_b} = \\mathbf{A}^T \\mathbf{b}\\). For the best straight line as in Figure 3.9a, find its four heights \\(\\mathbf{p_i}\\) and four errors \\(\\mathbf{e_i}\\). What is the minimum value \\(E^2 = e_1^2 + e_2^2 + e_3^2 + e_4^2\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "(Line \\(C + Dt\\) does go through \\(\\mathbf{p}\\)) With \\(\\mathbf{b} = (0, 8, 8, 20)\\) at times \\(t = 0, 1, 3, 4\\), write the four equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) (unsolvable). Change the measurements to \\(\\mathbf{p} = (1, 5, 13, 17)\\) and find an exact solution to \\(\\mathbf{A} \\mathbf{x} = \\mathbf{p}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Check that \\(\\mathbf{e} = \\mathbf{b} - \\mathbf{p} = (-1, 3, -5, 3)\\) is perpendicular to both columns of \\(\\mathbf{A}\\). What is the shortest distance \\(\\|\\mathbf{e}\\|\\) from \\(\\mathbf{b}\\) to the column space of \\(\\mathbf{A}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "For the closest parabola \\(\\mathbf{b} = C + Dt + Et^2\\) to the same four points, write the unsolvable equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) in three unknowns \\(\\mathbf{x} = (C, D, E)\\). Set up the three normal equations \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x_b} = \\mathbf{A}^T \\mathbf{b}\\) (solution not required). You are now fitting a parabola to four points\u2014what is happening in Figure 3.9b?"
    },
    {
        "chapter": "Orthogonality",
        "question": "For the closest cubic \\(\\mathbf{b} = C + Dt + Et^2 + Ft^3\\) to the same four points, write the four equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\). Solve them by elimination. This cubic now goes exactly through the points. What are \\(\\mathbf{p}\\) and \\(\\mathbf{e}\\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The average of the four times is \\(\\mathbf{b_t} = \\frac{1}{4} (0 + 1 + 3 + 4) = 2\\). The average of the four \\(\\mathbf{b}\\)\u2019s is \\(\\mathbf{b_b} = \\frac{1}{4} (0 + 8 + 8 + 20) = 9\\).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Verify that the best line goes through the center point \\((\\mathbf{b_t}, \\mathbf{b_b}) = (2, 9)\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Explain why \\(C + D \\mathbf{b_t} = \\mathbf{b_b}\\) comes from the first equation in \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x_b} = \\mathbf{A}^T \\mathbf{b}\\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "What happens to the weighted average \\(\\mathbf{x_b_W} = \\frac{w_1^2 \\mathbf{b_1} + w_2^2 \\mathbf{b_2}}{w_1^2 + w_2^2}\\) if the first weight \\(w_1\\) approaches zero? The measurement \\(\\mathbf{b_1}\\) is totally unreliable."
    },
    {
        "chapter": "Orthogonality",
        "question": "From \\( m \\) independent measurements \\( b_1, \\dots, b_m \\) of your pulse rate, weighted by \\( w_1, \\dots, w_m \\), what is the weighted average that replaces equation (9)? It is the best estimate when the statistical variances are \\( \\sigma_i^2 \\equiv \\frac{1}{w_i^2} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( W = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\), find the \\( W \\)-inner product of \\( \\mathbf{x} = (2, 3) \\) and \\( \\mathbf{y} = (1, 1) \\), and the \\( W \\)-length of \\( \\mathbf{x} \\). What line of vectors is \\( W \\)-perpendicular to \\( \\mathbf{y} \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the weighted least-squares solution \\( \\mathbf{x_b_W} \\) to \\( \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\):\n    \\[\n    \\mathbf{A} = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{W} = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}.\n    \\]\n    Check that the projection \\( \\mathbf{A} \\mathbf{x_b_W} \\) is still perpendicular (in the \\( W \\)-inner product) to the error \\( \\mathbf{b} - \\mathbf{A} \\mathbf{x_b_W} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) Suppose you guess your professor\u2019s age, making errors \\( e = -2, -1, 5 \\) with probabilities \\( \\frac{1}{2}, \\frac{1}{4}, \\frac{1}{4} \\). Check that the expected error \\( E(e) \\) is zero and find the variance \\( E(e^2) \\).\n    \n    (b) If the professor guesses too (or tries to remember), making errors \\( -1, 0, 1 \\) with probabilities \\( \\frac{1}{8}, \\frac{6}{8}, \\frac{1}{8} \\), what weights \\( w_1 \\) and \\( w_2 \\) give the reliability of your guess and the professor\u2019s guess?"
    },
    {
        "chapter": "Orthogonality",
        "question": "(a) Write the four equations for fitting \\( y = C + Dt \\) to the data \n    \\[\n    y = -4 \\text{ at } t = -2, \\quad y = -3 \\text{ at } t = -1, \\quad y = -1 \\text{ at } t = 1, \\quad y = 0 \\text{ at } t = 2.\n    \\]\n    Show that the columns are orthogonal.\n    \n    (b) Find the optimal straight line, draw its graph, and write \\( E^2 \\).\n    \n    (c) Interpret the zero error in terms of the original system of four equations in two unknowns: The right-hand side \\( (-4, -3, -1, 0) \\) is in the space."
    },
    {
        "chapter": "Orthogonality",
        "question": "Project \\( b = (0,3,0) \\) onto each of the orthonormal vectors \\( a_1 = \\left( \\frac{2}{3}, \\frac{2}{3}, -\\frac{1}{3} \\right) \\) and \\( a_2 = \\left( -\\frac{1}{3}, \\frac{2}{3}, \\frac{2}{3} \\right) \\), and then find its projection \\( p \\) onto the plane of \\( a_1 \\) and \\( a_2 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find also the projection of \\( b = (0,3,0) \\) onto \\( a_3 = \\left( \\frac{2}{3}, -\\frac{1}{3}, \\frac{2}{3} \\right) \\), and add the three projections. Why is \\( P = a_1 a_1^T + a_2 a_2^T + a_3 a_3^T \\) equal to \\( I \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( Q_1 \\) and \\( Q_2 \\) are orthogonal matrices, so that \\( Q^T Q = I \\), show that \\( Q_1 Q_2 \\) is also orthogonal. If \\( Q_1 \\) is rotation through \\( \\theta \\), and \\( Q_2 \\) is rotation through \\( \\phi \\), what is \\( Q_1 Q_2 \\)? Can you find the trigonometric identities for \\( \\sin(\\theta + \\phi) \\) and \\( \\cos(\\theta + \\phi) \\) in the matrix multiplication \\( Q_1 Q_2 \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( \\mathbf{u} \\) is a unit vector, show that \\( Q = I - 2 \\mathbf{u} \\mathbf{u}^T \\) is a symmetric orthogonal matrix. (It is a reflection, also known as a Householder transformation.) Compute \\( Q \\) when\n    \\[\n    \\mathbf{u}^T = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & -\\frac{1}{2} & -\\frac{1}{2} \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a third column so that the matrix\n    \\[\n    Q = \\begin{pmatrix} \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{14}} & \\frac{1}{\\sqrt{3}} & \\frac{2}{\\sqrt{14}} & \\frac{1}{\\sqrt{3}} & -\\frac{3}{\\sqrt{14}} \\end{pmatrix}\n    \\]\n    is orthogonal. It must be a unit vector that is orthogonal to the other columns; how much freedom does this leave? Verify that the rows automatically become orthonormal at the same time."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show, by forming \\( b^T b \\) directly, that Pythagoras\u2019s law holds for any combination\n    \\[\n    b = x_1 q_1 + \\dots + x_n q_n\n    \\]\n    of orthonormal vectors: \\( \\| b \\|^2 = x_1^2 + \\dots + x_n^2 \\). In matrix terms, \\( b = Qx \\), so this again proves that lengths are preserved: \\( \\| Qx \\|^2 = \\| x \\|^2 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Project the vector \\( b = (1,2) \\) onto two vectors that are not orthogonal, \\( a_1 = (1,0) \\) and \\( a_2 = (1,1) \\). Show that, unlike the orthogonal case, the sum of the two one-dimensional projections does not equal \\( b \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If the vectors \\( q_1, q_2, q_3 \\) are orthonormal, what combination of \\( q_1 \\) and \\( q_2 \\) is closest to \\( q_3 \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( q_1 \\) and \\( q_2 \\) are the outputs from Gram-Schmidt, what were the possible input vectors \\( a \\) and \\( b \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that an orthogonal matrix that is upper triangular must be diagonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "What multiple of \\( a_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\) should be subtracted from \\( a_2 = \\begin{pmatrix} 4 \\\\ 0 \\end{pmatrix} \\) to make the result orthogonal to \\( a_1 \\)? Factor \\( \\begin{pmatrix} 1 & 4 \\\\ 1 & 0 \\end{pmatrix} \\) into QR with orthonormal vectors in \\( Q \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Apply the Gram-Schmidt process to \n    \\[\n    a = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n    \\]\n    and write the result in the form \\( A = QR \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "From the nonorthogonal \\( a, b, c \\), find orthonormal vectors \\( q_1, q_2, q_3 \\):\n    \\[\n    a = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find an orthonormal set \\( q_1, q_2, q_3 \\) for which \\( q_1, q_2 \\) span the column space of\n    \\[\n    A = \\begin{pmatrix} 1 & 1 \\\\ 2 & -1 \\\\ -2 & 4 \\end{pmatrix}.\n    \\]\n    Which fundamental subspace contains \\( q_3 \\)? What is the least-squares solution of \\( Ax = b \\) if \\( b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 7 \\end{pmatrix} \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Express the Gram-Schmidt orthogonalization of \\( a_1, a_2 \\) as \\( A = QR \\):\n    \\[\n    a_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}, \\quad a_2 = \\begin{pmatrix} 1 \\\\ 3 \\\\ 1 \\end{pmatrix}.\n    \\]\n    Given \\( n \\) vectors \\( a_i \\) with \\( m \\) components, what are the shapes of \\( A \\), \\( Q \\), and \\( R \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "With the same matrix \\( A \\) as in Problem 16, and with \\( b = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\), use \\( A = QR \\) to solve the least-squares problem \\( Ax = b \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( A = QR \\), find a simple formula for the projection matrix \\( P \\) onto the column space of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that these modified Gram-Schmidt steps produce the same \\( C \\) as in equation (10):\n    \\[\n    C^* = c - (q_1^T c) q_1 \\quad \\text{and} \\quad C = C^* - (q_2^T C^*) q_2.\n    \\]\n    This is much more stable, to subtract the projections one at a time."
    },
    {
        "chapter": "Orthogonality",
        "question": "In Hilbert space, find the length of the vector \\( v = \\left( \\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{4}}, \\frac{1}{\\sqrt{8}}, \\dots \\right) \\) and the length of the function \\( f(x) = e^x \\) (over the interval \\( 0 \\leq x \\leq 1 \\)). What is the inner product over this interval of \\( e^x \\) and \\( e^{-x} \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "What is the closest function \\( a \\cos x + b \\sin x \\) to the function \\( f(x) = \\sin 2x \\) on the interval from \\( -\\pi \\) to \\( \\pi \\)? What is the closest straight line \\( c + dx \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "By setting the derivative to zero, find the value of \\( b_1 \\) that minimizes\n    \\[\n    \\| b_1 \\sin x - \\cos x \\|^2 = \\int_0^{2\\pi} \\left( b_1 \\sin x - \\cos x \\right)^2 dx.\n    \\]\n    Compare with the Fourier coefficient \\( b_1 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the Fourier coefficients \\( a_0, a_1, b_1 \\) of the step function \\( y(x) \\), which equals 1 on the interval \\( 0 \\leq x \\leq \\pi \\) and 0 on the remaining interval \\( \\pi < x < 2\\pi \\):\n    \\[\n    a_0 = \\frac{(y, 1)}{(1, 1)}, \\quad a_1 = \\frac{(y, \\cos x)}{(\\cos x, \\cos x)}, \\quad b_1 = \\frac{(y, \\sin x)}{(\\sin x, \\sin x)}.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the fourth Legendre polynomial. It is a cubic \\( x^3 + ax^2 + bx + c \\) that is orthogonal to 1, \\( x \\), and \\( x^2 - \\frac{1}{3} \\) over the interval \\( -1 \\leq x \\leq 1 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "What is the closest straight line to the parabola \\( y = x^2 \\) over \\( -1 \\leq x \\leq 1 \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "In the Gram-Schmidt formula (10), verify that \\( C \\) is orthogonal to \\( q_1 \\) and \\( q_2 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find an orthonormal basis for the subspace spanned by\n    \\[\n    a_1 = (1, -1, 0, 0), \\quad a_2 = (0, 1, -1, 0), \\quad a_3 = (0, 0, 1, -1).\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Apply Gram-Schmidt to \\( (1, -1, 0), (0, 1, -1), (1, 0, -1) \\), to find an orthonormal basis on the plane \\( x_1 + x_2 + x_3 = 0 \\). What is the dimension of this subspace, and how many nonzero vectors come out of Gram-Schmidt?"
    },
    {
        "chapter": "Orthogonality",
        "question": "(Recommended) Find orthogonal vectors \\( A, B, C \\) by Gram-Schmidt from \\( a, b, c \\):\n    \\[\n    a = (1, -1, 0, 0), \\quad b = (0, 1, -1, 0), \\quad c = (0, 0, 1, -1).\n    \\]\n    \\( A, B, C \\) and \\( a, b, c \\) are bases for the vectors perpendicular to \\( d = (1, 1, 1, 1) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( A = QR \\), then \\( A^T A = R^T R \\) (triangular times triangular). Gram-Schmidt on \\( A \\) corresponds to elimination on \\( A^T A \\). Compare\n    \\[\n    A = \\begin{bmatrix}\n        1 & 0 & 0 \\\\\n        -1 & 1 & 0 \\\\\n        0 & -1 & 1 \\\\\n        0 & 0 & -1\n    \\end{bmatrix}\n    \\quad \\text{with} \\quad \n    A^T A = \\begin{bmatrix}\n        2 & -1 & 0 \\\\\n        -1 & 2 & -1 \\\\\n        0 & -1 & 2\n    \\end{bmatrix}.\n    \\]\n    For \\( A^T A \\), the pivots are \\( 2, \\frac{3}{2}, \\frac{4}{3} \\), and the multipliers are \\( -\\frac{1}{2} \\) and \\( -\\frac{2}{3} \\).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Using those multipliers in \\( A \\), show that column 1 of \\( A \\) and \\( B = \\text{column 2} - \\frac{1}{2} (\\text{column 1}) \\) and \\( C = \\text{column 3} - \\frac{2}{3} (\\text{column 2}) \\) are orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Check that \\( \\| \\text{column 1} \\|_2 = 2 \\), \\( \\| B \\|_2 = \\frac{3}{2} \\), and \\( \\| C \\|_2 = \\frac{4}{3} \\), using the pivots."
    },
    {
        "chapter": "Orthogonality",
        "question": "True or false (give an example in either case):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "\\( Q^{-1} \\) is an orthogonal matrix when \\( Q \\) is an orthogonal matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( Q \\) (3 by 2) has orthonormal columns, then \\( \\| Qx \\| \\) always equals \\( \\| x \\| \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a basis for the subspace \\( S \\) in \\( \\mathbb{R}^4 \\) spanned by all solutions of\n        \\[\n        x_1 + x_2 + x_3 - x_4 = 0.\n        \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a basis for the orthogonal complement \\( S^\\perp \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find \\( b_1 \\in S \\) and \\( b_2 \\in S^\\perp \\) so that \\( b_1 + b_2 = b = (1, 1, 1, 1) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "What are \\( F_2 \\) and \\( F_4 \\) for the \\( 4 \\times 4 \\) Fourier matrix \\( F \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find a permutation \\( P \\) of the columns of \\( F \\) that produces \\( FP = F \\) (for \\( n \\times n \\)). Combine with \\( FF = nI \\) to find \\( F^2 \\) and \\( F^4 \\) for the \\( n \\times n \\) Fourier matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "If you form a \\( 3 \\times 3 \\) submatrix of the \\( 6 \\times 6 \\) matrix \\( F_6 \\), keeping only the entries in its first, third, and fifth rows and columns, what is that submatrix?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Mark all the sixth roots of \\( 1 \\) in the complex plane. What is the primitive root \\( \\omega_6 \\)? (Find its real and imaginary parts.) Which power of \\( \\omega_6 \\) is equal to \\( \\frac{1}{\\omega_6} \\)? What is\n    \\[\n    1 + \\omega + \\omega^2 + \\omega^3 + \\omega^4 + \\omega^5?\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find all solutions to the equation \\( e^{ix} = -1 \\), and all solutions to \\( e^{i\\theta} = i \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "What are the square and the square root of \\( \\omega_{128} \\), the primitive 128th root of 1?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Solve the \\( 4 \\times 4 \\) system if the right-hand sides are \\( y_0 = 2, y_1 = 0, y_2 = 2, y_3 = 0 \\). In other words, solve \\( F_4c = y \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Solve the same system with \\( y = (2,0,-2,0) \\) by knowing \\( F_4^{-1} \\) and computing \\( c = F_4^{-1} y \\). Verify that \n    \\[\n    c_0 + c_1 e^{ix} + c_2 e^{2ix} + c_3 e^{3ix}\n    \\]\n    takes the values \\( 2, 0, -2, 0 \\) at the points \\( x = 0, \\frac{\\pi}{2}, \\pi, \\frac{3\\pi}{2} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "If \\( y = (1,1,1,1) \\), show that \\( c = (1,0,0,0) \\) satisfies \\( F_4c = y \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Now suppose \\( y = (1,0,0,0) \\), and find \\( c \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Orthogonality",
        "question": "For \\( n = 2 \\), write \\( y_0 \\) from the first line of equation (13) and \\( y_1 \\) from the second line."
    },
    {
        "chapter": "Orthogonality",
        "question": "For \\( n = 4 \\), use the first line to find \\( y_0 \\) and \\( y_1 \\), and the second to find \\( y_2 \\) and \\( y_3 \\), all in terms of \\( y_0 \\) and \\( y'' \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Compute \\( y = F_4c \\) by the three steps of the Fast Fourier Transform if \\( c = (1,0,1,0) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Compute \\( y = F_8c \\) by the three steps of the Fast Fourier Transform if \\( c = (1,0,1,0,1,0,1,0) \\). Repeat the computation with \\( c = (0,1,0,1,0,1,0,1) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "For the \\( 4 \\times 4 \\) matrix, write out the formulas for \\( c_0, c_1, c_2, c_3 \\) and verify that if \\( f \\) is odd then \\( c \\) is odd. The vector \\( f \\) is odd if \\( f_{n-j} = -f_j \\); for \\( n = 4 \\) that means \\( f_0 = 0, f_3 = -f_1, f_2 = 0 \\) as in \\( \\sin 0, \\sin \\frac{\\pi}{2}, \\sin \\pi, \\sin \\frac{3\\pi}{2} \\). This is copied by \\( c \\) and it leads to a fast sine transform."
    },
    {
        "chapter": "Orthogonality",
        "question": "Multiply the three matrices in equation (16) and compare with \\( F \\). In which six entries do you need to know that \\( i^2 = -1 \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Invert the three factors in equation (14) to find a fast factorization of \\( F^{-1} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "\\( F \\) is symmetric. So transpose equation (14) to find a new Fast Fourier Transform!"
    },
    {
        "chapter": "Orthogonality",
        "question": "All entries in the factorization of \\( F_6 \\) involve powers of \\( \\omega \\), the sixth root of 1:\n    \\[\n    F_6 =\n    \\begin{bmatrix}\n        I & D \\\\\n        I & -D\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        F_3 & 0 \\\\\n        0 & F_3\n    \\end{bmatrix}\n    P.\n    \\]\n    Write these factors with \\( 1, \\omega, \\omega^2 \\) in \\( D \\) and \\( 1, \\omega^2, \\omega^4 \\) in \\( F_3 \\). Multiply!"
    },
    {
        "chapter": "Orthogonality",
        "question": "The columns of the Fourier matrix $F$ are the eigenvectors of the cyclic permutation $P$. Multiply $PF$ to find the eigenvalues $\\lambda_0$ to $\\lambda_3$:\n    \\begin{equation*}\n        \\begin{bmatrix}\n            0 & 1 & 0 & 0 \\\\\n            0 & 0 & 1 & 0 \\\\\n            0 & 0 & 0 & 1 \\\\\n            1 & 0 & 0 & 0\n        \\end{bmatrix}\n        \\begin{bmatrix}\n            1 & 1 & 1 & 1 \\\\\n            1 & i & i^2 & i^3 \\\\\n            1 & i^2 & i^4 & i^6 \\\\\n            1 & i^3 & i^6 & i^9\n        \\end{bmatrix}\n        =\n        \\begin{bmatrix}\n            1 & 1 & 1 & 1 \\\\\n            1 & i & i^2 & i^3 \\\\\n            1 & i^2 & i^4 & i^6 \\\\\n            1 & i^3 & i^6 & i^9\n        \\end{bmatrix}\n        \\begin{bmatrix}\n            \\lambda_0 \\\\\n            \\lambda_1 \\\\\n            \\lambda_2 \\\\\n            \\lambda_3\n        \\end{bmatrix}.\n    \\end{equation*}\n    This is $PF = F\\Lambda$ or $P = F\\Lambda F^{-1}$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Two eigenvectors of this circulant matrix $C$ are $(1,1,1,1)$ and $(1,i,i^2,i^3)$. What are the eigenvalues $e_0$ and $e_1$?\n    \\begin{equation*}\n        \\begin{bmatrix}\n            c_0 & c_1 & c_2 & c_3 \\\\\n            c_3 & c_0 & c_1 & c_2 \\\\\n            c_2 & c_3 & c_0 & c_1 \\\\\n            c_1 & c_2 & c_3 & c_0\n        \\end{bmatrix}\n        \\begin{bmatrix}\n            1 \\\\\n            1 \\\\\n            1 \\\\\n            1\n        \\end{bmatrix}\n        = e_0\n        \\begin{bmatrix}\n            1 \\\\\n            1 \\\\\n            1 \\\\\n            1\n        \\end{bmatrix}\n    \\end{equation*}\n    and\n    \\begin{equation*}\n        C\n        \\begin{bmatrix}\n            1 \\\\\n            i \\\\\n            i^2 \\\\\n            i^3\n        \\end{bmatrix}\n        = e_1\n        \\begin{bmatrix}\n            1 \\\\\n            i \\\\\n            i^2 \\\\\n            i^3\n        \\end{bmatrix}.\n    \\end{equation*}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the eigenvalues of the \u201cperiodic\u201d $-1, 2, -1$ matrix $C$. The $-1$s in the corners of $C$ make it periodic (a circulant matrix):\n    \\begin{equation*}\n        C =\n        \\begin{bmatrix}\n            2 & -1 & 0 & -1 \\\\\n            -1 & 2 & -1 & 0 \\\\\n            0 & -1 & 2 & -1 \\\\\n            -1 & 0 & -1 & 2\n        \\end{bmatrix}\n    \\end{equation*}\n    has $c_0 = 2, c_1 = -1, c_2 = 0, c_3 = -1$."
    },
    {
        "chapter": "Orthogonality",
        "question": "To multiply $C$ times $x$, when $C = FEF^{-1}$, we can multiply $F(E(F^{-1}x))$ instead. The direct $Cx$ uses $n^2$ separate multiplications. Knowing $E$ and $F$, the second way uses only $n \\log_2 n + n$ multiplications. How many of those come from $E$, how many from $F$, and how many from $F^{-1}$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "How could you quickly compute these four components of $Fc$ starting from $c_0 + c_2$, $c_0 - c_2$, $c_1 + c_3$, $c_1 - c_3$? You are finding the Fast Fourier Transform!\n    \\begin{equation*}\n        Fc =\n        \\begin{bmatrix}\n            c_0 + c_1 + c_2 + c_3 \\\\\n            c_0 + i c_1 + i^2 c_2 + i^3 c_3 \\\\\n            c_0 + i^2 c_1 + i^4 c_2 + i^6 c_3 \\\\\n            c_0 + i^3 c_1 + i^6 c_2 + i^9 c_3\n        \\end{bmatrix}\n    \\end{equation*}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the length of $a = (2,-2,1)$, and write two independent vectors that are perpendicular to $a$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find all vectors that are perpendicular to $(1,3,1)$ and $(2,7,2)$, by making those the rows of $A$ and solving $Ax = 0$."
    },
    {
        "chapter": "Orthogonality",
        "question": "What is the angle between $a = (2,-2,1)$ and $b = (1,2,2)$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "What is the projection $p$ of $b = (1,2,2)$ onto $a = (2,-2,1)$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the cosine of the angle between the vectors $(3,4)$ and $(4,3)$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Where is the projection of $b = (1,1,1)$ onto the plane spanned by $(1,0,0)$ and $(1,1,0)$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "The system $Ax = b$ has a solution if and only if $b$ is orthogonal to which of the four fundamental subspaces?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Which straight line gives the best fit to the following data: $b = 0$ at $t = 0$, $b = 0$ at $t = 1$, $b = 12$ at $t = 3$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Construct the projection matrix $P$ onto the space spanned by $(1,1,1)$ and $(0,1,3)$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Which constant function is closest to $y = x^4$ (in the least-squares sense) over the interval $0 \\leq x \\leq 1$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "If $Q$ is orthogonal, is the same true of $Q^3$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find all $3 \\times 3$ orthogonal matrices whose entries are zeros and ones."
    },
    {
        "chapter": "Orthogonality",
        "question": "What multiple of $a_1$ should be subtracted from $a_2$, to make the result orthogonal to $a_1$? Sketch a figure."
    },
    {
        "chapter": "Orthogonality",
        "question": "Factor \n    \\[\n    \\begin{bmatrix}\n        \\cos\\theta & \\sin\\theta \\\\\n        \\sin\\theta & 0\n    \\end{bmatrix}\n    \\]\n    into QR, recognizing that the first column is already a unit vector."
    },
    {
        "chapter": "Orthogonality",
        "question": "If every entry in an orthogonal matrix is either $\\frac{1}{4}$ or $-\\frac{1}{4}$, how big is the matrix?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose the vectors $q_1, \\dots, q_n$ are orthonormal. If $b = c_1q_1 + \\dots + c_nq_n$, give a formula for the first coefficient $c_1$ in terms of $b$ and the $q$'s."
    },
    {
        "chapter": "Orthogonality",
        "question": "What words describe the equation $A^T A x = A^T b$, the vector $p = Ax = Pb$, and the matrix $P = A(A^T A)^{-1} A^T$?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Given the orthonormal vectors \\( q_1 = \\left(\\frac{2}{3}, \\frac{2}{3}, -\\frac{1}{3} \\right) \\) and \\( q_2 = \\left(-\\frac{1}{3}, \\frac{2}{3}, \\frac{2}{3} \\right) \\) as columns of \\( Q \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the matrices \\( Q^TQ \\) and \\( QQ^T \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that \\( QQ^T \\) is a projection matrix onto the plane of \\( q_1 \\) and \\( q_2 \\).\n    \\end{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that if \\( v_1, \\dots, v_n \\) is an orthonormal basis for \\( \\mathbb{R}^n \\), then:\n    \\[\n    v_1 v_1^T + \\dots + v_n v_n^T = I.\n    \\]"
    },
    {
        "chapter": "Orthogonality",
        "question": "True or False: If the vectors \\( x \\) and \\( y \\) are orthogonal, and \\( P \\) is a projection, then \\( Px \\) and \\( Py \\) are orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Fit a line \\( b = C + Dt \\) through the points \\( (t,b) = (2,0) \\) and \\( (2,6) \\), and show that the normal equations break down. Sketch all the optimal lines minimizing the sum of squared errors."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the point on the plane \\( x+y-z=0 \\) that is closest to \\( b = (2,1,0) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find an orthonormal basis for \\( \\mathbb{R}^3 \\) starting with the vector \\( (1,1,1) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "CT scanners reconstruct density matrices from projections. In the \\( 2 \\times 2 \\) case, can you recover the matrix \\( A \\) if you know the sum along each row and column?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Can you recover a \\( 3 \\times 3 \\) matrix if you know its row sums, column sums, and also the sums along the main diagonal and the four parallel diagonals?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find an orthonormal basis for the plane \\( x - y + z = 0 \\), and determine the projection matrix \\( P \\) that projects onto the plane. What is the nullspace of \\( P \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A = [3 \\quad 1 \\quad 1] \\), and let \\( V \\) be the nullspace of \\( A \\):\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Use Gram-Schmidt to construct an orthonormal pair \\( q_1, q_2 \\) from:\n    \\[\n    a_1 = (4,5,2,2), \\quad a_2 = (1,2,0,0).\n    \\]\n    Express \\( a_1 \\) and \\( a_2 \\) as combinations of \\( q_1 \\) and \\( q_2 \\), and find the triangular \\( R \\) in \\( A = QR \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that:\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Is there a matrix whose row space contains \\( (1,1,0) \\) and whose nullspace contains \\( (0,1,1) \\)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the distance from the plane \\( x_1 + x_2 - x_3 - x_4 = 8 \\) to the origin, and find the closest point on the plane."
    },
    {
        "chapter": "Orthogonality",
        "question": "In a parallelogram with corners at \\( 0, v, w, v + w \\), show that the sum of the squared lengths of the four sides equals the sum of the squared lengths of the two diagonals."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & -6 \\\\\n    3 & 6 \\\\\n    4 & 8 \\\\\n    5 & 0 \\\\\n    7 & 8\n    \\end{bmatrix}\n    \\]\n    \\begin{itemize}"
    },
    {
        "chapter": "Orthogonality",
        "question": "Given the weighting matrix:\n    \\[\n    W =\n    \\begin{bmatrix}\n    2 & 1 \\\\\n    1 & 0\n    \\end{bmatrix}\n    \\]\n    find the \\( W \\)-inner product of \\( (1,0) \\) with \\( (0,1) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "To solve a rectangular system $Ax = b$, we replace $A^{-1}$ (which doesn\u2019t exist) by $(A^TA)^{-1}A^T$ (which exists if $A$ has independent columns). Show that this is a left-inverse of $A$ but not a right-inverse. On the left of $A$ it gives the identity; on the right it gives the projection $P$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the straight line $C + Dt$ that best fits the measurements $b = 0,1,2,5$ at times $t = 0,1,3,4$."
    },
    {
        "chapter": "Orthogonality",
        "question": "Find the curve $y = C + D t^2$ which gives the best least-squares fit to the measurements $y = 6$ at $t = 0$, $y = 4$ at $t = 1$, $y = 0$ at $t = 2$. Write the three equations that are solved if the curve goes through the three points, and find the best $C$ and $D$."
    },
    {
        "chapter": "Orthogonality",
        "question": "If the columns of $A$ are orthogonal to each other, what can you say about the form of $A^TA$? If the columns are orthonormal, what can you say then?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Under what condition on the columns of $A$ (which may be rectangular) is $A^TA$ invertible?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the Fourier matrix \\( F_n \\) of order \\( n \\), whose entries are given by \\( (F_n)_{jk} = \\frac{1}{\\sqrt{n}} e^{-2\\pi i jk/n} \\) for \\( j, k = 0, 1, \\dots, n-1 \\). Prove that \\( F_n \\) is a unitary matrix, i.e., show that \\( F_n^\\dagger F_n = I \\), where \\( I \\) is the identity matrix of order \\( n \\). Discuss the significance of this result in the context of Fourier transforms."
    },
    {
        "chapter": "Orthogonality",
        "question": "Compute the inverse of the Fourier matrix \\( F_4 \\) explicitly and verify that \\( F_4^{-1} = F_4^\\dagger \\). Explain why this property generalizes to Fourier matrices of any order \\( n \\) and describe its implications for signal processing and orthogonality."
    },
    {
        "chapter": "Orthogonality",
        "question": "The Discrete Fourier Transform (DFT) of an \\( n \\)-dimensional vector \\( x \\) is given by \\( X = F_n x \\), where \\( F_n \\) is the Fourier matrix. Show that the inverse transform is given by \\( x = F_n^\\dagger X \\). Using this property, prove that applying the Fourier transform twice results in a time-reversal operation, i.e., \\( F_n^2 x = x^* \\) (where \\( x^* \\) represents a permutation of \\( x \\) corresponding to time-reversal)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( n \\times n \\) circulant matrix, which means its rows are cyclic permutations of the first row. Show that any circulant matrix can be diagonalized using the Fourier matrix \\( F_n \\), i.e., prove that \\( A = F_n D F_n^\\dagger \\), where \\( D \\) is a diagonal matrix whose entries are the eigenvalues of \\( A \\). Compute the eigenvalues of a given circulant matrix \\( A \\) explicitly using the Fast Fourier Transform (FFT)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the Fourier matrix \\( F_n \\) forms an orthonormal basis for \\( \\mathbb{C}^n \\) and explain how this relates to Parseval's theorem. Given a function sampled at \\( n \\) equally spaced points, demonstrate how the Fourier basis can be used to expand the function in terms of complex exponentials."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a function \\( f(x) \\) defined on a discrete set of points \\( x_k = k/n \\) for \\( k = 0, 1, \\dots, n-1 \\). Define the Fourier coefficients as \\( c_k = \\sum_{j=0}^{n-1} f(x_j) e^{-2\\pi i jk/n} \\). Show that the set of exponentials \\( e^{2\\pi i jk/n} \\) forms an orthonormal basis with respect to the inner product \\( \\langle f, g \\rangle = \\sum_{k=0}^{n-1} f(x_k) \\overline{g(x_k)} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The Fast Fourier Transform (FFT) reduces the computational complexity of the Discrete Fourier Transform (DFT) from \\( O(n^2) \\) to \\( O(n \\log n) \\). Derive the recursive formula for the FFT algorithm by splitting an \\( n \\)-point DFT into two \\( n/2 \\)-point DFTs, and show how this leads to an efficient divide-and-conquer approach."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the Fourier matrix \\( F_8 \\). Compute its eigenvalues and eigenvectors explicitly. Show that the eigenvalues are roots of unity and discuss the significance of the eigenvectors in terms of harmonic decomposition."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given the Fourier matrix \\( F_n \\), show that its powers satisfy the property \\( F_n^4 = I \\) when \\( n \\) is a power of 2. Use this result to construct an efficient algorithm for computing the FFT of a sequence by breaking it into subproblems recursively."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that the Fourier matrix \\( F_n \\) diagonalizes any Toeplitz matrix whose entries depend only on the difference \\( i - j \\). Explain why such matrices appear frequently in signal processing and image analysis, and derive the spectral decomposition of a given Toeplitz matrix using the Fourier transform."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the space of continuous functions on the interval \\( [0,1] \\) with the inner product defined by \n    \\[\n    \\langle f, g \\rangle = \\int_0^1 f(x) g(x) \\,dx.\n    \\]\n    Use the Gram-Schmidt process to construct an orthonormal basis for the space spanned by the functions \\( \\{1, x, x^2\\} \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( V \\) be the space of real polynomials of degree at most \\( n \\) with inner product \n    \\[\n    \\langle f, g \\rangle = \\int_{-1}^{1} f(x) g(x) w(x) \\,dx,\n    \\]\n    where \\( w(x) \\) is a weight function. Apply the Gram-Schmidt process to derive the first three orthogonal polynomials when \\( w(x) = 1 \\), leading to the Legendre polynomials."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the space of square-integrable functions \\( L^2([0, \\pi]) \\) with the inner product \n    \\[\n    \\langle f, g \\rangle = \\int_0^{\\pi} f(x) g(x) \\,dx.\n    \\]\n    Apply the Gram-Schmidt process to the functions \\( \\{1, \\sin x, \\sin 2x\\} \\) to construct an orthonormal basis."
    },
    {
        "chapter": "Orthogonality",
        "question": "The set of functions \\( \\{e^{ix}, e^{2ix}, e^{3ix}\\} \\) is not orthogonal under the usual \\( L^2([0,2\\pi]) \\) inner product. Use the Gram-Schmidt process to construct an orthonormal basis from this set and compare it to the standard Fourier basis."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a symmetric matrix \\( A \\) of size \\( n \\times n \\), the eigenvectors of \\( A \\) form a basis for \\( \\mathbb{R}^n \\). Show that if the eigenvectors are not initially orthonormal, applying the Gram-Schmidt process to them yields an orthonormal set that diagonalizes \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( M \\) be an \\( m \\times n \\) matrix with independent column vectors. Explain why applying the Gram-Schmidt process to the column vectors of \\( M \\) results in an orthonormal basis for the column space of \\( M \\), and derive the QR decomposition of \\( M \\) using this method."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the space of continuous periodic functions on \\( [-\\pi, \\pi] \\) with inner product \n    \\[\n    \\langle f, g \\rangle = \\int_{-\\pi}^{\\pi} f(x) g(x) \\,dx.\n    \\]\n    Apply Gram-Schmidt to the trigonometric polynomials \\( \\{1, \\cos x, \\cos 2x\\} \\) to construct an orthonormal set and interpret the result in terms of Fourier series."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( \\{f_1, f_2, \\dots, f_n\\} \\) be a linearly independent set of functions in an inner product space. Show that the Gram-Schmidt process transforms this set into an orthonormal set while preserving the span of the original functions."
    },
    {
        "chapter": "Orthogonality",
        "question": "The matrix representation of a linear transformation \\( T: V \\to V \\) in an orthonormal basis is unitary if \\( V \\) is a complex inner product space. Use the Gram-Schmidt process to construct such an orthonormal basis from an arbitrary basis and explain why this simplifies the analysis of \\( T \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "In the vector space of polynomials with the inner product \n    \\[\n    \\langle p, q \\rangle = \\int_{0}^{1} p(x) q(x) e^{-x} \\,dx,\n    \\]\n    apply the Gram-Schmidt process to the set \\( \\{1, x, x^2\\} \\) to obtain the first three orthonormal polynomials associated with the Laguerre polynomials."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a set of data points \\( (x_i, y_i) \\) for \\( i = 1, 2, \\dots, n \\), the best straight-line approximation in the least squares sense minimizes the sum of squared errors. Derive the normal equations for finding the best-fitting line \\( y = mx + c \\) using the concept of orthogonality in linear algebra. Prove that the residual vector is orthogonal to the column space of the design matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the problem of fitting a straight line to a given dataset using orthogonal projections. Let \\( A \\) be the matrix whose columns are the basis vectors \\( [1, x] \\) for the space of linear functions, and let \\( b \\) be the vector of observed values. Show that the least squares solution corresponds to the orthogonal projection of \\( b \\) onto the column space of \\( A \\). Determine the conditions under which the solution is unique."
    },
    {
        "chapter": "Orthogonality",
        "question": "The best straight-line approximation in the sense of least squares can be obtained using the QR decomposition of the design matrix. Given a set of points \\( (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n) \\), construct the matrix equation for least squares regression and apply the QR factorization to solve for the coefficients of the best-fit line. Show explicitly how the orthogonality of \\( Q \\) simplifies the computation."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a set of \\( n \\) points \\( (x_i, y_i) \\) that are subject to measurement errors. Instead of minimizing the vertical distances (standard least squares), one can minimize the perpendicular distances from the points to the line, leading to the total least squares approach. Formulate the problem using singular value decomposition (SVD) and show how the best straight-line fit corresponds to the right singular vector associated with the smallest singular value of a transformed data matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "The best straight-line approximation problem is a special case of the more general problem of finding the best affine subspace approximation. Given a dataset in \\( \\mathbb{R}^m \\), formulate the problem of finding the best \\( k \\)-dimensional affine subspace using the concept of orthogonality and singular value decomposition. Prove that the principal components of the data provide the optimal directions for such a subspace and explain how this reduces to the best straight-line fit when \\( k = 1 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the space of square-integrable functions on the interval \\( [-\\pi, \\pi] \\), denoted as \\( L^2([-\\pi, \\pi]) \\). The Fourier basis consists of the functions \\( \\{1, \\cos(nx), \\sin(nx) \\}_{n=1}^{\\infty} \\). Prove that this set forms an orthogonal basis under the inner product \n    \\[\n    \\langle f, g \\rangle = \\int_{-\\pi}^{\\pi} f(x) g(x) \\,dx.\n    \\]\n    Then, derive the explicit Fourier series expansion of an arbitrary function \\( f(x) \\in L^2([-\\pi, \\pi]) \\) in terms of these basis functions."
    },
    {
        "chapter": "Orthogonality",
        "question": "The Fourier series representation of a function \\( f(x) \\) is given by\n    \\[\n    f(x) = \\frac{a_0}{2} + \\sum_{n=1}^{\\infty} \\left( a_n \\cos(nx) + b_n \\sin(nx) \\right).\n    \\]\n    Using the orthogonality of the Fourier basis functions, derive explicit expressions for the Fourier coefficients \\( a_n \\) and \\( b_n \\). Show that the inner product structure leads to these coefficients being projections of \\( f(x) \\) onto the basis functions."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a function \\( f(x) \\) defined on \\( [-\\pi, \\pi] \\) with a discontinuity at \\( x = x_0 \\). Use the orthogonality of the Fourier basis to show that the Fourier series of \\( f(x) \\) converges to the average of the left-hand and right-hand limits at \\( x_0 \\) (Gibbs phenomenon). Provide a rigorous proof that the Fourier series satisfies this property."
    },
    {
        "chapter": "Orthogonality",
        "question": "The Fourier matrix \\( F_n \\) of order \\( n \\) is given by\n    \\[\n    F_n = \\frac{1}{\\sqrt{n}} \\left[ e^{2\\pi i jk/n} \\right]_{j,k=0}^{n-1}.\n    \\]\n    Show that \\( F_n \\) is unitary, meaning \\( F_n^* F_n = I_n \\), and explain its connection to the discrete Fourier transform (DFT). Prove that the columns of \\( F_n \\) form an orthonormal set with respect to the standard inner product in \\( \\mathbb{C}^n \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The Fourier series expansion of a function \\( f(x) \\) on \\( [-\\pi, \\pi] \\) is known to converge in the \\( L^2 \\)-norm due to the completeness of the trigonometric basis. Prove that the sequence of partial sums of the Fourier series forms a best approximation to \\( f(x) \\) in the sense of the \\( L^2 \\)-norm, i.e., it minimizes the error \n    \\[\n    \\int_{-\\pi}^{\\pi} \\left| f(x) - S_n(x) \\right|^2 dx,\n    \\]\n    where \\( S_n(x) \\) is the \\( n \\)th partial sum of the Fourier series. Use the concept of orthogonal projections in Hilbert spaces to justify this result."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( H \\) be a Hilbert space with an inner product \\( \\langle \\cdot, \\cdot \\rangle \\). Prove that every Cauchy sequence in \\( H \\) converges to a unique limit in \\( H \\). Use this result to show that any closed subspace of \\( H \\) is also a Hilbert space."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a Hilbert space \\( H \\) and an orthonormal basis \\( \\{e_n\\}_{n=1}^{\\infty} \\), prove that for any vector \\( v \\in H \\), the series\n    \\[\n    v = \\sum_{n=1}^{\\infty} \\langle v, e_n \\rangle e_n\n    \\]\n    converges in the norm induced by the inner product. Show that this expansion minimizes the squared error among all finite approximations of \\( v \\) using a fixed number of basis elements."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that if \\( H \\) is a Hilbert space, then every bounded linear functional \\( f: H \\to \\mathbb{R} \\) (or \\( \\mathbb{C} \\)) can be represented as an inner product with a fixed element of \\( H \\), i.e., there exists a unique \\( g \\in H \\) such that\n    \\[\n    f(v) = \\langle v, g \\rangle \\quad \\forall v \\in H.\n    \\]\n    This is known as the Riesz Representation Theorem. Provide a constructive proof of this result."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the space \\( L^2([a, b]) \\) of square-integrable functions with the inner product\n    \\[\n    \\langle f, g \\rangle = \\int_{a}^{b} f(x) g(x) \\,dx.\n    \\]\n    Show that this space is a Hilbert space. Furthermore, prove that the set of Legendre polynomials forms an orthonormal basis for this space on \\( [-1,1] \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Define the notion of an orthogonal projection onto a closed subspace \\( V \\) of a Hilbert space \\( H \\). Show that for any vector \\( x \\in H \\), there exists a unique vector \\( v \\in V \\) such that \\( x - v \\) is orthogonal to \\( V \\). Prove that this projection is a linear operator and is idempotent."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that in a Hilbert space \\( H \\), the Gram-Schmidt process applied to a linearly independent sequence produces an orthonormal sequence that spans the same subspace. Use this result to construct an explicit orthonormal basis for the space of polynomials up to degree \\( n \\) in \\( L^2([-1,1]) \\) using the Gram-Schmidt process."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( H \\) be a Hilbert space, and let \\( T: H \\to H \\) be a bounded linear operator. Prove that if \\( T \\) is self-adjoint, then all of its eigenvalues are real. Show that if \\( T \\) is compact and self-adjoint, then it has an orthonormal basis of eigenvectors."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose that \\( H \\) is an infinite-dimensional Hilbert space. Show that every sequence \\( \\{x_n\\} \\) in \\( H \\) has a weakly convergent subsequence, i.e., there exists \\( x \\in H \\) such that\n    \\[\n    \\langle x_n, y \\rangle \\to \\langle x, y \\rangle\n    \\]\n    for all \\( y \\in H \\). Provide an example where strong convergence fails but weak convergence holds."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a self-adjoint operator \\( T \\) on a Hilbert space \\( H \\), prove that there exists an orthonormal basis of eigenvectors if and only if \\( T \\) is compact. Use this to explain why infinite-dimensional self-adjoint operators may not have an eigenvalue decomposition."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a bounded sequence \\( \\{x_n\\} \\) in a Hilbert space \\( H \\). Prove that if the sequence satisfies the condition\n    \\[\n    \\|x_{n+1} - x_n\\| \\to 0,\n    \\]\n    then \\( \\{x_n\\} \\) is weakly convergent. Discuss why this property is crucial in the study of iterative algorithms in numerical linear algebra."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank. Show that there exists an orthogonal matrix \\( Q \\) of size \\( m \\times m \\) and an upper triangular matrix \\( R \\) of size \\( m \\times n \\) such that \\( A = QR \\). Prove that if \\( A \\) has full column rank, then \\( R \\) has full row rank and its leading \\( n \\times n \\) submatrix is invertible."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose that \\( A \\) is an \\( m \\times n \\) matrix where \\( m > n \\) and has full column rank. Derive an explicit algorithm for computing the QR decomposition using the Gram-Schmidt process. Explain why this method may suffer from numerical instability, and suggest an alternative method for computing the QR factorization."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the Householder transformation-based approach to QR factorization. Given an arbitrary matrix \\( A \\), show how Householder reflectors can be used to iteratively reduce \\( A \\) to an upper triangular form. Prove that the product of Householder reflectors forms an orthogonal matrix \\( Q \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "The QR decomposition can be used to solve the least squares problem \\( Ax = b \\) for an overdetermined system \\( A \\in \\mathbb{R}^{m \\times n} \\) with \\( m > n \\). Show that using QR factorization, the normal equation solution can be rewritten as \\( Rx = Q^Tb \\). Prove that this formulation avoids issues related to ill-conditioning that arise in normal equations."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that for any invertible square matrix \\( A \\), the QR factorization can be used to compute the eigenvalues of \\( A \\) iteratively using the QR algorithm. Show that if \\( A \\) is symmetric, the iterates \\( A_k = Q_k^T A_{k-1} Q_k \\) converge to a diagonal matrix containing the eigenvalues of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank. Show that the QR decomposition is unique if and only if the diagonal elements of \\( R \\) are all positive. Provide an example where the QR decomposition is not unique and explain why."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the modified Gram-Schmidt algorithm as a variation of the classical Gram-Schmidt process for computing the QR decomposition. Show that the modified Gram-Schmidt process produces the same result as the classical approach but with improved numerical stability."
    },
    {
        "chapter": "Orthogonality",
        "question": "The QR decomposition can be applied to computing the singular value decomposition (SVD) of a matrix. Suppose \\( A \\) is an \\( m \\times n \\) matrix of full rank. Show that by first computing the QR factorization of \\( A \\), followed by applying the SVD to \\( R \\), one can derive the singular values and singular vectors of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be a symmetric positive definite matrix. Show that the QR factorization of \\( A \\) can be used in iterative methods such as the conjugate gradient method to solve the linear system \\( Ax = b \\). Explain how QR factorization improves numerical stability in such iterative methods."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider an ill-conditioned matrix \\( A \\). Prove that the QR factorization provides a numerically stable method for computing the solution to the least squares problem compared to normal equations. Provide an explicit example where the use of QR factorization significantly improves numerical accuracy over the direct normal equation approach."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( V \\) be an inner product space, and let \\( \\{ v_1, v_2, \\dots, v_n \\} \\) be a linearly independent set in \\( V \\). Prove that the Gram-Schmidt process generates an orthonormal basis \\( \\{ q_1, q_2, \\dots, q_n \\} \\) such that each \\( q_i \\) is a linear combination of \\( v_1, \\dots, v_i \\). Show that the transformation from \\( \\{ v_1, \\dots, v_n \\} \\) to \\( \\{ q_1, \\dots, q_n \\} \\) is unique up to sign."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given an \\( m \\times n \\) matrix \\( A \\) with full column rank, show that the QR decomposition \\( A = QR \\) provides an efficient way to determine an orthonormal basis for the column space of \\( A \\). Prove that the first \\( n \\) columns of \\( Q \\) form such a basis and discuss the geometric significance."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the classical Gram-Schmidt process and the modified Gram-Schmidt process for constructing an orthonormal basis. Show that both methods produce the same orthonormal basis in exact arithmetic but differ in numerical stability. Provide an example where the classical Gram-Schmidt process fails due to numerical instability."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that if \\( A \\) is an \\( m \\times n \\) matrix with full column rank, then the QR factorization \\( A = QR \\) is unique if and only if the diagonal elements of \\( R \\) are positive. Provide an explicit example where QR decomposition is not unique."
    },
    {
        "chapter": "Orthogonality",
        "question": "The QR decomposition is widely used in solving least squares problems. Prove that if \\( Ax = b \\) is an overdetermined system where \\( A \\) has full column rank, then the least squares solution can be written as \\( x = R^{-1} Q^T b \\). Explain why this method is preferred over solving the normal equations."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the QR decomposition can be applied iteratively to compute the eigenvalues of a symmetric matrix using the QR algorithm. Prove that if \\( A \\) is symmetric, then the sequence \\( A_k = Q_k^T A_{k-1} Q_k \\) converges to a diagonal matrix whose diagonal entries are the eigenvalues of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank, and let \\( A = QR \\) be its QR decomposition. Show that the columns of \\( Q \\) form an orthonormal basis for the column space of \\( A \\), and explain how this decomposition can be used to find the best approximation of a vector \\( b \\) in the column space of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that for any invertible matrix \\( A \\), the QR factorization can be used to compute the singular value decomposition (SVD). Show that if \\( A = QR \\), then applying SVD to \\( R \\) provides the singular values and singular vectors of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider an \\( n \\times n \\) symmetric matrix \\( A \\) with distinct eigenvalues. Prove that the sequence \\( A_k = Q_k^T A_{k-1} Q_k \\) generated by the QR algorithm converges to a diagonal matrix whose entries are the eigenvalues of \\( A \\). Justify why this holds for symmetric matrices."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank. Show that the Gram-Schmidt process applied to the columns of \\( A \\) results in a QR decomposition \\( A = QR \\). Prove that if \\( A \\) has linearly dependent columns, then the Gram-Schmidt process fails to produce a full set of orthonormal vectors."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a unitary matrix \\( U \\) of size \\( n \\times n \\). Prove that its QR decomposition satisfies \\( U = QR \\) where \\( Q = U \\) and \\( R \\) is an upper triangular matrix with unit diagonal entries. Show that in this case, \\( R \\) is necessarily diagonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given an ill-conditioned matrix \\( A \\), explain why using QR decomposition is numerically stable for solving \\( Ax = b \\) in least squares problems compared to solving the normal equations \\( A^T A x = A^T b \\). Provide an explicit example illustrating this."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that for any rectangular matrix \\( A \\), the QR decomposition can be used to compute the pseudo-inverse \\( A^+ \\). Prove that if \\( A = QR \\), then \\( A^+ = R^{-1} Q^T \\) when \\( A \\) has full column rank."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that if \\( A \\) is an \\( n \\times n \\) symmetric matrix with distinct eigenvalues, then the QR algorithm converges to an orthonormal basis of eigenvectors of \\( A \\). Explain why the shift technique is introduced to accelerate convergence."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix of full rank and let \\( A = QR \\) be its QR factorization. Show that the projection of any vector \\( b \\) onto the column space of \\( A \\) can be written as \\( \\text{Proj}_{\\text{Col}(A)} b = QQ^T b \\). Interpret this result geometrically."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank, and let \\( W \\) be a positive definite diagonal matrix of size \\( m \\times m \\). Derive the normal equations for the weighted least squares problem \n    \\[\n    \\min_x \\| W^{1/2} (Ax - b) \\|_2^2.\n    \\]\n    Show that the solution is given by \\( x = (A^T W A)^{-1} A^T W b \\) and discuss under what conditions this solution is unique."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a dataset consisting of \\( m \\) observations with varying levels of reliability. Explain how a weighted least squares approach can be used to account for different levels of confidence in the observations. Show that choosing the weight matrix \\( W \\) as the inverse of the variance-covariance matrix of the errors minimizes the variance of the estimator \\( x \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a system of linear equations \\( Ax = b \\) where \\( A \\) is an \\( m \\times n \\) matrix and the measurement errors have known variances \\( \\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_m^2 \\), explain how the choice \\( W = \\text{diag}(\\sigma_1^{-2}, \\sigma_2^{-2}, \\dots, \\sigma_m^{-2}) \\) leads to an optimal solution in the sense of minimizing the variance of \\( x \\). Prove that the weighted least squares estimator is unbiased."
    },
    {
        "chapter": "Orthogonality",
        "question": "Suppose \\( A \\) is an \\( m \\times n \\) matrix with full column rank and \\( W \\) is a symmetric positive definite weight matrix. Show that the residual \\( r = b - Ax \\) in the weighted least squares solution is orthogonal to the weighted column space of \\( A \\), i.e.,\n    \\[\n    A^T W r = 0.\n    \\]\n    Interpret this result geometrically."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the problem of fitting a polynomial \\( p(x) = a_0 + a_1 x + \\dots + a_n x^n \\) to a given set of data points \\( (x_i, y_i) \\) for \\( i = 1, \\dots, m \\). Derive the weighted least squares normal equations for determining the coefficients \\( a_0, a_1, \\dots, a_n \\) when each observation \\( y_i \\) has an associated weight \\( w_i \\). Discuss conditions under which the solution is unique."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that if \\( A \\) is an \\( m \\times n \\) matrix with full column rank, then the matrix \\( (A^T W A) \\) in the weighted least squares solution is symmetric and positive definite, ensuring that the normal equations have a unique solution. Give an example where dropping the full column rank assumption leads to non-uniqueness."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider an iterative refinement approach to solving the weighted least squares problem, where the weights are updated dynamically based on residual errors. Formulate an iterative algorithm that adjusts the weights as \\( W_{k+1} = \\text{diag}(|r_k|^{-1}) \\), where \\( r_k \\) is the residual at step \\( k \\). Analyze the convergence of this approach and its relationship to robust regression methods."
    },
    {
        "chapter": "Orthogonality",
        "question": "The QR decomposition is often used for solving least squares problems. Given the weighted least squares system \\( \\min_x \\| W^{1/2} (Ax - b) \\|_2^2 \\), show that applying a QR decomposition to \\( W^{1/2} A \\) provides a stable way to compute \\( x \\). Compare this method with the normal equations approach in terms of numerical stability."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank, and let \\( W \\) be a symmetric positive definite weight matrix. Consider a perturbation in the data \\( b \\), given by \\( b' = b + \\delta b \\). Show that the sensitivity of the weighted least squares solution \\( x \\) to changes in \\( b \\) depends on the condition number of \\( A^T W A \\). Provide an interpretation of this result in practical applications."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that if the weight matrix \\( W \\) in a weighted least squares problem is chosen optimally based on the error distribution, the resulting estimator is the Best Linear Unbiased Estimator (BLUE) according to the Gauss-Markov theorem. Prove this result formally and discuss its implications in statistics and machine learning."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank, and let \\( b \\in \\mathbb{R}^m \\). Derive the least squares solution \\( x \\) that minimizes \\( \\| Ax - b \\|_2^2 \\) and show that the error vector is orthogonal to the column space of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Prove that the least squares solution \\( x = (A^T A)^{-1} A^T b \\) exists and is unique when \\( A \\) has full column rank. What happens when \\( A \\) does not have full column rank?"
    },
    {
        "chapter": "Orthogonality",
        "question": "Define the projection matrix \\( P \\) that projects any vector \\( b \\in \\mathbb{R}^m \\) onto the column space of \\( A \\). Show that \\( P \\) is symmetric and idempotent, i.e., \\( P^2 = P \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that for any \\( m \\times n \\) matrix \\( A \\) with full column rank, the projection matrix onto \\( \\text{Col}(A) \\) is given by \\( P = A (A^T A)^{-1} A^T \\). Interpret this result geometrically."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the problem of fitting a linear model \\( y = a_0 + a_1 x \\) to given data points \\( (x_i, y_i) \\) for \\( i = 1, \\dots, m \\). Derive the normal equations for the least squares estimates of \\( a_0 \\) and \\( a_1 \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a data set of points \\( (x_i, y_i) \\) in \\( \\mathbb{R}^2 \\), derive the best quadratic polynomial fit \\( y = a_0 + a_1 x + a_2 x^2 \\) using least squares. Discuss conditions for uniqueness of the solution."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank. Prove that the residual vector \\( r = b - Ax \\) is orthogonal to every column of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that if \\( A \\) is an orthogonal matrix, then the least squares solution simplifies to \\( x = A^T b \\). Interpret this result."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a subspace \\( S \\) of \\( \\mathbb{R}^m \\) spanned by the columns of an \\( m \\times n \\) matrix \\( A \\). Define the orthogonal complement of \\( S \\) and explain why any vector in \\( \\mathbb{R}^m \\) can be uniquely decomposed into a sum of a vector in \\( S \\) and a vector in \\( S^\\perp \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a set of data points \\( (x_i, y_i) \\) in \\( \\mathbb{R}^2 \\), explain how the normal equations for least squares fitting can be obtained from an orthogonal projection argument."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the projection matrix \\( P = A (A^T A)^{-1} A^T \\) satisfies \\( P^T = P \\) and \\( P^2 = P \\). Interpret these properties in terms of orthogonality and projection onto a subspace."
    },
    {
        "chapter": "Orthogonality",
        "question": "Compute the least squares solution for the overdetermined system\n    \\[\n    \\begin{bmatrix} \n    1 & 1 \\\\ \n    1 & 2 \\\\ \n    1 & 3 \n    \\end{bmatrix} \n    \\begin{bmatrix} \n    x_1 \\\\ \n    x_2 \n    \\end{bmatrix} \n    = \n    \\begin{bmatrix} \n    1 \\\\ \n    2 \\\\ \n    2 \n    \\end{bmatrix}.\n    \\]\n    Find the corresponding projection matrix and verify that the residual is orthogonal to the column space of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that for a square invertible matrix \\( A \\), the projection matrix onto the column space of \\( A \\) is the identity matrix \\( I \\). Interpret this result in terms of least squares solutions."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider a matrix \\( A \\) whose columns form an orthonormal basis for \\( \\mathbb{R}^m \\). Show that the least squares solution simplifies to \\( x = A^T b \\) and compare it to the general case where \\( A \\) is not orthonormal."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( A \\) be an \\( m \\times n \\) matrix with full column rank, and let \\( P \\) be the projection matrix onto \\( \\text{Col}(A) \\). Prove that for any vector \\( b \\in \\mathbb{R}^m \\), the projection \\( Pb \\) minimizes the distance from \\( b \\) to \\( \\text{Col}(A) \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the determinant of the projection matrix \\( P = A (A^T A)^{-1} A^T \\) is zero when \\( A \\) is not square. Explain why this must be the case."
    },
    {
        "chapter": "Orthogonality",
        "question": "Discuss how Gram-Schmidt orthogonalization can be used to derive an alternative formula for the least squares solution when \\( A \\) has full column rank. Compare this with the normal equations approach."
    },
    {
        "chapter": "Orthogonality",
        "question": "Show that the eigenvalues of the projection matrix \\( P = A (A^T A)^{-1} A^T \\) are either 0 or 1. Explain why this is expected based on the geometric interpretation of projections."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( U \\) and \\( W \\) be subspaces of an inner product space \\( V \\) such that \\( U \\cap W = \\{0\\} \\). Show that \\( U \\) and \\( W \\) are orthogonal if and only if for all \\( u \\in U \\) and \\( w \\in W \\), the inner product satisfies \\( \\langle u, w \\rangle = 0 \\). Further, prove that if \\( V = U \\oplus W \\), then every vector in \\( V \\) can be uniquely decomposed as the sum of vectors from \\( U \\) and \\( W \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider an \\( m \\times n \\) matrix \\( A \\) with full column rank. Define the projection matrix \\( P = A(A^T A)^{-1} A^T \\) that projects vectors onto the column space of \\( A \\). Show that for any \\( b \\in \\mathbb{R}^m \\), the vector \\( Pb \\) is the closest vector to \\( b \\) in the column space of \\( A \\). Additionally, prove that the residual \\( (I - P)b \\) is orthogonal to the column space of \\( A \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Given a nonzero vector \\( a \\in \\mathbb{R}^n \\), prove that the projection of a vector \\( b \\) onto the line spanned by \\( a \\) is given by\n    \\[\n    \\text{proj}_a (b) = \\frac{\\langle b, a \\rangle}{\\langle a, a \\rangle} a.\n    \\]\n    Show that the residual vector \\( r = b - \\text{proj}_a (b) \\) is orthogonal to \\( a \\), and use this to prove the Cauchy-Schwarz inequality."
    },
    {
        "chapter": "Orthogonality",
        "question": "Let \\( P \\) be a symmetric matrix such that \\( P^2 = P \\). Prove that the eigenvalues of \\( P \\) are either 0 or 1, and interpret this result in terms of projections onto subspaces. Further, show that the rank of \\( P \\) equals the dimension of the subspace onto which \\( P \\) projects."
    },
    {
        "chapter": "Orthogonality",
        "question": "Define the cosine of the angle \\( \\theta \\) between two nonzero vectors \\( a, b \\in \\mathbb{R}^n \\) using the inner product:\n    \\[\n    \\cos \\theta = \\frac{\\langle a, b \\rangle}{\\|a\\| \\|b\\|}.\n    \\]\n    Prove that \\( -1 \\leq \\cos \\theta \\leq 1 \\) and characterize the cases when \\( \\cos \\theta = 1, 0, -1 \\). Additionally, derive an expression for the projection of \\( b \\) onto \\( a \\) in terms of \\( \\cos \\theta \\)."
    },
    {
        "chapter": "Orthogonality",
        "question": "Consider the problem of projecting a point \\( p \\) onto a plane in \\( \\mathbb{R}^3 \\) defined by a normal vector \\( n \\). Derive a formula for the projection of \\( p \\) onto the plane and show that the distance from \\( p \\) to the plane is given by \\( \\frac{|\\langle p, n \\rangle|}{\\|n\\|} \\). Apply this result to find the projection of the point \\( (3, 4, 5) \\) onto the plane \\( x + 2y + 3z = 6 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "The quadratic \\( f = x^2 + 4xy + 2y^2 \\) has a saddle point at the origin, despite the fact that its coefficients are positive. Write \\( f \\) as a difference of two squares."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Decide for or against the positive definiteness of these matrices, and write out the corresponding \\( f = x^T A x \\):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( \\begin{bmatrix} 1 & 3 \\\\ 3 & 5 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( \\begin{bmatrix} 2 & 3 \\\\ 3 & 5 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( \\begin{bmatrix} -1 & 2 \\\\ 2 & -8 \\end{bmatrix} \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "If a 2 by 2 symmetric matrix passes the tests \\( a > 0 \\), \\( ac > b^2 \\), solve the quadratic equation \\( \\det(A - \\lambda I) = 0 \\) and show that both eigenvalues are positive."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Decide between a minimum, maximum, or saddle point for the following functions:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( F = -1 + 4(e^x - x) - 5x \\sin y + 6y^2 \\) at the point \\( x = y = 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( F = (x^2 - 2x) \\cos y \\), with a stationary point at \\( x = 1, y = \\pi \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For which numbers \\( b \\) is the matrix \\( A = \\begin{bmatrix} 1 & b \\\\ b & 9 \\end{bmatrix} \\) positive definite?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Factor \\( A = LDL^T \\) when \\( b \\) is in the range for positive definiteness."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the minimum value of \\( \\frac{1}{2}(x^2 + 2bxy + 9y^2) - y \\) for \\( b \\) in this range."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What is the minimum if \\( b = 3 \\)?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Suppose the positive coefficients \\( a \\) and \\( c \\) dominate \\( b \\) in the sense that \\( a + c > 2b \\). Find an example that has \\( ac < b^2 \\), so the matrix is not positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What 3 by 3 symmetric matrices \\( A_1 \\) and \\( A_2 \\) correspond to \\( f_1 \\) and \\( f_2 \\)?\n        \\[\n        f_1 = x_1^2 + x_2^2 + x_3^2 - 2x_1x_2 - 2x_1x_3 + 2x_2x_3\n        \\]\n        \\[\n        f_2 = x_1^2 + 2x_2^2 + 11x_3^2 - 2x_1x_2 - 2x_1x_3 - 4x_2x_3\n        \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that \\( f_1 \\) is a single perfect square and not positive definite. Where is \\( f_1 \\) equal to 0?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Factor \\( A_2 \\) into \\( LL^T \\). Write \\( f_2 = x^T A_2 x \\) as a sum of three squares."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "If \\( A = \\begin{bmatrix} a & b \\\\ b & c \\end{bmatrix} \\) is positive definite, test \\( A^{-1} = \\begin{bmatrix} p & q \\\\ q & r \\end{bmatrix} \\) for positive definiteness."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "The quadratic \\( f(x_1, x_2) = 3(x_1 + 2x_2)^2 + 4x_2^2 \\) is positive. Find its matrix \\( A \\), factor it into \\( LDL^T \\), and connect the entries in \\( D \\) and \\( L \\) to 3, 2, 4 in \\( f \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "If \\( R = \\begin{bmatrix} p & q \\\\ q & r \\end{bmatrix} \\), write out \\( R^2 \\) and check that it is positive definite unless \\( R \\) is singular."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "If \\( A = \\begin{bmatrix} a & b \\\\ b & c \\end{bmatrix} \\) is Hermitian (complex \\( b \\)), find its pivots and determinant."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Complete the square for \\( x^H A x \\). Now \\( x^H = [x_1 \\, x_2] \\) can be complex\n        \\[\n        a |x_1|^2 + 2\\text{Re}(b)x_1 x_2 + c |x_2|^2 = a \\left| x_1 + \\frac{b}{a} x_2 \\right|^2 + |x_2|^2.\n        \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that \\( a > 0 \\) and \\( ac > |b|^2 \\) ensure that \\( A \\) is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Are the matrices \\( \\begin{bmatrix} 1 & 1+i \\\\ 1-i & 2 \\end{bmatrix} \\) and \\( \\begin{bmatrix} 3 & 4+i \\\\ 4-i & 6 \\end{bmatrix} \\) positive definite?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Decide whether \\( F = x^2 y^2 - 2x - 2y \\) has a minimum at the point \\( x = y = 1 \\) (after showing that the first derivatives are zero at that point)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Under what conditions on \\( a, b, c \\) is \\( ax^2 + 2bxy + cy^2 > x^2 + y^2 \\) for all \\( x, y \\)?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Which of \\( A_1, A_2, A_3, A_4 \\) has two positive eigenvalues? Test \\( a > 0 \\) and \\( ac > b^2 \\), don\u2019t compute the eigenvalues. Find an \\( x \\) so that \\( x^T A_1 x < 0 \\).\n    \\[\n    A_1 = \\begin{bmatrix} 5 & 6 \\\\ 6 & 7 \\end{bmatrix}, \n    A_2 = \\begin{bmatrix} -1 & -2 \\\\ -2 & -5 \\end{bmatrix}, \n    A_3 = \\begin{bmatrix} 1 & 10 \\\\ 10 & 100 \\end{bmatrix}, \n    A_4 = \\begin{bmatrix} 1 & 10 \\\\ 10 & 101 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What is the quadratic \\( f = ax^2 + 2bxy + cy^2 \\) for each of these matrices? Complete the square to write \\( f \\) as a sum of one or two squares \\( d_1(\\cdot)^2 + d_2(\\cdot)^2 \\).\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 9 \\end{bmatrix}, \n    A = \\begin{bmatrix} 1 & 3 \\\\ 3 & 9 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that \\( f(x,y) = x^2 + 4xy + 3y^2 \\) does not have a minimum at \\( (0,0) \\) even though it has positive coefficients. Write \\( f \\) as a difference of squares and find a point \\( (x,y) \\) where \\( f \\) is negative."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(Important) If \\( A \\) has independent columns, then \\( A^T A \\) is square and symmetric and invertible (Section 4.2). Rewrite \\( x^T A^T A x \\) to show why it is positive except when \\( x = 0 \\). Then \\( A^T A \\) is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Test to see if \\( A^T A \\) is positive definite in each case:\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 0 & 3 \\end{bmatrix}, \n    A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\\\ 2 & 1 \\end{bmatrix}, \n    A = \\begin{bmatrix} 1 & 1 & 2 \\\\ 1 & 2 & 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the 3 by 3 matrix \\( A \\) and its pivots, rank, eigenvalues, and determinant:}\n    \\[\n    \\begin{bmatrix}\n    x_1 & x_2 & x_3\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    A\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    x_3\n    \\end{bmatrix}\n    = 4(x_1 - x_2 + 2x_3)\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For \\( F_1(x,y) = \\frac{1}{4}x^4 + x^2y + y^2 \\) and \\( F_2(x,y) = x^3 + xy - x \\), find the second derivative matrices \\( A_1 \\) and \\( A_2 \\):}\n    \\[\n    A = \\begin{bmatrix}\n    \\frac{\\partial^2 F}{\\partial x^2} & \\frac{\\partial^2 F}{\\partial x \\partial y} \\\\\n    \\frac{\\partial^2 F}{\\partial y \\partial x} & \\frac{\\partial^2 F}{\\partial y^2}\n    \\end{bmatrix}\n    \\]\n    \\( A_1 \\) is positive definite, so \\( F_1 \\) is concave up (convex). Find the minimum point of \\( F_1 \\) and the saddle point of \\( F_2 \\) (look where first derivatives are zero)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{The graph of \\( z = x^2 + y^2 \\) is a bowl opening upward. The graph of \\( z = x^2 - y^2 \\) is a saddle. The graph of \\( z = -x^2 - y^2 \\) is a bowl opening downward. What is a test on \\( F(x,y) \\) to have a saddle at (0,0)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Which values of \\( c \\) give a bowl and which give a saddle point for the graph of \\( z = 4x^2 + 12xy + cy^2 \\)? Describe this graph at the borderline value of \\( c \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For what range of numbers \\( a \\) and \\( b \\) are the matrices \\( A \\) and \\( B \\) positive definite?}\n    \\[\n    A = \\begin{bmatrix}\n    a & 2 & 2 \\\\\n    2 & a & 2 \\\\\n    2 & 2 & a\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n    1 & 2 & 4 \\\\\n    2 & b & 8 \\\\\n    4 & 8 & 7\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Decide for or against the positive definiteness of}\n    \\[\n    A = \\begin{bmatrix}\n    2 & -1 & -1 \\\\\n    -1 & 2 & -1 \\\\\n    -1 & -1 & 2\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n    2 & -1 & -1 \\\\\n    -1 & 2 & 1 \\\\\n    -1 & 1 & 2\n    \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix}\n    0 & 1 & 2 \\\\\n    1 & 0 & 1 \\\\\n    2 & 1 & 0\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Construct an indefinite matrix with its largest entries on the main diagonal:}\n    \\[\n    A = \\begin{bmatrix}\n    1 & b & -b \\\\\n    b & 1 & b \\\\\n    -b & b & 1\n    \\end{bmatrix}\n    \\]\n    with \\( |b| < 1 \\) can have \\( \\det(A) < 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Show from the eigenvalues that if \\( A \\) is positive definite, so is \\( A^2 \\) and so is \\( A^{-1} \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( A \\) and \\( B \\) are positive definite, then \\( A + B \\) is positive definite. Pivots and eigenvalues are not convenient for \\( A + B \\). Much better to prove \\( x^T (A + B) x > 0 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{From the pivots, eigenvalues, and eigenvectors of}\n    \\[\n    A = \\begin{bmatrix}\n    5 & 4 \\\\\n    4 & 5\n    \\end{bmatrix}\n    \\]\n    write \\( A \\) as \\( R^T R \\) in three ways: \\( (L \\sqrt{D})(\\sqrt{D} L^T) \\), \\( (Q \\sqrt{\\Lambda})(\\sqrt{\\Lambda} Q^T) \\), and \\( (Q \\sqrt{\\Lambda} Q^T)(Q \\sqrt{\\Lambda} Q^T) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( A = Q \\Lambda Q^T \\) is symmetric positive definite, then \\( R = Q \\sqrt{\\Lambda} Q^T \\) is its symmetric positive definite square root. Why does \\( R \\) have positive eigenvalues? Compute \\( R \\) and verify \\( R^2 = A \\) for}\n    \\[\n    A = \\begin{bmatrix}\n    10 & 6 \\\\\n    6 & 10\n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix}\n    10 & -6 \\\\\n    -6 & 10\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( A \\) is symmetric positive definite and \\( C \\) is nonsingular, prove that \\( B = C^T A C \\) is also symmetric positive definite.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( A = R^T R \\) prove the generalized Schwarz inequality \\( |x^T A y|^2 \\leq (x^T A x)(y^T A y) \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{The ellipse \\( u^2 + 4v^2 = 1 \\) corresponds to}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 4\n    \\end{bmatrix}\n    \\]\n    Write the eigenvalues and eigenvectors, and sketch the ellipse."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Reduce the equation \\( 3u^2 - 2\\sqrt{2} uv + 2v^2 = 1 \\) to a sum of squares by finding the eigenvalues of the corresponding \\( A \\), and sketch the ellipse.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{In three dimensions, \\( \\lambda_1 y_1^2 + \\lambda_2 y_2^2 + \\lambda_3 y_3^2 = 1 \\) represents an ellipsoid when all \\( \\lambda_i > 0 \\). Describe all the different kinds of surfaces that appear in the positive semidefinite case when one or more of the eigenvalues is zero.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Write down the five conditions for a 3 by 3 matrix to be negative definite (\\( -A \\) is positive definite) with special attention to condition III: How is \\( \\det(-A) \\) related to \\( \\det(A) \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Decide whether the following matrices are positive definite, negative definite, semidefinite, or indefinite:}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    2 & 5 & 4 \\\\\n    3 & 4 & 9\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n    1 & 2 & 0 & 0 \\\\\n    2 & 6 & -2 & 0 \\\\\n    0 & -2 & 5 & -2 \\\\\n    0 & 0 & -2 & 3\n    \\end{bmatrix}, \\quad\n    C = -B, \\quad\n    D = A^{-1}\n    \\]\n    Is there a real solution to \\( -x^2 - 5y^2 - 9z^2 - 4xy - 6xz - 8yz = 1 \\)?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( A \\) is symmetric positive definite and \\( Q \\) is an orthogonal matrix. True or false:}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( Q^T A Q \\) is a diagonal matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( Q^T A Q \\) is symmetric positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( Q^T A Q \\) has the same eigenvalues as \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( e^{-A} \\) is symmetric positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( A \\) is positive definite and \\( a_{11} \\) is increased, prove from cofactors that the determinant is increased. Show by example that this can fail if \\( A \\) is indefinite.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{From \\( A = R^T R \\), show for positive definite matrices that \\( \\det(A) \\leq a_{11} a_{22} \\cdots a_{nn} \\). (The length squared of column \\( j \\) of \\( R \\) is \\( a_{jj} \\). Use determinant = volume.)}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{(Lyapunov test for stability of \\( M \\)) Suppose \\( A M + M^T A = -I \\) with positive definite \\( A \\). If \\( M x = \\lambda x \\), show that \\( \\text{Re}(\\lambda) < 0 \\). (Hint: Multiply the first equation by \\( x^T \\) and \\( x \\).)}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Which 3 by 3 symmetric matrices \\( A \\) produce these functions \\( f = x^T A x \\)? Why is the first matrix positive definite but not the second one?}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( f = 2(x_1^2 + x_2^2 + x_3^2 - x_1 x_2 - x_2 x_3) \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\( f = 2(x_1^2 + x_2^2 + x_3^2 - x_1 x_2 - x_1 x_3 - x_2 x_3) \\)"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Compute the three upper left determinants to establish positive definiteness. Verify that their ratios give the second and third pivots.}\n    \\[\n    A = \\begin{bmatrix}\n    2 & 2 & 0 \\\\\n    2 & 5 & 3 \\\\\n    0 & 3 & 8\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{A positive definite matrix cannot have a zero (or even worse, a negative number) on its diagonal. Show that this matrix fails to have \\( x^T A x > 0 \\):}\n    \\[\n    A = \\begin{bmatrix}\n    4 & 1 & 1 \\\\\n    1 & 0 & 2 \\\\\n    1 & 2 & 5\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{A diagonal entry \\( a_{jj} \\) of a symmetric matrix cannot be smaller than all \\( \\lambda \\)'s. If it were, then \\( A - a_{jj} I \\) would have eigenvalues and would be positive definite. But \\( A - a_{jj} I \\) has a on the main diagonal.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Give a quick reason why each of these statements is true:}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Every positive definite matrix is invertible."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "The only positive definite projection matrix is \\( P = I \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "A diagonal matrix with positive diagonal entries is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "A symmetric matrix with a positive determinant might not be positive definite!"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For which \\( s \\) and \\( t \\) do \\( A \\) and \\( B \\) have all \\( \\lambda > 0 \\) (and are therefore positive definite)?}\n    \\[\n    A = \\begin{bmatrix}\n    s & -4 & -4 \\\\\n    -4 & s & -4 \\\\\n    -4 & -4 & s\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n    t & 3 & 0 \\\\\n    3 & t & 4 \\\\\n    0 & 4 & t\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{You may have seen the equation for an ellipse as \\( \\left( \\frac{x}{a} \\right)^2 + \\left( \\frac{y}{b} \\right)^2 = 1 \\). What are \\( a \\) and \\( b \\) when the equation is written as \\( \\lambda_1 x^2 + \\lambda_2 y^2 = 1 \\)? The ellipse \\( 9x^2 + 16y^2 = 1 \\) has half-axes with lengths \\( a = \\) and \\( b = \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Draw the tilted ellipse \\( x^2 + xy + y^2 = 1 \\) and find the half-lengths of its axes from the eigenvalues of the corresponding \\( A \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{With positive pivots in \\( D \\), the factorization \\( A = LDL^T \\) becomes \\( L \\sqrt{D} \\sqrt{D} L^T \\). (Square roots of the pivots give \\( D = \\sqrt{D} \\sqrt{D} \\).) Then \\( C = L \\sqrt{D} \\) yields the Cholesky factorization \\( A = C C^T \\), which is \"symmetrized LU\":}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "From \\( C = \\begin{bmatrix} 3 & 0 \\\\ 1 & 2 \\end{bmatrix} \\), find \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "From \\( A = \\begin{bmatrix} 4 & 8 \\\\ 8 & 25 \\end{bmatrix} \\), find \\( C \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{In the Cholesky factorization \\( A = C C^T \\), with \\( C = L \\sqrt{D} \\), the square roots of the pivots are on the diagonal of \\( C \\). Find \\( C \\) (lower triangular) for}\n    \\[\n    A = \\begin{bmatrix}\n    9 & 0 & 0 \\\\\n    0 & 1 & 2 \\\\\n    0 & 2 & 8\n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 2 & 2 \\\\\n    1 & 2 & 7\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{The symmetric factorization \\( A = LDL^T \\) means that \\( x^T A x = x^T L D L^T x \\):}\n    \\[\n    \\begin{bmatrix} \n    x & y \n    \\end{bmatrix} \\begin{bmatrix} \n    a & b \\\\\n    b & c \n    \\end{bmatrix} \\begin{bmatrix} \n    x \\\\\n    y\n    \\end{bmatrix} \n    = \\begin{bmatrix} \n    x & y\n    \\end{bmatrix} \\begin{bmatrix} \n    1 & 0 \\\\\n    \\frac{b}{a} & 1\n    \\end{bmatrix} \\begin{bmatrix} \n    a & 0 \\\\\n    0 & \\frac{ac-b^2}{a}\n    \\end{bmatrix} \\begin{bmatrix} \n    1 & \\frac{b}{a} \\\\\n    0 & 1\n    \\end{bmatrix} \\begin{bmatrix} \n    x \\\\\n    y\n    \\end{bmatrix}\n    \\]\n    The left-hand side is \\( ax^2 + 2bxy + cy^2 \\). The right-hand side is \\( a(x + \\frac{b}{a} y)^2 + y^2 \\). The second pivot completes the square! Test with \\( a = 2 \\), \\( b = 4 \\), \\( c = 10 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Without multiplying} \n    \\[\n    A = \\begin{bmatrix}\n    \\cos\\theta & -\\sin\\theta \\\\\n    \\sin\\theta & \\cos\\theta\n    \\end{bmatrix} \\begin{bmatrix}\n    2 & 0 \\\\\n    0 & 5\n    \\end{bmatrix} \\begin{bmatrix}\n    \\cos\\theta & \\sin\\theta \\\\\n    -\\sin\\theta & \\cos\\theta\n    \\end{bmatrix}\n    \\]\n    Find:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(a) The determinant of \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(b) The eigenvalues of \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(c) The eigenvectors of \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(d) A reason why \\( A \\) is symmetric positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For the semidefinite matrices}\n    \\[\n    A = \\begin{bmatrix}\n    2 & -1 & -1 \\\\\n    -1 & 2 & -1 \\\\\n    -1 & -1 & 2\n    \\end{bmatrix} \\quad \\text{(rank 2)} \\quad \\text{and} \\quad B = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 1\n    \\end{bmatrix} \\quad \\text{(rank 1)},\n    \\]\n    write \\( x^T A x \\) as a sum of two squares and \\( x^T B x \\) as one square."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Apply any three tests to each of the matrices}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 1 \\\\\n    1 & 1 & 0\n    \\end{bmatrix} \\quad \\text{and} \\quad B = \\begin{bmatrix}\n    2 & 1 & 2 \\\\\n    1 & 1 & 1 \\\\\n    2 & 1 & 2\n    \\end{bmatrix},\n    \\]\n    to decide whether they are positive definite, positive semidefinite, or indefinite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For} \n    \\[\n    C = \\begin{bmatrix}\n    2 & 0 \\\\\n    0 & -1\n    \\end{bmatrix} \\quad \\text{and} \\quad A = \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 1\n    \\end{bmatrix},\n    \\]\n    confirm that \\( C^T A C \\) has eigenvalues of the same signs as \\( A \\). Construct a chain of nonsingular matrices \\( C(t) \\) linking \\( C \\) to an orthogonal matrix \\( Q \\). Why is it impossible to construct a nonsingular chain linking \\( C \\) to the identity matrix?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If the pivots of a matrix are all greater than 1, are the eigenvalues all greater than 1? Test on the tridiagonal \\( -1, 2, -1 \\) matrices.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Use the pivots of \\( A - \\frac{1}{2}I \\) to decide whether \\( A \\) has an eigenvalue smaller than \\( \\frac{1}{2} \\):}\n    \\[\n    A - \\frac{1}{2} I = \\begin{bmatrix}\n    2.5 & 3 & 0 \\\\\n    3 & 9.5 & 7 \\\\\n    0 & 7 & 7.5\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{An algebraic proof of the law of inertia starts with the orthonormal eigenvectors \\( x_1, \\dots, x_p \\) of \\( A \\) corresponding to eigenvalues \\( \\lambda_i > 0 \\), and the orthonormal eigenvectors \\( y_1, \\dots, y_q \\) of \\( C^T A C \\) corresponding to eigenvalues \\( \\mu_i < 0 \\).}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(a) To prove that the \\( p + q \\) vectors \\( x_1, \\dots, x_p, Cy_1, \\dots, Cy_q \\) are independent, assume that some combination gives zero:\n        \\[\n        a_1 x_1 + \\dots + a_p x_p = b_1 C y_1 + \\dots + b_q C y_q = z \\quad (\\text{say}).\n        \\]\n        Show that\n        \\[\n        z^T A z = \\lambda_1 a_1^2 + \\dots + \\lambda_p a_p^2 \\geq 0 \\quad \\text{and} \\quad z^T A z = \\mu_1 b_1^2 + \\dots + \\mu_q b_q^2 \\leq 0.\n        \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(b) Deduce that the \\( a_i \\)'s and \\( b_i \\)'s are zero (proving linear independence). From that, deduce \\( p + q \\leq n \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "(c) The same argument for the \\( n - p \\) negative \\( \\lambda \\)'s and the \\( n - q \\) positive \\( \\mu \\)'s gives\n        \\[\n        n - p + n - q \\leq n.\n        \\]\n        (We again assume no zero eigenvalues, which are handled separately). Show that \\( p + q = n \\), so the number \\( p \\) of positive \\( \\lambda \\)'s equals the number \\( n - q \\) of positive \\( \\mu \\)'s \u2014 which is the law of inertia."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( C \\) is nonsingular, show that \\( A \\) and \\( C^T A C \\) have the same rank. Thus they have the same number of zero eigenvalues.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find by experiment the number of positive, negative, and zero eigenvalues of}\n    \\[\n    A = \\begin{bmatrix} \n    I & B \\\\\n    B^T & 0\n    \\end{bmatrix}\n    \\]\n    when the block \\( B \\) (of order \\( \\frac{1}{2} n \\)) is nonsingular."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Do \\( A \\) and \\( C^T A C \\) always satisfy the law of inertia when \\( C \\) is not square?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{In equation (9) with \\( m_1 = 1 \\) and \\( m_2 = 2 \\), verify that the normal modes are orthogonal:}\n    \\[\n    x_1^T M x_2 = 0.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the eigenvalues and eigenvectors of} \n    \\[\n    A x = \\lambda M x:\n    \\quad A = \\begin{bmatrix} \n    6 & -3 \\\\\n    -3 & 6\n    \\end{bmatrix}, \\quad M = \\begin{bmatrix}\n    4 & 1 \\\\\n    1 & 4\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If the symmetric matrices \\( A \\) and \\( M \\) are indefinite, \\( A x = \\lambda M x \\) might not have real eigenvalues. Construct a 2 by 2 example.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{A group of nonsingular matrices includes \\( AB \\) and \\( A^{-1} \\) if it includes \\( A \\) and \\( B \\). \u201cProducts and inverses stay in the group.\u201d Which of these sets are groups?}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Positive definite symmetric matrices \\( A \\),"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Orthogonal matrices \\( Q \\),"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "All exponentials \\( e^{tA} \\) of a fixed matrix \\( A \\),"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Matrices \\( P \\) with positive eigenvalues,"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Matrices \\( D \\) with determinant 1."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Compute \\( A^T A \\) and its eigenvalues \\( \\sigma_1^2, 0 \\) and unit eigenvectors \\( v_1, v_2 \\):}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 4 \\\\\n    2 & 8\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{(a) Compute \\( A A^T \\) and its eigenvalues \\( \\sigma_1^2, 0 \\) and unit eigenvectors \\( u_1, u_2 \\).}\n    \n    \\textbf{(b) Choose signs so that \\( A v_1 = \\sigma_1 u_1 \\) and verify the SVD:}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 4 \\\\\n    2 & 8\n    \\end{bmatrix} = \\begin{bmatrix} \n    u_1 & u_2\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    \\sigma_1 & 0\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    v_1 & v_2\n    \\end{bmatrix}^T.\n    \\]\n    \n    \\textbf{(c) Which four vectors give orthonormal bases for \\( C(A), N(A), C(A^T), N(A^T) \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the SVD from the eigenvectors \\( v_1, v_2 \\) of \\( A^T A \\) and \\( A v_i = \\sigma_i u_i \\):}\n    \\[\n    \\text{Fibonacci matrix } A = \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Use the SVD part of the MATLAB demo eigshow (or Java on the course page \\texttt{web.mit.edu/18.06}) to find the same vectors \\( v_1 \\) and \\( v_2 \\) graphically.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Compute \\( A^T A \\) and \\( A A^T \\), and their eigenvalues and unit eigenvectors, for}\n    \\[\n    A = \\begin{bmatrix}\n    1 & 1 & 0 \\\\\n    0 & 1 & 1\n    \\end{bmatrix}.\n    \\]\n    Multiply the three matrices \\( U \\Sigma V^T \\) to recover \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( u_1, \\dots, u_n \\) and \\( v_1, \\dots, v_n \\) are orthonormal bases for \\( \\mathbb{R}^n \\). Construct the matrix \\( A \\) that transforms each \\( v_j \\) into \\( u_j \\) to give \\( A v_1 = u_1, \\dots, A v_n = u_n \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Construct the matrix with rank 1 that has \\( A v = 12 u \\) for}\n    \\[\n    v = \\frac{1}{2} (1,1,1,1), \\quad u = \\frac{1}{3} (2,2,1).\n    \\]\n    Its only singular value is \\( \\sigma_1 = \\cdots \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find \\( U \\Sigma V^T \\) if \\( A \\) has orthogonal columns \\( w_1, \\dots, w_n \\) of lengths \\( \\sigma_1, \\dots, \\sigma_n \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Explain how \\( U \\Sigma V^T \\) expresses \\( A \\) as a sum of \\( r \\) rank-1 matrices in equation (3):}\n    \\[\n    A = \\sigma_1 u_1 v_1^T + \\cdots + \\sigma_r u_r v_r^T.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( A \\) is a 2 by 2 symmetric matrix with unit eigenvectors \\( u_1 \\) and \\( u_2 \\). If its eigenvalues are \\( \\lambda_1 = 3 \\) and \\( \\lambda_2 = -2 \\), what are \\( U \\), \\( \\Sigma \\), and \\( V^T \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( A \\) is invertible (with \\( \\sigma_1 > \\sigma_2 > 0 \\)). Change \\( A \\) by as small a matrix as possible to produce a singular matrix \\( A' \\). Hint: \\( U \\) and \\( V \\) do not change. Find \\( A' \\) from}\n    \\[\n    A = \\begin{bmatrix} \n    u_1 & u_2 \n    \\end{bmatrix}\n    \\begin{bmatrix}\n    \\sigma_1 & 0 \\\\\n    0 & \\sigma_2\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    v_1 & v_2\n    \\end{bmatrix}^T.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{(a) If \\( A \\) changes to \\( 4A \\), what is the change in the SVD?}\n    \n    \\textbf{(b) What is the SVD for \\( A^T \\) and for \\( A^{-1} \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Why doesn\u2019t the SVD for \\( A + I \\) just use \\( \\Sigma + I \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the SVD and the pseudoinverse \\( A^+ \\) of the \\( m \\times n \\) zero matrix.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the SVD and the pseudoinverse \\( V \\Sigma^+ U^T \\) of}\n    \\[\n    A = \\begin{bmatrix} \n    1 & 1 & 1 & 1\n    \\end{bmatrix}, \\quad B = \\begin{bmatrix}\n    0 & 1 & 0 \\\\\n    1 & 0 & 0\n    \\end{bmatrix}, \\quad C = \\begin{bmatrix}\n    1 & 1 \\\\\n    0 & 0\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If an \\( m \\times n \\) matrix \\( Q \\) has orthonormal columns, what is \\( Q^+ \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Diagonalize \\( A^T A \\) to find its positive definite square root \\( S = V \\Sigma^{1/2} V^T \\) and its polar decomposition \\( A = QS \\):}\n    \\[\n    A = \\frac{1}{\\sqrt{10}} \\begin{bmatrix}\n    10 & 6 \\\\\n    0 & 8\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{What is the minimum-length least-squares solution \\( x^+ = A^+ b \\) to the following?}\n    \\[\n    Ax = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    1 & 0 & 0 \\\\\n    1 & 1 & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    C \\\\\n    D \\\\\n    E\n    \\end{bmatrix}\n    = \\begin{bmatrix}\n    0 \\\\\n    2 \\\\\n    2\n    \\end{bmatrix}.\n    \\]\n    You can compute \\( A^+ \\), or find the general solution to \\( A^T A x = A^T b \\) and choose the solution that is in the row space of \\( A \\). This problem fits the best plane \\( C + Dt + Ez \\) to \\( b = 0 \\) and also \\( b = 2 \\) at \\( t = z = 0 \\) (and \\( b = 2 \\) at \\( t = z = 1 \\)).\n    \n    \\textbf{(a) If \\( A \\) has independent columns, its left-inverse \\( (A^T A)^{-1} A^T \\) is \\( A^+ \\).}\n    \n    \\textbf{(b) If \\( A \\) has independent rows, its right-inverse \\( A^T (A A^T)^{-1} \\) is \\( A^+ \\).}\n    \n    In both cases, verify that \\( x^+ = A^+ b \\) is in the row space, and \\( A^T A x^+ = A^T b \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Split \\( A = U \\Sigma V^T \\) into its reverse polar decomposition \\( Q S_0 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Is \\( (AB)^+ = B^+ A^+ \\) always true for pseudoinverses? I believe not.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Removing zero rows of \\( U \\) leaves \\( A = LU \\), where the \\( r \\) columns of \\( L \\) span the column space of \\( A \\) and the \\( r \\) rows of \\( U \\) span the row space. Then \\( A^+ \\) has the explicit formula}\n    \\[\n    A^+ = U^T (U U^T)^{-1} (L^T L)^{-1} L^T.\n    \\]\n    \\textbf{Why is \\( A^+ b \\) in the row space with \\( U^T \\) at the front? Why does \\( A^T A A^+ b = A^T b \\), so that \\( x^+ = A^+ b \\) satisfies the normal equation as it should?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Explain why \\( A A^+ \\) and \\( A^+ A \\) are projection matrices (and therefore symmetric). What fundamental subspaces do they project onto?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Consider the system \\( A\\mathbf{x} = \\mathbf{b} \\) given by}\n    \\[\n    A = \\begin{pmatrix}\n    2 & -1 & 0 \\\\\n    -1 & 2 & -1 \\\\\n    0 & -1 & 2\n    \\end{pmatrix}, \\quad\n    \\mathbf{b} = \\begin{pmatrix}\n    4 \\\\\n    0 \\\\\n    4\n    \\end{pmatrix}.\n    \\]\n    \\textbf{Construct the corresponding quadratic function \\( P(x_1, x_2, x_3) \\), compute its partial derivatives \\( \\frac{\\partial P}{\\partial x_i} \\), and verify that they vanish exactly at the desired solution.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Complete the square in \\( P = \\frac{1}{2} \\mathbf{x}^T A \\mathbf{x} - \\mathbf{x}^T \\mathbf{b} = \\frac{1}{2} (\\mathbf{x} - A^{-1} \\mathbf{b})^T A (\\mathbf{x} - A^{-1} \\mathbf{b}) + \\text{constant}.} \\\\\n    \\textbf{This constant equals \\( P_{\\text{min}} \\) because the term before it is never negative. (Why?)}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the minimum, if there is one, of \\( P_1 = \\frac{1}{2} x^2 + xy + y^2 - 3y \\) and \\( P_2 = \\frac{1}{2} x^2 - 3y \\). What matrix \\( A \\) is associated with \\( P_2 \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{(Review) Another quadratic that certainly has its minimum at \\( A\\mathbf{x} = \\mathbf{b} \\) is}\n    \\[\n    Q(\\mathbf{x}) = \\frac{1}{2} \\| A\\mathbf{x} - \\mathbf{b} \\|^2 = \\frac{1}{2} \\mathbf{x}^T A^T A \\mathbf{x} - \\mathbf{x}^T A^T \\mathbf{b} + \\frac{1}{2} \\mathbf{b}^T \\mathbf{b}.\n    \\]\n    \\textbf{Comparing \\( Q \\) with \\( P \\), and ignoring the constant \\( \\frac{1}{2} \\mathbf{b}^T \\mathbf{b} \\), what system of equations do we get at the minimum of \\( Q \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For any symmetric matrix \\( A \\), compute the ratio \\( R(x) \\) for the special choice \\( x = (1, \\ldots, 1) \\). How is the sum of all entries \\( a_{ij} \\) related to \\( \\lambda_1 \\) and \\( \\lambda_n \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{With \\( A = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\), find a choice of \\( x \\) that gives a smaller \\( R(x) \\) than the bound \\( \\lambda_1 \\leq 2 \\) that comes from the diagonal entries. What is the minimum value of \\( R(x) \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( B \\) is positive definite, show from the Rayleigh quotient that the smallest eigenvalue of \\( A + B \\) is larger than the smallest eigenvalue of \\( A \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( \\lambda_1 \\) and \\( \\mu_1 \\) are the smallest eigenvalues of \\( A \\) and \\( B \\), show that the smallest eigenvalue \\( \\theta_1 \\) of \\( A + B \\) is at least as large as \\( \\lambda_1 + \\mu_1 \\). (Try the corresponding eigenvector \\( x \\) in the Rayleigh quotients.)}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If \\( B \\) is positive definite, show from the minimax principle that the second smallest eigenvalue is increased by adding \\( B \\): \\( \\lambda_2(A + B) > \\lambda_2(A) \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{If you throw away two rows and columns of \\( A \\), what inequalities do you expect between the smallest eigenvalue \\( \\mu \\) of the new matrix and the original \\( \\lambda \\)'s?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Find the minimum values of}\n    \\[\n    R(x) = \\frac{x_1^2 - x_1 x_2 + x_2^2}{x_1^2 + x_2^2}\n    \\]\n    and\n    \\[\n    R(x) = \\frac{x_1^2 - x_1 x_2 + x_2^2}{2x_1^2 + x_2^2}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Prove from equation (11) that \\( R(x) \\) is never larger than the largest eigenvalue \\( \\lambda_n \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{The minimax principle for \\( \\lambda_j \\) involves \\( j \\)-dimensional subspaces \\( S_j \\):}\n    \\[\n    \\lambda_j = \\min_{S_j} \\max_{x \\in S_j} R(x).\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "If \\( \\lambda_j \\) is positive, infer that every \\( S_j \\) contains a vector \\( x \\) with \\( R(x) > 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Deduce that \\( S_j \\) contains a vector \\( y = C^{-1} x \\) with \\( \\frac{y^T C^T A C y}{y^T y} > 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Conclude that the \\( j \\)-th eigenvalue of \\( C^T A C \\), from its minimax principle, is also positive\u2014proving again the law of inertia in Section 6.2."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Show that the smallest eigenvalue \\( \\lambda_1 \\) of \\( A x = \\lambda M x \\) is not larger than the ratio \\( \\frac{a_{11}}{m_{11}} \\) of the corner entries.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Which particular subspace \\( S_2 \\) in Problem 13 gives the minimum value \\( \\lambda_2 \\)? In other words, over which \\( S_2 \\) is the maximum of \\( R(x) \\) equal to \\( \\lambda_2 \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{16.} From the zero submatrix, determine the signs of the \\( n \\) eigenvalues of the matrix \\( A \\):\n    \\[\n    A = \\begin{pmatrix}\n    0 & \\cdot & 0 & 1 \\\\\n    \\cdot & \\cdot & 0 & 2 \\\\\n    0 & 0 & 0 & \\cdot \\\\\n    1 & 2 & \\cdot & n\n    \\end{pmatrix}\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{17.} (Constrained minimum) Suppose the unconstrained minimum \\( x = A^{-1}b \\) happens to satisfy the constraint \\( Cx = d \\). Verify that equation (5) correctly gives \\( P_{\\text{min}} = P_{\\text{min}} \\); the correction term is zero."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Use three hat functions, with \\( h = \\frac{1}{4} \\), to solve \\( -u'' = 2 \\) with \\( u(0) = u(1) = 0 \\). Verify that the approximation \\( U \\) matches \\( u = x - x^2 \\) at the nodes.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Solve \\( -u'' = x \\) with \\( u(0) = u(1) = 0 \\). Then solve approximately with two hat functions and \\( h = \\frac{1}{3} \\). Where is the largest error?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( -u'' = 2 \\), with the boundary condition \\( u(1) = 0 \\) changed to \\( u'(1) = 0 \\). This \u201cnatural\u201d condition on \\( u' \\) need not be imposed on the trial functions \\( V \\). With \\( h = \\frac{1}{3} \\), there is an extra half-hat \\( V_3 \\), which goes from 0 to 1 between \\( x = \\frac{2}{3} \\) and \\( x = 1 \\). Compute \\( A_{33} = \\int (V_3')^2 \\, dx \\) and \\( f_3 = \\int 2V_3 \\, dx \\). Solve \\( A y = f \\) for the finite element solution \\( y_1 V_1 + y_2 V_2 + y_3 V_3 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Solve \\( -u'' = 2 \\) with a single hat function, but place its node at \\( x = \\frac{1}{4} \\) instead of \\( x = \\frac{1}{2} \\). (Sketch this function \\( V_1 \\).) With boundary conditions \\( u(0) = u(1) = 0 \\), compare the finite element approximation with the true \\( u = x - x^2 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Use three hat functions, with \\( h = \\frac{1}{4} \\), to solve \\( -u'' = 2 \\) with \\( u(0) = u(1) = 0 \\). Verify that the approximation \\( U \\) matches \\( u = x - x^2 \\) at the nodes.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Solve \\( -u'' = x \\) with \\( u(0) = u(1) = 0 \\). Then solve approximately with two hat functions and \\( h = \\frac{1}{3} \\). Where is the largest error?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Suppose \\( -u'' = 2 \\), with the boundary condition \\( u(1) = 0 \\) changed to \\( u'(1) = 0 \\). This \"natural\" condition on \\( u' \\) need not be imposed on the trial functions \\( V \\). With \\( h = \\frac{1}{3} \\), there is an extra half-hat \\( V_3 \\), which goes from 0 to 1 between \\( x = \\frac{2}{3} \\) and \\( x = 1 \\). Compute \\( A_{33} = \\int (V_3')^2 \\, dx \\) and \\( f_3 = \\int 2V_3 \\, dx \\). Solve \\( A y = f \\) for the finite element solution \\( y_1 V_1 + y_2 V_2 + y_3 V_3 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Solve \\( -u'' = 2 \\) with a single hat function, but place its node at \\( x = \\frac{1}{4} \\) instead of \\( x = \\frac{1}{2} \\). (Sketch this function \\( V_1 \\).) With boundary conditions \\( u(0) = u(1) = 0 \\), compare the finite element approximation with the true \\( u = x - x^2 \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{Galerkin\u2019s method starts with the differential equation (say \\( -u'' = f(x) \\)) instead of the energy \\( P \\). The trial solution is still \\( u = y_1 V_1 + y_2 V_2 + \\cdots + y_n V_n \\), and the \\( y \\)'s are chosen to make the difference between \\( -u'' \\) and \\( f \\) orthogonal to every \\( V_j \\):}\n    \\[\n    \\int \\left( -y_1 V_1'' - y_2 V_2'' - \\cdots - y_n V_n'' \\right) V_j \\, dx = \\int f(x) V_j(x) \\, dx.\n    \\]\n    \\textbf{Integrate the left side by parts to reach \\( A y = f \\), proving that Galerkin gives the same \\( A \\) and \\( f \\) as Rayleigh-Ritz for symmetric problems.}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{A basic identity for quadratics shows \\( y = A^{-1} b \\) as minimizing:}\n    \\[\n    P(y) = \\frac{1}{2} y^T A y - y^T b = \\frac{1}{2} (y - A^{-1} b)^T A (y - A^{-1} b) - \\frac{1}{2} b^T A^{-1} b.\n    \\]\n    \\textbf{The minimum over a subspace of trial functions is at the \\( y \\) nearest to \\( A^{-1} b \\). (That makes the first term on the right as small as possible; it is the key to convergence of \\( U \\) to \\( u \\).) If \\( A = I \\) and \\( b = (1,0,0) \\), which multiple of \\( V = (1,1,1) \\) gives the smallest value of \\( P(y) = \\frac{1}{2} y^T y - y_1 \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For a single hat function \\( V(x) \\) centered at \\( x = \\frac{1}{2} \\), compute \\( A = \\int (V')^2 \\, dx \\) and \\( M = \\int V^2 \\, dx \\). In the 1 by 1 eigenvalue problem, is \\( \\lambda = \\frac{A}{M} \\) larger or smaller than the true eigenvalue \\( \\lambda = \\pi^2 \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{For the hat functions \\( V_1 \\) and \\( V_2 \\) centered at \\( x = h = \\frac{1}{3} \\) and \\( x = 2h = \\frac{2}{3} \\), compute the 2 by 2 mass matrix \\( M_{ij} = \\int V_i V_j \\, dx \\), and solve the eigenvalue problem \\( A x = \\lambda M x \\).}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "\\textbf{What is the mass matrix \\( M_{ij} = \\int V_i V_j \\, dx \\) for \\( n \\) hat functions with \\( h = \\frac{1}{n+1} \\)?}"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define a local minimum, local maximum, and saddle point. Provide an example of each for a function of two variables."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the necessary conditions for a point to be classified as a local maximum. Include a detailed explanation of the role of the gradient and Hessian matrix in this classification."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What is the significance of the second-derivative test in multivariable optimization? Derive the conditions under which the second-derivative test can be used to classify critical points as local minima, maxima, or saddle points."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain how the Hessian matrix is used to classify critical points of a function. Provide the necessary conditions for a critical point to be a local minimum, local maximum, or saddle point based on the eigenvalues of the Hessian matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that if the Hessian matrix of a function at a critical point is positive definite, then that point is a local minimum."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the second derivative test for a function of two variables. Provide an example and use this test to classify the critical points of the given function."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the function \\( f(x, y) = x^2 + y^2 - 4x - 6y + 13 \\). Find the critical points and classify them as minima, maxima, or saddle points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Determine whether the point \\( (1, 1) \\) is a local minimum, maximum, or saddle point for the function \\( f(x, y) = x^2 + y^2 + 2xy - 6x - 4y \\). Use the second-derivative test and discuss the results."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For the function \\( f(x, y) = x^3 + y^3 - 3x^2 - 3y^2 \\), find the critical points and classify them as local minima, maxima, or saddle points. Use the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the critical points of the function \\( f(x, y) = 4x^2 + 4y^2 - 16x - 8y + 18 \\). Classify them as minima, maxima, or saddle points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the function \\( f(x, y) = x^2 + 2y^2 - 4x + 4y \\), find the critical points and determine whether each point is a minimum, maximum, or saddle point using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve for the critical points of the function \\( f(x, y) = x^2y + y^3 - 4x \\). Use the second-derivative test to classify the critical points."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the function \\( f(x, y) = x^2y + 3xy^2 - 6x - 5y \\). Find and classify the critical points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For the function \\( f(x, y, z) = x^2 + y^2 + z^2 - 4x - 2y + 2z + 3 \\), find the critical points and classify them as minima, maxima, or saddle points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the function \\( f(x, y, z) = x^2 + y^2 + z^2 + 2xy - 4xz \\). Find and classify the critical points as minima, maxima, or saddle points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the function \\( f(x, y, z) = x^2y + y^2z + z^2x \\), find and classify the critical points using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Let \\( f(x, y, z) = x^3 + y^3 + z^3 - 6x^2 - 6y^2 - 6z^2 \\). Find the critical points and classify them using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Determine the nature of the critical points for the function \\( f(x, y) = 4x^2 - 3xy + 2y^2 - 6x + 5y \\) using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For the function \\( f(x, y) = 3x^2 + 2y^2 - 8x - 6y \\), find the critical points and classify them using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the function \\( f(x, y) = 2x^2 + 3y^2 + 4xy - 6x + 5y \\). Find the critical points and use the second-derivative test to classify them."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Determine whether the function \\( f(x, y) = x^3 - 3xy + y^3 \\) has any saddle points. If so, classify them."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the critical points of the function \\( f(x, y) = x^2y + y^2 - 6x - 4y + 9 \\). Use the second-derivative test to classify the points as minima, maxima, or saddle points."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the function \\( f(x, y) = x^2 + y^2 - 6xy \\), find the critical points and classify them using the second-derivative test."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define a positive definite matrix and explain its significance in optimization problems. Provide examples of how positive definite matrices are used in quadratic forms."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "State and explain Sylvester\u2019s criterion for testing positive definiteness. Apply this criterion to the matrix \n    \\[\n    A = \\begin{bmatrix} 4 & 2 \\\\ 2 & 3 \\end{bmatrix}\n    \\]\n    and determine if it is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What are the necessary and sufficient conditions for a matrix to be positive definite? Discuss the role of eigenvalues and principal minors in these conditions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive Sylvester\u2019s criterion for testing whether a matrix is positive definite. Use this to test the positive definiteness of the matrix\n    \\[\n    A = \\begin{bmatrix} 2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that if a matrix is positive definite, all its eigenvalues are positive. Provide an example of a positive definite matrix and demonstrate how the eigenvalues can be computed."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the Cholesky decomposition of a positive definite matrix. Use the matrix\n    \\[\n    A = \\begin{bmatrix} 6 & 3 \\\\ 3 & 6 \\end{bmatrix}\n    \\]\n    and find its Cholesky decomposition."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix\n    \\[\n    A = \\begin{bmatrix} 5 & 2 \\\\ 2 & 5 \\end{bmatrix}.\n    \\]\n    Use Sylvester\u2019s criterion to determine if the matrix is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve the quadratic form \\( Q(x) = x^T A x \\) where \n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n    \\]\n    and determine if the matrix is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Determine if the matrix\n    \\[\n    A = \\begin{bmatrix} 10 & 2 & 3 \\\\ 2 & 10 & 4 \\\\ 3 & 4 & 10 \\end{bmatrix}\n    \\]\n    is positive definite by checking its eigenvalues and principal minors."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix \n    \\[\n    A = \\begin{bmatrix} 3 & 1 & 1 \\\\ 1 & 3 & 1 \\\\ 1 & 1 & 3 \\end{bmatrix}\n    \\]\n    verify whether it is positive definite by computing the eigenvalues."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that if the principal minors of a matrix are all positive, then the matrix is positive definite. Use this to verify the positive definiteness of the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 1 \\end{bmatrix}.\n    \\]\n    Use Sylvester\u2019s criterion to check if it is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Let\n    \\[\n    A = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}.\n    \\]\n    Show that this matrix is positive definite using both Sylvester\u2019s criterion and eigenvalue computation."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{bmatrix} 4 & 2 & 1 \\\\ 2 & 3 & 1 \\\\ 1 & 1 & 2 \\end{bmatrix}.\n    \\]\n    Determine if it is positive definite by calculating the eigenvalues and principal minors."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 3 \\end{bmatrix}\n    \\]\n    verify that it is positive definite by checking its eigenvalues and principal minors."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix\n    \\[\n    A = \\begin{bmatrix} 6 & 1 & 2 \\\\ 1 & 6 & 3 \\\\ 2 & 3 & 6 \\end{bmatrix}.\n    \\]\n    Use Sylvester\u2019s criterion to determine if the matrix is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve the quadratic form \\( Q(x) = x^T A x \\) where \n    \\[\n    A = \\begin{bmatrix} 5 & 4 \\\\ 4 & 5 \\end{bmatrix}.\n    \\]\n    Show whether the matrix is positive definite by checking the eigenvalues and principal minors."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the Cholesky decomposition of the matrix\n    \\[\n    A = \\begin{bmatrix} 4 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that if all eigenvalues of a matrix are positive, the matrix is positive definite. Use this theorem to prove that the matrix\n    \\[\n    A = \\begin{bmatrix} 8 & 6 \\\\ 6 & 8 \\end{bmatrix}\n    \\]\n    is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}.\n    \\]\n    Check whether it is positive definite by computing the eigenvalues."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the eigenvalues of the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}\n    \\]\n    and determine if the matrix is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{bmatrix} 4 & 1 & 2 \\\\ 1 & 4 & 1 \\\\ 2 & 1 & 4 \\end{bmatrix}.\n    \\]\n    Verify if the matrix is positive definite using Sylvester\u2019s criterion."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that if a matrix is positive definite, then it is symmetric. Use this result to verify if the matrix \n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}\n    \\]\n    is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use Sylvester\u2019s criterion to verify whether the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 4 \\\\ 4 & 6 \\end{bmatrix}\n    \\]\n    is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the matrix \n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}\n    \\]\n    is not positive definite by computing its eigenvalues."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Verify if the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n    \\]\n    is positive definite by using Sylvester\u2019s criterion."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}.\n    \\]\n    Determine if the matrix is positive definite using both Sylvester\u2019s criterion and eigenvalue computation."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix \n    \\[\n    A = \\begin{bmatrix} 7 & 3 & 4 \\\\ 3 & 7 & 5 \\\\ 4 & 5 & 7 \\end{bmatrix}\n    \\]\n    determine if it is positive definite by checking the eigenvalues and principal minors."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define Singular Value Decomposition (SVD) and discuss its properties. Explain how the singular values provide insight into the structure of a matrix and its rank."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "How is Singular Value Decomposition (SVD) related to the eigenvalue decomposition of a matrix? In particular, relate the singular values of \\( A \\) to the eigenvalues of \\( A^T A \\) and \\( A A^T \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the importance of the singular values in dimensionality reduction. How do they contribute to reducing the rank and improving computational efficiency in applications such as principal component analysis (PCA)?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the Singular Value Decomposition of a matrix. Show the steps involved in decomposing a matrix \\( A \\) into \\( A = U \\Sigma V^T \\), where \\( U \\), \\( \\Sigma \\), and \\( V \\) have specific properties."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the singular values of a matrix \\( A \\) are the square roots of the eigenvalues of \\( A^T A \\). Use this result to find the singular values of the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the columns of the matrix \\( U \\) in the SVD of \\( A \\) are orthonormal. That is, prove that \\( U^T U = I \\) where \\( I \\) is the identity matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\end{bmatrix},\n    \\]\n    compute its Singular Value Decomposition (SVD)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the Singular Value Decomposition (SVD) of the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n    \\]\n    to compute the rank and nullity of the matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply SVD to solve the least squares problem \\( Ax = b \\), where\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 7 \\\\ 8 \\\\ 9 \\end{bmatrix}.\n    \\]\n    Find the least squares solution \\( x \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the matrix \\( A \\) has the same singular values as the matrix \\( A^T \\). Prove this by computing the SVD of both \\( A \\) and \\( A^T \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Compute the Singular Value Decomposition (SVD) of the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 4 \\\\ 4 & 3 \\end{bmatrix}.\n    \\]\n    Discuss how the singular values can be interpreted geometrically."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix},\n    \\]\n    use SVD to compute its rank, and then use this information to describe the nullity of \\( A \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the SVD provides a unique factorization up to sign. Specifically, show that if \\( A = U \\Sigma V^T \\), then the decomposition is unique except for possible signs of the singular values and the columns of \\( U \\) and \\( V \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the Singular Value Decomposition (SVD) to the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}\n    \\]\n    and find its approximate rank using the first two singular values."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the singular values of a matrix \\( A \\) are invariant under orthogonal transformations. That is, for any orthogonal matrix \\( Q \\), the singular values of \\( A \\) and \\( QA \\) are the same."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given a matrix \\( A \\), define and explain the relationship between the rank of \\( A \\) and its singular values. Prove that the rank of \\( A \\) is equal to the number of non-zero singular values."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how the SVD can be used to solve an overdetermined system of equations \\( Ax = b \\) where \\( A \\) is a non-square matrix. Solve the system using the SVD of the matrix\n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\\\ 2 & 2 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 5 \\\\ 6 \\\\ 7 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the connection between the SVD and the spectral theorem for symmetric matrices. Specifically, describe how the eigenvalue decomposition of a symmetric matrix relates to the SVD."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Compute the SVD of the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 4 & 0 \\\\ 4 & 3 & 0 \\\\ 0 & 0 & 5 \\end{bmatrix}.\n    \\]\n    Discuss how the singular values reflect the geometry of the matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the SVD to compute the pseudoinverse of the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}.\n    \\]\n    Verify that \\( A^+ A = I \\) where \\( A^+ \\) is the pseudoinverse."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the Frobenius norm of a matrix \\( A \\), defined as \\( \\|A\\|_F = \\sqrt{\\sum_{i} \\sigma_i^2} \\), is equal to the square root of the sum of the squares of the singular values."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the SVD to perform dimensionality reduction on the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}\n    \\]\n    by keeping only the first singular value. Compare the original matrix with the reduced matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that for a diagonal matrix \\( D \\), the SVD of \\( D \\) is simply \\( D = U \\Sigma V^T \\) where \\( U = V = I \\) and \\( \\Sigma = D \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 2 & 3 \\\\ 2 & 2 \\\\ 3 & 2 \\end{bmatrix},\n    \\]\n    compute the SVD of \\( A \\) and discuss the significance of the singular values in relation to the matrix's rank."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the SVD of the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 3 \\\\ 2 & 2 \\end{bmatrix}\n    \\]\n    to perform dimensionality reduction, reducing the matrix to a rank-1 approximation. Compare this approximation to the original matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix},\n    \\]\n    compute its SVD and explain the relationship between its singular values and the rank."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Compute the SVD of the matrix\n    \\[\n    A = \\begin{bmatrix} 5 & 4 \\\\ 4 & 5 \\end{bmatrix}.\n    \\]\n    Discuss how the singular values and vectors relate to the transformation properties of the matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Find the rank of the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\n    \\]\n    using its singular values."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how the SVD can be used to obtain an optimal low-rank approximation of a matrix. Use this to approximate the matrix\n    \\[\n    A = \\begin{bmatrix} 4 & 3 \\\\ 3 & 4 \\end{bmatrix}\n   ]\n    to rank-1."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define the minimum principle in optimization. Discuss its significance in solving constrained optimization problems, and provide an example where the minimum principle is used to determine the optimal solution to a problem."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "How does the minimum principle relate to positive definite matrices in optimization? Discuss the importance of positive definiteness and explain how it ensures the uniqueness of the solution in certain optimization problems."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the application of the minimum principle in variational problems. Illustrate this by providing a classical example such as the brachistochrone problem or the problem of finding the shortest path under certain constraints."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the minimum principle for a functional \\( J(y) = \\int_{a}^{b} f(x, y(x), y'(x)) \\, dx \\), and explain how the conditions for optimality are derived using the Euler-Lagrange equation. Discuss the role of the boundary conditions in this derivation."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that a function \\( f(x) \\) that satisfies the minimum principle must have a positive definite Hessian matrix. Use the second-order necessary condition for optimality to demonstrate this property, and provide an example where this condition is verified."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the minimum principle to solve the variational problem of finding the function \\( y(x) \\) that minimizes the functional\n    \\[\n    J(y) = \\int_{0}^{1} \\left( (y')^2 + y^2 \\right) \\, dx.\n    \\]\n    Solve this problem by deriving the Euler-Lagrange equation and solving for \\( y(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the minimum principle in optimization by considering the quadratic objective function\n    \\[\n    f(x) = x^T A x + b^T x + c,\n    \\]\n    where \\( A \\) is a symmetric matrix. Show how positive definiteness of \\( A \\) ensures that the function has a unique minimum. Solve for the optimal \\( x \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the minimum principle in the context of constrained optimization. Consider a constrained optimization problem with an equality constraint \\( g(x) = 0 \\). Use the method of Lagrange multipliers to derive the necessary conditions for optimality."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the connection between the minimum principle and the concept of convexity in optimization. Prove that if the Hessian of the objective function is positive definite, the function is strictly convex, and hence the minimum principle guarantees a unique minimum."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the functional\n    \\[\n    J(y) = \\int_0^1 \\left( y''(x)^2 + (y'(x))^2 \\right) dx.\n    \\]\n    Use the minimum principle to derive the Euler-Lagrange equation for this variational problem and solve for \\( y(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that a function \\( f(x) \\) is convex if its second derivative is positive definite. Use this result to explain why positive definite matrices guarantee a unique minimum in optimization problems."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the minimum principle to solve the following variational problem:\n    \\[\n    J(y) = \\int_0^1 (y''(x)^2 - y'(x)^2) \\, dx,\n    \\]\n    where \\( y(x) \\) is a function subject to boundary conditions. Solve for the function \\( y(x) \\) that minimizes the functional."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the minimum principle for a multi-variable function and use it to find the minimum of the objective function\n    \\[\n    f(x_1, x_2) = x_1^2 + x_2^2 + 2x_1 x_2.\n    \\]\n    Solve for the values of \\( x_1 \\) and \\( x_2 \\) that minimize this function."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the role of the Hessian matrix in the minimum principle. Specifically, show that the Hessian matrix of a twice-differentiable function is positive definite at a local minimum."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the variational problem\n    \\[\n    J(y) = \\int_0^1 \\left( y'(x)^2 + 3y(x)^2 \\right) dx.\n    \\]\n    Use the minimum principle to solve for the function \\( y(x) \\) that minimizes this functional subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the minimum principle in the context of functional optimization. Use this principle to determine the optimal value of the integral\n    \\[\n    \\int_0^1 (y''(x)^2 + y(x)^2) dx,\n    \\]\n    where \\( y(x) \\) is a function with boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that for a convex optimization problem, the minimum principle guarantees that any local minimum is also a global minimum. Use an example to illustrate this property."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the minimum principle to find the optimal solution for the quadratic functional\n    \\[\n    J(y) = \\int_0^1 (y'(x)^2 + 2y(x)^2) \\, dx.\n    \\]\n    Solve for the function \\( y(x) \\) that minimizes the functional subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that a positive definite Hessian matrix implies a strictly convex function. Use this result to explain why the minimum principle guarantees a unique minimum for a strictly convex function."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the minimum principle to the following constrained optimization problem:\n    \\[\n    \\min_{x} \\, f(x) = x_1^2 + x_2^2 \\quad \\text{subject to} \\quad g(x) = x_1 + x_2 - 1 = 0.\n    \\]\n    Solve for the optimal values of \\( x_1 \\) and \\( x_2 \\) using Lagrange multipliers."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the variational problem where the functional is given by\n    \\[\n    J(y) = \\int_0^1 \\left( (y'(x))^2 + (y(x))^3 \\right) dx.\n    \\]\n    Use the minimum principle to derive the Euler-Lagrange equation and solve for \\( y(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the necessary conditions for optimality using the minimum principle for the functional\n    \\[\n    J(y) = \\int_0^1 (y'(x)^2 - y(x)^2) \\, dx,\n    \\]\n    subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the second derivative of a convex function is positive definite. Use this result to demonstrate the application of the minimum principle in optimization problems with convex objective functions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the minimum principle to solve the variational problem\n    \\[\n    J(y) = \\int_0^1 \\left( 2y'(x)^2 + y(x)^2 \\right) \\, dx.\n    \\]\n    Solve for the function \\( y(x) \\) that minimizes this functional subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the first-order condition of the minimum principle gives a necessary condition for a local minimum of a quadratic functional."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the connection between the minimum principle and the method of steepest descent in optimization. Provide an example illustrating how the gradient of a function leads to the minimum principle."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the objective function\n    \\[\n    f(x) = x^T A x + b^T x + c,\n    \\]\n    where \\( A \\) is a positive definite matrix. Show that this function has a unique minimum at \\( x = -A^{-1}b \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve the following variational problem using the minimum principle:\n    \\[\n    J(y) = \\int_0^1 \\left( y'(x)^2 + y(x)^4 \\right) dx,\n    \\]\n    subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the necessary and sufficient conditions for optimality in the minimum principle for the problem of minimizing the functional\n    \\[\n    J(y) = \\int_0^1 (y'(x)^2 - y(x)^3) \\, dx.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the minimum principle in the context of a constrained optimization problem. For the objective function \\( f(x) = x^2 + 2x \\), solve the optimization problem subject to the constraint \\( x = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the minimum principle to a multi-variable optimization problem. Given the function\n    \\[\n    f(x, y) = x^2 + y^2 + 2xy,\n    \\]\n    find the critical points and determine whether they correspond to a minimum using the second-order conditions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the minimum principle for a functional involving higher-order derivatives, such as \\( J(y) = \\int_0^1 \\left( y^{(3)}(x)^2 + y(x)^2 \\right) dx \\). Solve for the function \\( y(x) \\) that minimizes this functional."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Use the minimum principle to solve the optimization problem for the function\n    \\[\n    f(x) = x_1^2 + x_2^2 - 2x_1x_2,\n    \\]\n    and find the point where this function achieves its minimum."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that if the Hessian matrix of a function is positive definite, the function has a unique minimum. Apply this to the function \\( f(x) = x^2 + 3x + 2 \\) to find its minimum."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the Euler-Lagrange equation for the functional\n    \\[\n    J(y) = \\int_0^1 \\left( y'(x)^2 + 3y(x)^2 \\right) dx.\n    \\]"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define the finite element method and explain its significance in solving partial differential equations (PDEs). Provide a detailed discussion on how the finite element method discretizes the domain and how it translates a continuous problem into a solvable system of algebraic equations."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "How does the concept of positive definiteness relate to the stiffness matrix in the finite element method? Discuss the implications of positive definite matrices for the existence and uniqueness of the solution in the context of finite element analysis."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the application of the finite element method in structural engineering. Illustrate how it is used to analyze stress, strain, and displacement in structures like beams, trusses, and plates under various loading conditions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the weak form of a boundary value problem for the Poisson equation:\n    \\[\n    -\\Delta u(x) = f(x), \\quad u(x) = 0 \\text{ on } \\partial\\Omega.\n    \\]\n    Show how the weak formulation leads to a system of linear equations in the finite element method."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the stiffness matrix in the finite element method is positive definite. Assume a linear finite element for a 1D structural problem and show that the associated stiffness matrix is positive definite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve a simple finite element problem involving the solution of a 1D Poisson equation:\n    \\[\n    -\\frac{d^2u}{dx^2} = f(x), \\quad u(0) = 0, \\quad u(1) = 0.\n    \\]\n    Use linear finite elements to discretize the problem and assemble the stiffness matrix. Solve the resulting system of equations for \\( u(x) \\) assuming a given source function \\( f(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the stiffness matrix for a 1D finite element problem:\n    \\[\n    K = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix},\n    \\]\n    analyze its positive definiteness by calculating its eigenvalues and discuss the implications for the solution of the corresponding system of equations."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the weak form of a boundary value problem for the heat equation:\n    \\[\n    \\frac{\\partial u}{\\partial t} - \\alpha \\Delta u = 0, \\quad u = 0 \\text{ on } \\partial\\Omega.\n    \\]\n    Show how the weak formulation leads to a time-stepping scheme for finite element analysis."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the process of discretization in the finite element method. How does the choice of element type (e.g., linear, quadratic) affect the accuracy of the solution? Provide examples comparing different element types."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the stiffness matrix \\( K \\) is symmetric and positive definite for a linear finite element problem. Use the variational principle to show that the associated functional is minimized by the solution, and explain the role of symmetry and positive definiteness in this context."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Consider the finite element formulation for the bending of a beam under an applied load. Derive the governing equations for the system, the stiffness matrix, and boundary conditions for a beam subjected to both bending and axial forces."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the concept of \"degrees of freedom\" in the context of finite element analysis. How does the number of degrees of freedom affect the size of the stiffness matrix and the computational complexity of the problem?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how the stiffness matrix for a 1D linear finite element problem can be derived using the Galerkin method. Assume the following linear trial function \\( \\hat{u}(x) \\) for the approximation of the displacement field:\n    \\[\n    \\hat{u}(x) = \\lambda_1 u_1 + \\lambda_2 u_2.\n    \\]\n    Calculate the stiffness matrix for this element."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "In a 2D finite element problem, derive the stiffness matrix for a triangular element using linear interpolation. Assume the element has nodes at \\( (x_1, y_1), (x_2, y_2), (x_3, y_3) \\), and derive the matrix form of the element's stiffness matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that for a linear finite element in 1D, the stiffness matrix is invertible and hence provides a unique solution. Use the properties of the bilinear form and the positive definiteness of the stiffness matrix to argue this point."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For a 1D beam subjected to a uniform load \\( w(x) = 1 \\) and simply supported at both ends, derive the stiffness matrix for the beam element and compute the displacements at the nodes."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how boundary conditions (Dirichlet and Neumann) are incorporated into the finite element formulation. Provide a numerical example to demonstrate how these conditions affect the final stiffness matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the concept of mesh refinement in the finite element method. How does refining the mesh improve the accuracy of the solution? Explain the trade-off between computational cost and accuracy."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the weak form of the boundary value problem for the wave equation:\n    \\[\n    \\frac{\\partial^2 u}{\\partial t^2} - c^2 \\Delta u = 0, \\quad u = 0 \\text{ on } \\partial\\Omega.\n    \\]\n    Show how the weak formulation leads to a system of equations for the finite element method."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the stiffness matrix\n    \\[\n    K = \\begin{bmatrix} 4 & -2 & 0 \\\\ -2 & 4 & -2 \\\\ 0 & -2 & 4 \\end{bmatrix},\n    \\]\n    solve the corresponding system of equations for \\( u = [u_1, u_2, u_3]^T \\) assuming boundary conditions \\( u_1 = 0 \\) and \\( u_3 = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the role of the mass matrix in finite element analysis. How does it differ from the stiffness matrix, and how is it used in dynamic problems such as vibration analysis?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the weak form of a boundary value problem for the elasticity equation in 2D:\n    \\[\n    \\nabla \\cdot (\\sigma) = f, \\quad \\sigma = C \\varepsilon, \\quad u = 0 \\text{ on } \\partial\\Omega.\n    \\]\n    Explain how this weak form leads to a finite element formulation for the displacement field \\( u(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how the stiffness matrix for a 2D structural problem can be assembled using a 2D quadrilateral element. Derive the shape functions and element stiffness matrix, and discuss the boundary conditions that are applied."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For a 1D finite element model, derive the system of equations for a structure subjected to both internal and external forces. Explain how the stiffness matrix is assembled and solve for the displacements at the nodes."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the process of solving the system of equations resulting from the finite element method. How does the assembly of the global stiffness matrix and force vector work, and what methods are used to solve the resulting linear system?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For a 1D linear finite element with two nodes, derive the global stiffness matrix for a structure subjected to a uniform distributed load. Assume that the element has Young's modulus \\( E = 210 \\, \\text{GPa} \\) and the element length \\( L = 2 \\, \\text{m} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the impact of mesh size and element type on the convergence of the finite element solution. How does refining the mesh lead to a more accurate solution in the context of the finite element method?"
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the stiffness matrix\n    \\[\n    K = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix},\n    \\]\n    calculate the displacement vector for a system subjected to a force vector \\( F = [1, 1]^T \\). Solve for the displacements and discuss the implications for the structure's deformation."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the stiffness matrix for a 2D finite element problem using quadratic shape functions. Explain the differences between linear and quadratic shape functions, and show how they affect the accuracy of the solution."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For a 1D finite element problem, derive the stiffness matrix for a triangular element. Discuss how this element is used to discretize a domain and solve a boundary value problem."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the global stiffness matrix in the finite element method is symmetric. Discuss the implications of this symmetry for the efficiency of solving the system of equations."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given a 2D triangular element, derive the stiffness matrix using the Galerkin method. Assume the element has nodes at \\( (x_1, y_1), (x_2, y_2), (x_3, y_3) \\), and show how the shape functions are used to derive the matrix."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that the finite element stiffness matrix is always positive semi-definite. Discuss how positive definiteness ensures the stability of the numerical solution."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the weak form of a boundary value problem for a system of nonlinear equations. Explain how the finite element method can be extended to solve nonlinear PDEs."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "For a 1D bar with constant cross-sectional area subjected to an axial force, derive the stiffness matrix and solve for the displacement at each node using finite element analysis."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the stiffness matrix for a 1D bar element is positive definite. Show that the stiffness matrix leads to a unique solution for the displacement field."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the global stiffness matrix for a 1D finite element model consisting of two elements. Discuss how the element stiffness matrices are assembled to form the global system."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the finite element formulation for a 1D elasticity problem. Assume the material is isotropic, and the structure is subjected to a uniform tensile force."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain how the finite element method is applied to problems in heat transfer. Derive the weak form of the heat conduction equation and show how it leads to a finite element solution for temperature distribution."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss how finite element methods are used in fluid dynamics. Derive the weak form for the Navier-Stokes equations and explain how the method can be applied to fluid flow problems."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the stiffness matrix for a 2D finite element problem, explain how boundary conditions are incorporated and how the global system of equations is solved for the displacements."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the element stiffness matrix for a 2D rectangular finite element. Assume the element has uniform material properties and discuss how the stiffness matrix is derived using shape functions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the numerical solution of the finite element method using direct and iterative solvers. Compare the advantages and disadvantages of both approaches in terms of computational cost and accuracy."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define a matrix norm in the context of linear algebra. Discuss its role in matrix inequalities and provide examples of commonly used norms such as the Frobenius norm and the spectral norm. How do these norms relate to the structure of optimization problems, and what are the implications for matrix analysis? Given the matrix \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\), compute its Frobenius norm and spectral norm."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "State and explain Ky Fan\u2019s inequalities in the context of matrix theory. Discuss their significance in optimization, particularly in the context of matrix eigenvalues. How can these inequalities be used to establish bounds in convex optimization problems involving eigenvalues of symmetric matrices? Apply Ky Fan's inequalities to the matrix \\( A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and determine its eigenvalue bounds."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "What is the L\u00f6wner-Heinz inequality, and how is it applied in matrix analysis? Provide a detailed explanation of its geometric interpretation and discuss its importance in the context of matrix functions, particularly when applied to positive semidefinite matrices. Prove the L\u00f6wner-Heinz inequality for the matrices \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the concept of matrix majorization and its relationship with matrix inequalities. How does matrix majorization serve as a tool in convex optimization? Provide examples of matrix inequalities that are related to matrix majorization, and explain their significance in optimization theory. For the matrix \\( A = \\begin{pmatrix} 3 & 1 \\\\ 0 & 2 \\end{pmatrix} \\), determine whether \\( A \\) is majorized by \\( B = \\begin{pmatrix} 2 & 2 \\\\ 1 & 1 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive Ky Fan's inequalities for the case of general matrices, not necessarily symmetric, and demonstrate how they can be applied to establish bounds on eigenvalues of non-symmetric matrices in optimization problems. Discuss the relationship between these inequalities and other matrix inequalities in convex optimization. Use Ky Fan\u2019s inequality to find eigenvalue bounds for the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 1 & 4 \\\\ 3 & 4 & 1 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove the L\u00f6wner-Heinz inequality for self-adjoint operators and discuss its significance in the context of convexity. How does this inequality relate to the optimization of convex functions over self-adjoint matrices or operators? Provide an example where this inequality is used to solve an optimization problem. Let \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\), prove the L\u00f6wner-Heinz inequality and find its application in an optimization problem."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply Ky Fan\u2019s inequalities to solve a semidefinite programming problem. Given the semidefinite program \\( \\max \\text{Tr}(A X) \\), subject to \\( X \\succeq 0 \\) and \\( \\text{Tr}(X) = 1 \\), where \\( A = \\begin{pmatrix} 3 & 2 \\\\ 2 & 1 \\end{pmatrix} \\), use Ky Fan\u2019s inequalities to determine the optimal solution."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve an optimization problem using matrix inequalities, such as maximizing a convex function subject to matrix constraints. Discuss the use of Ky Fan\u2019s inequalities and L\u00f6wner-Heinz inequality in obtaining optimal solutions for problems involving semidefinite matrices. Given \\( A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix} \\), solve the optimization problem \\( \\max \\text{Tr}(A X) \\) subject to \\( X \\succeq 0 \\) and \\( \\text{Tr}(X) = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive a set of inequalities involving matrix norms, and discuss their application to optimization problems. Show how these inequalities can be used to analyze the stability of solutions in optimization problems involving matrix constraints. For the matrix \\( A = \\begin{pmatrix} 2 & 3 \\\\ 3 & 4 \\end{pmatrix} \\), find its Frobenius norm and spectral norm, and use them to analyze the stability of a related optimization problem."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss how matrix inequalities are used in convex optimization to derive duality theorems. Provide a detailed explanation of the duality gap in semidefinite programming and how matrix inequalities play a crucial role in its analysis. For the semidefinite program \\( \\max \\text{Tr}(A X) \\), subject to \\( X \\succeq 0 \\), compute the duality gap for the given matrix \\( A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the application of Ky Fan's inequalities in the context of low-rank approximation problems. How can these inequalities be used to derive bounds on the rank of matrix approximations and to solve optimization problems involving low-rank matrices? Given a matrix \\( A = \\begin{pmatrix} 6 & 2 \\\\ 2 & 3 \\end{pmatrix} \\), use Ky Fan\u2019s inequalities to find the rank of a low-rank approximation."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive an explicit formula for the eigenvalues of a matrix function involving a positive semidefinite matrix. Use this formula to show how matrix inequalities can be applied to optimization problems involving matrix functions, such as maximizing the trace of a matrix function subject to constraints. For the matrix \\( A = \\begin{pmatrix} 4 & 2 \\\\ 2 & 4 \\end{pmatrix} \\), compute its eigenvalues and use them to solve a related optimization problem."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that the L\u00f6wner-Heinz inequality is a special case of a more general matrix inequality involving matrix monotonicity. Discuss the implications of this more general form for optimization problems, particularly in the context of semidefinite programming and convex optimization. Use the inequality to solve an optimization problem with the matrix \\( A = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 2 & 0 \\\\ 0 & 2 \\end{pmatrix} \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how matrix inequalities can be applied to the analysis of the complexity of algorithms in semidefinite programming. Discuss how the matrix inequalities associated with the dual problem can be used to derive bounds on the computational complexity of solving semidefinite programs. Consider the matrix \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and analyze its computational complexity using matrix inequalities."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain how the concept of matrix majorization can be used to establish bounds in optimization problems involving eigenvalues of matrix functions. Provide an example where matrix majorization is used to optimize a function over a set of matrices with specified eigenvalue constraints. Use matrix majorization to solve the problem where \\( A = \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix} \\) and the eigenvalue constraints are \\( \\lambda_1 = 4, \\lambda_2 = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the relationship between matrix inequalities and the optimization of matrix-valued functions. Show how Ky Fan\u2019s inequalities and the L\u00f6wner-Heinz inequality can be used to derive conditions for optimality in matrix optimization problems, and explain how these conditions lead to the solution of matrix optimization problems in practice. Given \\( A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 4 \\end{pmatrix} \\), solve the matrix optimization problem \\( \\max \\text{Tr}(A X) \\) subject to \\( X \\succeq 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show how Ky Fan's inequalities can be used to derive bounds on the eigenvalues of the sum of two positive semidefinite matrices. Provide a detailed proof and discuss the implications for optimization problems involving matrix sums. Given \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\), compute the bounds on the eigenvalues of \\( A + B \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the concept of Schur-convex functions in matrix optimization and show how matrix inequalities are used to establish conditions for the convexity of matrix-valued functions. Provide an example where Schur-convex functions are used to optimize matrix functions under matrix inequality constraints. Given a Schur-convex function \\( f(X) = \\text{Tr}(A X^2) \\), find the optimal matrix \\( X \\) given the constraint \\( X \\succeq 0 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve an optimization problem involving a matrix inequality constraint. Consider a problem where the objective is to maximize a convex function subject to a matrix constraint such as \\( A \\succeq B \\). Apply the theory of matrix inequalities to derive the optimal solution and discuss its significance in the context of matrix analysis and convex optimization. Given \\( A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 2 & 0 \\\\ 0 & 2 \\end{pmatrix} \\), solve the optimization problem \\( \\max \\text{Tr}(A X) \\) subject to \\( X \\succeq B \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Define a positive semidefinite matrix and explain the difference between a positive semidefinite matrix and a positive definite matrix. Provide examples of both types of matrices, and describe how their eigenvalues influence their classification. Given the matrix \\( A = \\begin{pmatrix} 4 & 2 \\\\ 2 & 3 \\end{pmatrix} \\), determine whether it is positive semidefinite and explain your reasoning."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "State Schur's theorem and explain how it applies to positive semidefinite matrices. What does Schur\u2019s theorem imply about the eigenvalues of a positive semidefinite matrix? Use Schur's theorem to prove that the matrix \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\) is positive semidefinite."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the role of positive semidefinite matrices in quadratic forms. How can you express a quadratic form \\( x^T A x \\) as a convex function when \\( A \\) is positive semidefinite? Given \\( A = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and \\( x = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\), compute the quadratic form \\( x^T A x \\) and discuss its implications."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the conditions under which a matrix is positive semidefinite. What are the key criteria that a matrix must satisfy to be classified as positive semidefinite? Given the matrix \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\), show that it is positive semidefinite by verifying its conditions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Prove that a matrix is positive semidefinite if and only if all of its eigenvalues are non-negative. Use the matrix \\( A = \\begin{pmatrix} 1 & 2 \\\\ 2 & 1 \\end{pmatrix} \\) to verify this property by finding its eigenvalues and checking whether they are non-negative."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain the concept of Cholesky factorization and its application to positive semidefinite matrices. How does Cholesky decomposition help in solving systems of linear equations where the coefficient matrix is positive semidefinite? Perform the Cholesky factorization of the matrix \\( A = \\begin{pmatrix} 4 & 2 \\\\ 2 & 3 \\end{pmatrix} \\) and verify that the resulting matrix is lower triangular."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the properties of positive semidefinite matrices to optimization problems in machine learning. How are these matrices used in the formulation of cost functions and constraints in machine learning algorithms? Consider the following optimization problem: minimize \\( f(x) = x^T A x \\), subject to \\( A = \\begin{pmatrix} 5 & 1 \\\\ 1 & 5 \\end{pmatrix} \\) and \\( x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\). Compute the minimum value of \\( f(x) \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 5 \\\\ 3 & 5 & 6 \\end{pmatrix} \\), determine whether it is positive semidefinite by examining its eigenvalues. Show your work by finding the eigenvalues of the matrix and explaining why the matrix is positive semidefinite if all the eigenvalues are non-negative."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the significance of the spectral properties of positive semidefinite matrices in optimization. How can eigenvalues and eigenvectors be used to analyze the stability and optimality of solutions to optimization problems involving positive semidefinite matrices? Given \\( A = \\begin{pmatrix} 6 & 2 \\\\ 2 & 6 \\end{pmatrix} \\), find the eigenvalues and eigenvectors, and interpret them in the context of optimization."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Apply the concept of positive semidefinite matrices to the analysis of covariance matrices in statistics. How does the positive semidefiniteness of a covariance matrix influence its interpretation and use in multivariate analysis? Given the covariance matrix \\( A = \\begin{pmatrix} 1 & 0.8 \\\\ 0.8 & 1 \\end{pmatrix} \\), verify its positive semidefiniteness and discuss its implications for multivariate normal distributions."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Explain how positive semidefinite matrices are used in signal processing, particularly in the context of filtering and estimation problems. Provide an example where the matrix \\( A = \\begin{pmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{pmatrix} \\) is used as a covariance matrix in a Kalman filter and discuss how the positive semidefiniteness of \\( A \\) ensures the stability of the filter."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Investigate the relationship between positive semidefinite matrices and convex optimization. How do positive semidefinite matrices play a role in formulating convex optimization problems, and what properties do these matrices provide for solution methods such as gradient descent? Given \\( A = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix} \\), solve the convex optimization problem \\( \\min_x \\, x^T A x \\), subject to \\( x_1 + x_2 = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Derive the conditions under which a symmetric matrix is positive semidefinite. How can you use the Cholesky factorization and eigenvalue decomposition to test if a symmetric matrix is positive semidefinite? Given \\( A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 4 \\end{pmatrix} \\), check if \\( A \\) is positive semidefinite by performing both Cholesky factorization and eigenvalue decomposition."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Discuss the applications of positive semidefinite matrices in machine learning, particularly in the context of support vector machines (SVMs). How do positive semidefinite kernels lead to optimal hyperplane classification? Consider the kernel matrix \\( K = \\begin{pmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{pmatrix} \\), and demonstrate how its positive semidefiniteness ensures the feasibility of SVM optimization."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Given the matrix \\( A = \\begin{pmatrix} 2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\), determine whether it is positive semidefinite. If so, explain why this matrix is useful in a machine learning application such as kernel methods for regression or classification."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Solve an optimization problem involving positive semidefinite matrices using a Lagrange multiplier approach. Given the matrix \\( A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\), solve the optimization problem \\( \\max \\text{Tr}(A X) \\), subject to \\( X \\succeq 0 \\) and \\( \\text{Tr}(X) = 1 \\)."
    },
    {
        "chapter": "Positive Definite Matrices",
        "question": "Show that if a matrix is positive semidefinite, its inverse is also positive semidefinite, provided the matrix is invertible. Given \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\), find \\( A^{-1} \\) and verify that it is positive semidefinite."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a subset of the $x$-$y$ plane $\\mathbb{R}^2$ that is\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "closed under vector addition and subtraction, but not scalar multiplication."
    },
    {
        "chapter": "Vector Spaces",
        "question": "closed under scalar multiplication but not under vector addition."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which of the following subsets of $\\mathbb{R}^3$ are actually subspaces?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The plane of vectors $(b_1, b_2, b_3)$ with the first component $b_1 = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The plane of vectors $\\mathbf{b}$ with $b_1 = 1$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors $\\mathbf{b}$ with $b_2 b_3 = 0$ (this is the union of two subspaces, the plane $b_2 = 0$ and the plane $b_3 = 0$)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All combinations of two given vectors $(1, 1, 0)$ and $(2, 0, 1)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The plane of vectors $(b_1, b_2, b_3)$ that satisfy $b_3 - b_2 + 3b_1 = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the column space and the nullspace of the matrices\n    \\[\n    A = \\begin{pmatrix}\n        1 & -1 \\\\\n        0 & 0\n    \\end{pmatrix}, \\quad\n    B = \\begin{pmatrix}\n        0 & 0 & 3 \\\\\n        1 & 2 & 3\n    \\end{pmatrix}, \\quad\n    C = \\begin{pmatrix}\n        0 & 0 & 0 \\\\\n        0 & 0 & 0\n    \\end{pmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the smallest subspace of $3 \\times 3$ matrices that contains all symmetric matrices and all lower triangular matrices? What is the largest subspace that is contained in both of those subspaces?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Addition and scalar multiplication are required to satisfy these eight rules:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$x + y = y + x$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$x + (y + z) = (x + y) + z$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "There is a unique \"zero vector\" such that $x + 0 = x$ for all $x$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "For each $x$ there is a unique vector $-x$ such that $x + (-x) = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$1x = x$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$(c_1 c_2)x = c_1 (c_2 x)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$c(x + y) = cx + cy$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$(c_1 + c_2)x = c_1 x + c_2 x$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose addition in $\\mathbb{R}^2$ adds an extra 1 to each component, so that $(3,1) + (5,0)$ equals $(9,2)$ instead of $(8,1)$. With scalar multiplication unchanged, which rules are broken?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Show that the set of all positive real numbers, with $x+y$ and $cx$ redefined to equal the usual $xy$ and $x^c$, is a vector space. What is the \"zero vector\"?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $(x_1, x_2) + (y_1, y_2)$ is defined to be $(x_1 + y_2, x_2 + y_1)$. With the usual $cx = (cx_1, cx_2)$, which of the eight conditions are not satisfied?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Let $P$ be the plane in $\\mathbb{R}^3$ with equation $x + 2y + z = 6$. What is the equation of the plane $P_0$ through the origin parallel to $P$? Are $P$ and $P_0$ subspaces of $\\mathbb{R}^3$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which of the following are subspaces of $\\mathbb{R}^{\\infty}$?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "All sequences like $(1,0,1,0,...)$ that include infinitely many zeros."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All sequences $(x_1, x_2, ...)$ with $x_j = 0$ from some point onward."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All decreasing sequences: $x_{j+1} \\leq x_j$ for each $j$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All convergent sequences: the $x_j$ have a limit as $j \\to \\infty$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All arithmetic progressions: $x_{j+1} - x_j$ is the same for all $j$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All geometric progressions $(x_1, kx_1, k^2x_1, ...)$ allowing all $k$ and $x_1$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which of the following descriptions are correct? The solutions $x$ of\n    \\[\n    A x = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n    \\]\n    form\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "a plane."
    },
    {
        "chapter": "Vector Spaces",
        "question": "a line."
    },
    {
        "chapter": "Vector Spaces",
        "question": "a point."
    },
    {
        "chapter": "Vector Spaces",
        "question": "a subspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "the nullspace of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "the column space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Show that the set of nonsingular $2 \\times 2$ matrices is not a vector space. Show also that the set of singular $2 \\times 2$ matrices is not a vector space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The matrix $A = \\begin{pmatrix} 2 & -2 \\\\ 2 & -2 \\end{pmatrix}$ is a \"vector\" in the space $M$ of all $2 \\times 2$ matrices. Write the zero vector in this space, the vector $\\frac{1}{2} A$, and the vector $-A$. What matrices are in the smallest subspace containing $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe a subspace of $M$ that contains $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ but not $B = \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If a subspace of $M$ contains $A$ and $B$, must it contain $I$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe a subspace of $M$ that contains no nonzero diagonal matrices."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The functions $f(x) = x^2$ and $g(x) = 5x$ are ``vectors'' in the vector space $F$ of all real functions. The combination $3 f(x)-4g(x)$ is the function $h(x) =$. Which rule is broken if multiplying $f(x)$ by $c$ gives the function $f(cx)$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the sum of the ``vectors'' $f(x)$ and $g(x)$ in $F$ is defined to be $f(g(x))$, then the ``zero vector'' is $g(x) = x$. Keep the usual scalar multiplication $c f(x)$, and find two rules that are broken."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the smallest subspace of the $2 \\times 2$ matrix space $M$ that contains\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ and $\\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ and $\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $\\begin{bmatrix} 0 & 1 \\\\ 0 & 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Let $P$ be the plane in $\\mathbb{R}^3$ with equation $x + y - 2z = 4$. The origin $(0,0,0)$ is not in $P$! Find two vectors in $P$ and check that their sum is not in $P$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$P_0$ is the plane through $(0,0,0)$ parallel to the plane $P$ in Problem 15. What is the equation for $P_0$? Find two vectors in $P_0$ and check that their sum is in $P_0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The four types of subspaces of $\\mathbb{R}^3$ are planes, lines, $\\mathbb{R}^3$ itself, or $Z$ containing only $(0,0,0)$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the three types of subspaces of $\\mathbb{R}^2$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the five types of subspaces of $\\mathbb{R}^4$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The intersection of two planes through $(0,0,0)$ is probably a \\underline{ } but it could be a \\underline{ }. It can\u2019t be the zero vector $Z$!"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The intersection of a plane through $(0,0,0)$ with a line through $(0,0,0)$ is probably a \\underline{ } but it could be a \\underline{ }."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $S$ and $T$ are subspaces of $\\mathbb{R}^5$, their intersection $S \\cap T$ (vectors in both subspaces) is a subspace of $\\mathbb{R}^5$. Check the requirements on $x+y$ and $cx$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $P$ is a plane through $(0,0,0)$ and $L$ is a line through $(0,0,0)$. The smallest vector space containing both $P$ and $L$ is either \\underline{ } or \\underline{ }."
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false for $M =$ all $3 \\times 3$ matrices (check addition using an example)?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The skew-symmetric matrices in $M$ (with $A^T = -A$) form a subspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The unsymmetric matrices in $M$ (with $A^T \\neq A$) form a subspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The matrices that have $(1,1,1)$ in their nullspace form a subspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the column spaces (lines or planes) of these particular matrices:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 \\\\ 0 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad \n        B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\\\ 0 & 0 \\end{bmatrix}, \\quad \n        C = \\begin{bmatrix} 1 & 0 \\\\ 2 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which right-hand sides (find a condition on $b_1, b_2, b_3$) are these systems solvable?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 4 & 2 \\\\ 2 & 8 & 4 \\\\ -1 & -4 & -2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}.$"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 4 \\\\ 2 & 9 \\\\ -1 & -4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}.$"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Adding row 1 of $A$ to row 2 produces $B$. Adding column 1 to column 2 produces $C$.\n    A combination of the columns of one matrix is also a combination of the columns of another.\n    Which two matrices have the same column space?\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix} 1 & 3 \\\\ 2 & 6 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which vectors $(b_1, b_2, b_3)$ do these systems have a solution?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\[\n        \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix}\n        \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} =\n        \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\[\n        \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 0 \\end{bmatrix}\n        \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} =\n        \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "(Recommended) If we add an extra column $b$ to a matrix $A$, then the column space\n    gets larger unless . Give an example in which the column space gets larger and\n    an example in which it doesn\u2019t. Why is $Ax = b$ solvable exactly when the column\n    space doesn\u2019t get larger by including $b$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the smallest subspace of the $2 \\times 2$ matrix space $M$ that contains:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ and $\\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ and $\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $\\begin{bmatrix} 0 & 1 \\\\ 0 & 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Let $P$ be the plane in $\\mathbb{R}^3$ given by $x + y - 2z = 4$. Find two vectors in $P$ and verify their sum is not in $P$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the equation of $P_0$, the plane through $(0,0,0)$ parallel to $P$. Find two vectors in $P_0$ and check that their sum is in $P_0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the types of subspaces:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Three types of subspaces in $\\mathbb{R}^2$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Five types of subspaces in $\\mathbb{R}^4$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the column spaces of these matrices:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 \\\\ 0 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad\n        B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\\\ 0 & 0 \\end{bmatrix}, \\quad\n        C = \\begin{bmatrix} 1 & 0 \\\\ 2 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which right-hand sides $(b_1, b_2, b_3)$ are these systems solvable?\n    \\begin{align*}\n        \\begin{bmatrix} 1 & 4 & 2 \\\\ 2 & 8 & 4 \\\\ -1 & -4 & -2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} &= \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix},\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Provide an example where the column spaces of $A$ and $AB$ are not equal."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is an invertible $8 \\times 8$ matrix, explain why its column space is $\\mathbb{R}^8$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false (provide counterexamples if false):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors $b$ not in $C(A)$ form a subspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $C(A)$ contains only the zero vector, then $A$ is the zero matrix."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of $2A$ equals the column space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of $A-I$ equals the column space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a $3 \\times 3$ matrix whose column space contains $(1,1,0)$ and $(1,0,1)$ but not $(1,1,1)$. Construct another matrix whose column space is only a line."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the $9 \\times 12$ system $Ax = b$ is solvable for every $b$, what is $C(A)$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Why isn\u2019t $\\mathbb{R}^2$ a subspace of $\\mathbb{R}^3$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a system with more unknowns than equations, but no solution. Change the right-hand side to zero and find all solutions $x_n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Reduce $A$ and $B$ to echelon form, to find their ranks. Which variables are free?\n    \\[\n    A = \\begin{bmatrix}\n        1 & 2 & 0 & 1 \\\\\n        0 & 1 & 1 & 0 \\\\\n        1 & 2 & 0 & 1\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n        1 & 2 & 3 \\\\\n        4 & 5 & 6 \\\\\n        7 & 8 & 9\n    \\end{bmatrix}\n    \\]\n    Find the special solutions to $Ax = 0$ and $Bx = 0$. Find all solutions."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the echelon form $U$, the free variables, and the special solutions:\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 0 & 3 \\\\ 0 & 2 & 0 & 6 \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n    \\]\n    The system $Ax = b$ is consistent (has a solution) when $b$ satisfies $b_2 = \\; ?$ Find the complete solution.\nFind two vectors in the nullspace of A, and the complete solution to Ax = b.\n9. (a) Find the special solutions to Ux = 0. Reduce U to R and repeat:\nUx =\n\uf8ee\n\uf8ef\n\uf8f0\n1 2 3 4\n0 0 1 2\n0 0 0 0\n\uf8f9\n\uf8fa\n\uf8fb\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f0\nx1\nx2\nx3\nx4\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n=\n\uf8ee\n\uf8ef\n\uf8f0\n0\n0\n0\n\uf8f9\n\uf8fa\n\uf8fb.\n(b) If the right-hand side is changed from (0,0,0) to (a,b,0), what are all solutions?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a system with more unknowns than equations, but no solution. Change the right-hand side to zero and find all solutions $x_n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Reduce $A$ and $B$ to echelon form, to find their ranks. Which variables are free?\n    \\[\n    A = \\begin{bmatrix}\n        1 & 2 & 0 & 1 \\\\\n        0 & 1 & 1 & 0 \\\\\n        1 & 2 & 0 & 1\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n        1 & 2 & 3 \\\\\n        4 & 5 & 6 \\\\\n        7 & 8 & 9\n    \\end{bmatrix}.\n    \\]\n    Find the special solutions to $Ax = 0$ and $Bx = 0$. Find all solutions."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the echelon form $U$, the free variables, and the special solutions:\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 0 & 3 \\\\ 0 & 2 & 0 & 6 \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n    \\]\n    $Ax = b$ is consistent (has a solution) when $b$ satisfies $b_2 = \\ldots$. Find the complete solution in the same form as equation (4)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Carry out the same steps as in the previous problem to find the complete solution of $Mx = b$:\n    \\[\n    M = \\begin{bmatrix} 0 & 0 \\\\ 1 & 2 \\\\ 0 & 0 \\\\ 3 & 6 \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write the complete solutions $x = x_p + x_n$ to these systems, as in equation (4):\n    \\[\n    \\begin{bmatrix} 1 & 2 & 2 \\\\ 2 & 4 & 5 \\end{bmatrix}\n    \\begin{bmatrix} u \\\\ v \\\\ w \\end{bmatrix} =\n    \\begin{bmatrix} 1 \\\\ 4 \\end{bmatrix},\n    \\]\n    \\[\n    \\begin{bmatrix} 1 & 2 & 2 \\\\ 2 & 4 & 4 \\end{bmatrix}\n    \\begin{bmatrix} u \\\\ v \\\\ w \\end{bmatrix} =\n    \\begin{bmatrix} 1 \\\\ 4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the set of attainable right-hand sides $b$ (in the column space) for\n    \\[\n    \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 3 \\end{bmatrix}\n    \\begin{bmatrix} u \\\\ v \\end{bmatrix} =\n    \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix},\n    \\]\n    by finding the constraints on $b$ that turn the third equation into $0 = 0$ (after elimination). What is the rank, and a particular solution?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the value of $c$ that makes it possible to solve $Ax = b$, and solve it:\n    \\begin{align*}\n    u + v + 2w &= 2, \\\\\n    2u + 3v - w &= 5, \\\\\n    3u + 4v + w &= c.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Under what conditions on $b_1$ and $b_2$ (if any) does $Ax = b$ have a solution?\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 0 & 3 \\\\ 2 & 4 & 0 & 7 \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a $2 \\times 3$ system $Ax = b$ whose complete solution is\n    \\begin{equation*}\n        x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0 \\end{bmatrix} + w \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix}.\n    \\end{equation*}\n    Find a $3 \\times 3$ system with these solutions exactly when $b_1 + b_2 = b_3$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write a $2 \\times 2$ system $Ax = b$ with many solutions $x_n$ but no solution $x_p$. (Therefore, the system has no solution.) Which $b$'s allow an $x_p$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which of these rules give a correct definition of the rank of $A$?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of nonzero rows in $R$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of columns minus the total number of rows."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of columns minus the number of free columns."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of 1s in $R$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the reduced row echelon forms $R$ and the rank of these matrices:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $3 \\times 4$ matrix of all 1s."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $4 \\times 4$ matrix with $a_{ij} = (-1)^{ij}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $3 \\times 4$ matrix with $a_{ij} = (-1)^j$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find $R$ for each of these (block) matrices, and the special solutions:\n    \\begin{equation*}\n        A = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix}, \\quad\n        B = \\begin{bmatrix} A & A \\end{bmatrix}, \\quad\n        C = \\begin{bmatrix} A & A \\\\ A & 0 \\end{bmatrix}.\n    \\end{equation*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the $r$ pivot variables come first, the reduced $R$ must look like\n    \\begin{equation*}\n        R = \\begin{bmatrix} I & F \\\\ 0 & 0 \\end{bmatrix},\n    \\end{equation*}\n    where $I$ is $r \\times r$ and $F$ is $r \\times (n-r)$. What is the nullspace matrix $N$ containing the special solutions?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose all $r$ pivot variables come last. Describe the four blocks in the $m \\times n$ reduced echelon form (the block $B$ should be $r \\times r$):\n    \\begin{equation*}\n        R = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}.\n    \\end{equation*}\n    What is the nullspace matrix $N$ of special solutions? What is its shape?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "(Silly problem) Describe all $2 \\times 3$ matrices $A_1$ and $A_2$ with row echelon forms $R_1$ and $R_2$, such that $R_1 + R_2$ is the row echelon form of $A_1 + A_2$. Is it true that $R_1 = A_1$ and $R_2 = A_2$ in this case?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ has $r$ pivot columns, then $A^T$ has $r$ pivot columns. Give a $3 \\times 3$ example for which the column numbers are different for $A$ and $A^T$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a system with more unknowns than equations, but no solution. Change the right-hand side to zero and find all solutions $x_n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Reduce $A$ and $B$ to echelon form, to find their ranks. Which variables are free?\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 2 & 0 & 1 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}.\n    \\]\n    Find the special solutions to $Ax = 0$ and $Bx = 0$. Find all solutions."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the echelon form $U$, the free variables, and the special solutions:\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 0 & 3 \\\\ 0 & 2 & 0 & 6 \\end{bmatrix}, \\quad b = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$Ax = b$ is consistent (has a solution) when $b$ satisfies $b_2 = $. Find the complete solution in the same form as equation (4)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Carry out the same steps as in the previous problem to find the complete solution of $Mx = b$:\n    \\[\n    M = \\begin{bmatrix} 0 & 0 \\\\ 1 & 2 \\\\ 0 & 0 \\\\ 3 & 6 \\end{bmatrix}, \\quad b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a $2 \\times 3$ system $Ax = b$ whose complete solution is:\n    \\[\n    x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0 \\end{bmatrix} + w \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a $3 \\times 3$ system with these solutions exactly when $b_1 + b_2 = b_3$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write a $2 \\times 2$ system $Ax = b$ with many solutions $x_n$ but no solution $x_p$. Which $b$\u2019s allow an $x_p$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which of these rules give a correct definition of the rank of $A$?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of nonzero rows in $R$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of columns minus the total number of rows."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of columns minus the number of free columns."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The number of 1s in $R$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the reduced row echelon forms $R$ and the rank of these matrices:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $3 \\times 4$ matrix of all 1s."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $4 \\times 4$ matrix with $a_{ij} = (-1)^{ij}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $3 \\times 4$ matrix with $a_{ij} = (-1)^j$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the ranks of $AB$ and $AM$ (rank 1 matrix times rank 1 matrix):\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} 2 & 1 & 4 \\\\ 3 & 1.5 & 6 \\end{bmatrix}, \\quad\n    M = \\begin{bmatrix} 1 & b \\\\ c & bc \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $A$ and $B$ have the same reduced-row echelon form $R$. Explain how to change $A$ to $B$ by elementary row operations."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Every $m \\times n$ matrix of rank $r$ reduces to $(m \\times r)$ times $(r \\times n)$:\n    \\[\n    A = (\\text{pivot columns of } A)(\\text{first } r \\text{ rows of } R) = (\\text{COL})(\\text{ROW}).\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write the $3 \\times 4$ matrix $A$ as the product of a $3 \\times 2$ matrix from the pivot columns and a $2 \\times 4$ matrix from $R$:\n    \\[\n    A = \\begin{bmatrix} 1 & 3 & 3 & 2 \\\\ 2 & 6 & 9 & 7 \\\\ -1 & -3 & 3 & 4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $A$ is an $m \\times n$ matrix of rank $r$. Its reduced echelon form is $R$. Describe exactly the reduced row echelon form of $R^T$ (not $A^T$)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Execute the six steps following equation (6) to find the column space and null space of $A$ and the solution to $Ax = b$:\n    \\[\n    A = \\begin{bmatrix} 2 & 4 & 6 & 4 \\\\ 2 & 5 & 7 & 6 \\\\ 2 & 3 & 5 & 2 \\end{bmatrix}, \\quad b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 3 \\\\ 5 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For every $c$, find $R$ and the special solutions to $Ax = 0$:\n    \\[\n    A = \\begin{bmatrix} 1 & 1 & 2 & 2 \\\\ 2 & 2 & 4 & 4 \\\\ 1 & c & 2 & 2 \\end{bmatrix}, \\quad A = \\begin{bmatrix} 1-c & 2 \\\\ 0 & 2-c \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the null space matrix $N$ (of special solutions) for $A$, $B$, $C$?\n    \\[\n    A = \\begin{bmatrix} I & I \\end{bmatrix}, \\quad B = \\begin{bmatrix} I & I \\\\ 0 & 0 \\end{bmatrix}, \\quad C = \\begin{bmatrix} I & I & I \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the complete solutions of:\n    \\[\n    x + 3y + 3z = 1, \\quad 2x + 6y + 9z = 5, \\quad -x - 3y + 3z = 5.\n    \\]\n    \\[\n    \\begin{bmatrix} 1 & 3 & 1 & 2 \\\\ 2 & 6 & 4 & 8 \\\\ 0 & 0 & 2 & 4 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\\\ t \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Under what condition on $b_1, b_2, b_3$ is the following system solvable? Include $b$ as a fourth column in $[A | b]$. Find all solutions when that condition holds:\n    \\[\n    \\begin{aligned}\n    x + 2y - 2z &= b_1 \\\\\n    2x + 5y - 4z &= b_2 \\\\\n    4x + 9y - 8z &= b_3.\n    \\end{aligned}\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What conditions on $b_1, b_2, b_3, b_4$ make each system solvable? Solve for $x$:\n    \\[\n    \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\\\ 2 & 5 \\\\ 3 & 9 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}, \\quad \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\\\ 2 & 5 & 7 \\\\ 3 & 9 & 12 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the special solutions to $Rx = 0$ and $R^T y = 0$ for:\n    \\begin{align*}\n        R &= \\begin{bmatrix} 1 & 0 & 2 & 3 \\\\ 0 & 1 & 4 & 5 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix},\n        &R &= \\begin{bmatrix} 0 & 1 & 2 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find an $r \\times r$ invertible submatrix $S$ from the pivot rows and columns of each $A$:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 & 3 \\\\ 1 & 2 & 4 \\end{bmatrix},\n        &A &= \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix},\n        &A &= \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Explain why the pivot rows and columns always give an invertible submatrix."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the ranks of $AB$ and $AM$ for:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix},\n        &B &= \\begin{bmatrix} 2 & 1 & 4 \\\\ 3 & 1.5 & 6 \\end{bmatrix},\n        &M &= \\begin{bmatrix} 1 & b \\\\ c & bc \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Prove that $\\text{rank}(AB) \\leq \\text{rank}(B)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $A$ and $B$ are $n \\times n$ matrices and $AB = I$. Prove that $A$ is invertible."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is $2 \\times 3$ and $C$ is $3 \\times 2$, show that $CA \\neq I$. Give an example where $AC = I$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $A$ and $B$ have the same reduced row echelon form $R$. Explain how $A$ can be transformed into $B$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the complete solution to:\n    \\begin{align*}\n        x + 3y + 3z &= 1 \\\\\n        2x + 6y + 9z &= 5 \\\\\n        -x - 3y + 3z &= 5.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For what conditions on $b_1, b_2, b_3$ is the following system solvable?\n    \\begin{align*}\n        x + 2y - 2z &= b_1 \\\\\n        2x + 5y - 4z &= b_2 \\\\\n        4x + 9y - 8z &= b_3.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which vectors $(b_1, b_2, b_3)$ are in the column space of $A$?\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 6 & 3 \\\\ 0 & 2 & 5 \\end{bmatrix},\n        &A &= \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 4 \\\\ 2 & 4 & 8 \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Explain why the following statements are false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The complete solution is any linear combination of $x_p$ and $x_n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "A system $Ax = b$ has at most one particular solution."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The solution $x_p$ with all free variables zero is the shortest solution."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is invertible, there is no solution $x_n$ in the null space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose column 5 of $U$ has no pivot. Determine if the zero vector is the only solution to $Ax = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find $x_p$ and all special solutions for:\n    \\begin{align*}\n        Ax &= 2b, & \\begin{bmatrix} A & A \\end{bmatrix} \\begin{bmatrix} x \\\\ X \\end{bmatrix} &= b.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the values of $q$ for which the rank conditions hold:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 6 & 4 & 2 \\\\ -3 & -2 & -1 \\\\ 9 & 6 & q \\end{bmatrix},\n        &B &= \\begin{bmatrix} 3 & 1 & 3 \\\\ q & 2 & q \\end{bmatrix}.\n    \\end{align*}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Give examples of matrices $A$ for which the number of solutions to $Ax = b$ is:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "0 or 1, depending on $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Infinite, regardless of $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "0 or infinite, depending on $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "1, regardless of $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write all known relations between $r$, $m$, and $n$ if $Ax = b$ has\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "no solution for some $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "infinitely many solutions for every $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "exactly one solution for some $b$, no solution for other $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "exactly one solution for every $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Apply Gauss-Jordan elimination (right-hand side becomes extra column) to $Ux = 0$ and $Ux = c$. Reach $Rx = 0$ and $Rx = d$:\n    \\[\n    \\begin{bmatrix} 1 & 2 & 3 & 0 \\\\ 0 & 0 & 4 & 0 \\end{bmatrix},\n    \\quad \\begin{bmatrix} 1 & 2 & 3 & 5 \\\\ 0 & 0 & 4 & 8 \\end{bmatrix}\n    \\]\n    Solve $Rx = 0$ to find $x_n$ (free variable $x_2 = 1$). Solve $Rx = d$ to find $x_p$ (free variable $x_2 = 0$)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Apply elimination with the extra column to reach $Rx = 0$ and $Rx = d$:\n    \\[\n    \\begin{bmatrix} 3 & 0 & 6 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix},\n    \\quad \\begin{bmatrix} 3 & 0 & 6 & 9 \\\\ 0 & 0 & 2 & 4 \\\\ 0 & 0 & 0 & 5 \\end{bmatrix}\n    \\]\n    Solve $Rx = 0$ (free variable = 1). What are the solutions to $Rx = d$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Reduce to $Ux = c$ (Gaussian elimination) and then $Rx = d$:\n    \\[\n    \\begin{bmatrix} 1 & 0 & 2 & 3 \\\\ 1 & 3 & 2 & 0 \\\\ 2 & 0 & 4 & 9 \\end{bmatrix}\n    \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} =\n    \\begin{bmatrix} 2 \\\\ 5 \\\\ 10 \\end{bmatrix} = b\n    \\]\n    Find a particular solution $x_p$ and all nullspace solutions $x_n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find $A$ and $B$ with the given property or explain why you can\u2019t.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The only solution to $Ax = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ is $x = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The only solution to $Bx = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ is $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The complete solution to $Ax = \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix}$ is $x = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + c \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$. Find $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The nullspace of a $3 \\times 4$ matrix $A$ is the line through $(2,3,1,0)$.\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the rank of $A$ and the complete solution to $Ax = 0$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the exact row reduced echelon form $R$ of $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Reduce these matrices $A$ and $B$ to their ordinary echelon forms $U$:\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$A = \\begin{bmatrix} 1 & 2 & 2 & 4 & 6 \\\\ 1 & 2 & 3 & 6 & 9 \\\\ 0 & 0 & 1 & 2 & 3 \\end{bmatrix}$"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$B = \\begin{bmatrix} 2 & 4 & 2 \\\\ 0 & 4 & 4 \\\\ 0 & 8 & 8 \\end{bmatrix}$"
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or False? (Give reason if true, or counterexample to show it is false.)\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "A square matrix has no free variables."
    },
    {
        "chapter": "Vector Spaces",
        "question": "An invertible matrix has no free variables."
    },
    {
        "chapter": "Vector Spaces",
        "question": "An $m \\times n$ matrix has no more than $n$ pivot variables."
    },
    {
        "chapter": "Vector Spaces",
        "question": "An $m \\times n$ matrix has no more than $m$ pivot variables."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Is there a $3 \\times 3$ matrix with no zero entries for which $U = R = I$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Put as many $1$s as possible in a $4 \\times 7$ echelon matrix $U$ and in a reduced form $R$ whose pivot columns are $2, 4, 5$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose column 4 of a $3 \\times 5$ matrix is all 0s. Then $x_4$ is certainly a variable. The special solution for this variable is the vector $x = \\begin{bmatrix} ? \\\\ ? \\\\ ? \\\\ 1 \\\\ 0 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose the first and last columns of a $3 \\times 5$ matrix are the same (nonzero). Then $x_5$ is a free variable. Find the special solution for this variable."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The equation $x -3y - z = 0$ determines a plane in $\\mathbb{R}^3$. What is the matrix $A$ in this equation? Which are the free variables? The special solutions are $(3,1,0)$ and $(-1,0,1)$. The parallel plane $x-3y-z = 12$ contains the particular point $(12,0,0)$. All points on this plane have the following form:\n\\[\n\\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 0 \\\\ 0 \\end{bmatrix} + y \\begin{bmatrix} 3 \\\\ 1 \\\\ 0 \\end{bmatrix} + z \\begin{bmatrix} -1 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n\\]\n  % Question 59"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose column 1 + column 3 + column 5 = 0 in a $4 \\times 5$ matrix with four pivots. \nWhich column is sure to have no pivot (and which variable is free)? What is the special solution? What is the nullspace?\n\n% Question 60 - 66"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose nullspace consists of all combinations of $\\begin{bmatrix}2 \\\\ 2 \\\\ 1 \\\\ 0 \\end{bmatrix}$ and $\\begin{bmatrix}3 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose nullspace consists of all multiples of $\\begin{bmatrix}4 \\\\ 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose column space contains $\\begin{bmatrix}1 \\\\ 1 \\\\ 5 \\end{bmatrix}$ and $\\begin{bmatrix}0 \\\\ 3 \\\\ 1 \\end{bmatrix}$ and whose nullspace contains $\\begin{bmatrix}1 \\\\ 1 \\\\ 2 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose column space contains $\\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\end{bmatrix}$ and $\\begin{bmatrix}0 \\\\ 1 \\\\ 1 \\end{bmatrix}$ and whose nullspace contains $\\begin{bmatrix}1 \\\\ 0 \\\\ 1 \\end{bmatrix}$ and $\\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose column space contains $\\begin{bmatrix}1 \\\\ 1 \\\\ 1 \\end{bmatrix}$ and whose nullspace is the line of multiples of $\\begin{bmatrix}1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a $2 \\times 2$ matrix whose nullspace equals its column space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Why does no $3 \\times 3$ matrix have a nullspace that equals its column space?\n\n% Question 67"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The reduced form $R$ of a $3 \\times 3$ matrix with randomly chosen entries is almost sure to be\\dots What $R$ is virtually certain if the random $A$ is $4 \\times 3$?\n\n% Question 68"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Show by example that these three statements are generally false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$A$ and $A^T$ have the same nullspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$A$ and $A^T$ have the same free variables."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $R$ is the reduced form $\\text{rref}(A)$ then $R^T$ is $\\text{rref}(A^T)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the special solutions to $Rx = 0$ are in the columns of these $N$, go backward to find the nonzero rows of the reduced matrices $R$:\n    \\[ N = \\begin{bmatrix} 2 & 3 \\\\ 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\quad N = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\quad N = \\begin{bmatrix} \\end{bmatrix} \\text{ (empty } 3 \\times 1 \\text{)}. \\]\n\n% Question 70"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Explain why $A$ and $-A$ always have the same reduced echelon form $R$.\n\n\n   Question 1"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Show that the vectors $v_1$, $v_2$, and $v_3$ are independent, but the vectors $v_1$, $v_2$, $v_3$, and $v_4$ are dependent. Solve the equation $c_1 v_1 + c_2 v_2 + c_3 v_3 + c_4 v_4 = 0$ (or equivalently, $Ac = 0$), where the vectors are the columns of the matrix $A$.\n\n\\[\nv_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad \nv_2 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad\nv_3 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad\nv_4 = \\begin{bmatrix} 2 \\\\ 3 \\\\ 4 \\end{bmatrix}\n\\]\n\n% Question 2"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the largest possible number of independent vectors among the following:\n\n\\[\nv_1 = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad\nv_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 0 \\end{bmatrix}, \\quad\nv_3 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ -1 \\end{bmatrix}, \\quad\nv_4 = \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{bmatrix}, \\quad\nv_5 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ -1 \\end{bmatrix}, \\quad\nv_6 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -1 \\end{bmatrix}\n\\]\n\nThis number is the dimension of the space spanned by these vectors.\n\n% Question 3"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Prove that if $a = 0$, $d = 0$, or $f = 0$ (in the three cases), the columns of the matrix $U$ are dependent. Given:\n\n\\[\nU = \\begin{bmatrix} \na & b & c \\\\\n0 & d & e \\\\\n0 & 0 & f \n\\end{bmatrix}\n\\]\n    % Question 4"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $a$, $d$, and $f$ in Problem 3 are all nonzero, show that the only solution to $U x = 0$ is $x = 0$. Then $U$ has independent columns."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Decide the dependence or independence of the following sets of vectors:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors $(1, 3, 2)$, $(2, 1, 3)$, and $(3, 2, 1)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors $(1, -3, 2)$, $(2, 1, -3)$, and $(-3, 2, 1)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Choose three independent columns of $U$. Then make two other choices. Do the same for $A$. You have found bases for which spaces?\n\\[\nU = \\begin{bmatrix}\n2 & 3 & 4 & 1 \\\\\n0 & 6 & 7 & 0 \\\\\n0 & 0 & 0 & 9 \\\\\n0 & 0 & 0 & 0\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n2 & 3 & 4 & 1 \\\\\n0 & 6 & 7 & 0 \\\\\n0 & 0 & 0 & 9 \\\\\n4 & 6 & 8 & 2\n\\end{bmatrix}\n\\]\n\n% Question 7"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $w_1$, $w_2$, $w_3$ are independent vectors, show that the differences $v_1 = w_2 - w_3$, $v_2 = w_1 - w_3$, and $v_3 = w_1 - w_2$ are dependent. Find a combination of the $v$'s that gives zero.\n\n% Question 8"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $w_1$, $w_2$, $w_3$ are independent vectors, show that the sums $v_1 = w_2 + w_3$, $v_2 = w_1 + w_3$, and $v_3 = w_1 + w_2$ are independent. (Write $c_1 v_1 + c_2 v_2 + c_3 v_3 = 0$ in terms of the $w$'s. Find and solve equations for the $c$'s.)\n\n% Question 9"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $v_1$, $v_2$, $v_3$, and $v_4$ are vectors in $\\mathbb{R}^3$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "These four vectors are dependent because \\underline{\\hspace{5cm}}."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The two vectors $v_1$ and $v_2$ will be dependent if \\underline{\\hspace{5cm}}."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors $v_1$ and $(0, 0, 0)$ are dependent because \\underline{\\hspace{5cm}}."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find two independent vectors on the plane $x + 2y - 3z - t = 0$ in $\\mathbb{R}^4$. Then find three independent vectors. Why not four? This plane is the nullspace of what matrix?\n\n% Problems 11\u201318 are about the space spanned by a set of vectors.\n\n% Question 11"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the subspace of $\\mathbb{R}^3$ (is it a line, a plane, or $\\mathbb{R}^3$?) spanned by the following vectors:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The two vectors $(1, 1, -1)$ and $(-1, -1, 1)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The three vectors $(0, 1, 1)$, $(1, 1, 0)$, and $(0, 0, 0)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The columns of a $3 \\times 5$ echelon matrix with 2 pivots."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All vectors with positive components."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vector $b$ is in the subspace spanned by the columns of $A$ when there is a solution to \\underline{\\hspace{5cm}}. The vector $c$ is in the row space of $A$ when there is a solution to \\underline{\\hspace{5cm}}. True or false: If the zero vector is in the row space, the rows are dependent. \\underline{\\hspace{5cm}}\n\n% Question 13"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the dimensions of the following spaces:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of $U$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The row space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The row space of $U$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Choose \\( x = (x_1, x_2, x_3, x_4) \\) in \\( \\mathbb{R}^4 \\). It has 24 rearrangements like \\( (x_2, x_1, x_3, x_4) \\) and \\( (x_4, x_3, x_1, x_2) \\). Those 24 vectors, including \\( x \\) itself, span a subspace \\( S \\). Find specific vectors \\( x \\) so that the dimension of \\( S \\) is:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "0"
    },
    {
        "chapter": "Vector Spaces",
        "question": "1"
    },
    {
        "chapter": "Vector Spaces",
        "question": "3"
    },
    {
        "chapter": "Vector Spaces",
        "question": "4"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( v + w \\) and \\( v - w \\) are combinations of \\( v \\) and \\( w \\). Write \\( v \\) and \\( w \\) as combinations of \\( v + w \\) and \\( v - w \\). The two pairs of vectors span the same space. When are they a basis for the same space?\n\n% Question 16"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Decide whether or not the following vectors are linearly independent, by solving \\( c_1 v_1 + c_2 v_2 + c_3 v_3 + c_4 v_4 = 0 \\):\n    \\[\n    v_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \n    v_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \n    v_3 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}, \n    v_4 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n    \\]\n    Decide also if they span \\( \\mathbb{R}^4 \\), by trying to solve \\( c_1 v_1 + \\dots + c_4 v_4 = (0, 0, 0, 1) \\).\n\n% Question 17"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose the vectors to be tested for independence are placed into the rows instead of the columns of \\( A \\). How does the elimination process from \\( A \\) to \\( U \\) decide for or against independence?\n\n% Question 18"
    },
    {
        "chapter": "Vector Spaces",
        "question": "To decide whether \\( b \\) is in the subspace spanned by \\( w_1, \\dots, w_n \\), let the vectors \\( w \\) be the columns of \\( A \\) and try to solve \\( A x = b \\). What is the result for:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( w_1 = (1, 1, 0), w_2 = (2, 2, 1), w_3 = (0, 0, 2), b = (3, 4, 5) \\)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( w_1 = (1, 2, 0), w_2 = (2, 5, 0), w_3 = (0, 0, 2), w_4 = (0, 0, 0), \\) and any \\( b \\)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If \\( v_1, \\dots, v_n \\) are linearly independent, the space they span has dimension \\_\\_\\_. These vectors are a \\_\\_\\_ for that space. If the vectors are the columns of an \\( m \\times n \\) matrix, then \\( m \\) is \\_\\_\\_ than \\( n \\).\n\n% Question 20"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for each of these subspaces of \\( \\mathbb{R}^4 \\):\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "All vectors whose components are equal."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All vectors whose components add to zero."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All vectors that are perpendicular to \\( (1,1,0,0) \\) and \\( (1,0,1,1) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space (in \\( \\mathbb{R}^2 \\)) and null space (in \\( \\mathbb{R}^5 \\)) of  \n        \\[\n        U =\n        \\begin{bmatrix}\n        1 & 0 & 1 & 0 & 1 \\\\\n        0 & 1 & 0 & 1 & 0\n        \\end{bmatrix}.\n        \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find three different bases for the column space of \\( U \\) above. Then find two different bases for the row space of \\( U \\).\n\n% Question 22"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose \\( v_1, v_2, \\dots, v_6 \\) are six vectors in \\( \\mathbb{R}^4 \\).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Those vectors (do)(do not)(might not) span \\( \\mathbb{R}^4 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Those vectors (are)(are not)(might be) linearly independent."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Any four of those vectors (are)(are not)(might be) a basis for \\( \\mathbb{R}^4 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If those vectors are the columns of \\( A \\), then \\( Ax = b \\) (has) (does not have) (might not have) a solution."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The columns of \\( A \\) are \\( n \\) vectors from \\( \\mathbb{R}^m \\). If they are linearly independent, what is the rank of \\( A \\)? If they span \\( \\mathbb{R}^m \\), what is the rank? If they are a basis for \\( \\mathbb{R}^m \\), what then?\n\n% Question 24"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the plane \\( x - 2y + 3z = 0 \\) in \\( \\mathbb{R}^3 \\). Then find a basis for the intersection of that plane with the \\( xy \\)-plane. Then find a basis for all vectors perpendicular to the plane.\n\n% Question 25"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose the columns of a \\( 5 \\times 5 \\) matrix \\( A \\) are a basis for \\( \\mathbb{R}^5 \\).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The equation \\( Ax = 0 \\) has only the solution \\( x = 0 \\) because \\_\\_\\_."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If \\( b \\) is in \\( \\mathbb{R}^5 \\), then \\( Ax = b \\) is solvable because \\_\\_\\_."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose \\( S \\) is a five-dimensional subspace of \\( \\mathbb{R}^6 \\). True or false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Every basis for \\( S \\) can be extended to a basis for \\( \\mathbb{R}^6 \\) by adding one more vector."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Every basis for \\( \\mathbb{R}^6 \\) can be reduced to a basis for \\( S \\) by removing one vector."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( U \\) comes from \\( A \\) by subtracting row 1 from row 3:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 3 & 2 \\\\\n    0 & 1 & 1 \\\\\n    1 & 3 & 2\n    \\end{bmatrix},\n    \\quad\n    U =\n    \\begin{bmatrix}\n    1 & 3 & 2 \\\\\n    0 & 1 & 1 \\\\\n    0 & 0 & 0\n    \\end{bmatrix}.\n    \\]\n    Find bases for:\n    \\begin{itemize}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The two column spaces."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The two row spaces."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The two null spaces.\n    \\end{itemize}\n\n% Question 28"
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false (give a good reason)?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the columns of a matrix are dependent, so are the rows."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of a \\( 2 \\times 2 \\) matrix is the same as its row space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The column space of a \\( 2 \\times 2 \\) matrix has the same dimension as its row space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The columns of a matrix are a basis for the column space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which numbers \\( c \\) and \\( d \\) do these matrices have rank 2?\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 2 & 5 & 0 & 5 \\\\\n    0 & 0 & c & 2 & 2 \\\\\n    0 & 0 & 0 & d & 2\n    \\end{bmatrix}\n    \\]\n    and\n    \\[\n    B =\n    \\begin{bmatrix}\n    c & d \\\\\n    d & c\n    \\end{bmatrix}.\n    \\]\n  % Question 30"
    },
    {
        "chapter": "Vector Spaces",
        "question": "By locating the pivots, find a basis for the column space of\n    \\[\n    U =\n    \\begin{bmatrix}\n    0 & 5 & 4 & 3 \\\\\n    0 & 0 & 2 & 1 \\\\\n    0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0\n    \\end{bmatrix}.\n    \\]\n    Express each column that is not in the basis as a combination of the basic columns. Find also a matrix \\( A \\) with this echelon form \\( U \\), but a different column space.\n\n% Question 31"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a counterexample to the following statement: If \\( v_1, v_2, v_3, v_4 \\) is a basis for the vector space \\( \\mathbb{R}^4 \\), and if \\( W \\) is a subspace, then some subset of the \\( v \\)'s is a basis for \\( W \\).\n\n% Question 32"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the dimensions of these vector spaces:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The space of all vectors in \\( \\mathbb{R}^4 \\) whose components add to zero."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The nullspace of the \\( 4 \\times 4 \\) identity matrix."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The space of all \\( 4 \\times 4 \\) matrices."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose \\( V \\) is known to have dimension \\( k \\). Prove that:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Any \\( k \\) independent vectors in \\( V \\) form a basis."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Any \\( k \\) vectors that span \\( V \\) form a basis."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Prove that if \\( V \\) and \\( W \\) are three-dimensional subspaces of \\( \\mathbb{R}^5 \\), then \\( V \\) and \\( W \\) must have a nonzero vector in common. \n\n\\textbf{Hint}: Start with bases for the two subspaces, making six vectors in all.  \n    % Question 35"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{True or false?}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the columns of \\( A \\) are linearly independent, then \\( Ax = b \\) has exactly one solution for every \\( b \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "A \\( 5 \\times 7 \\) matrix never has linearly independent columns."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If \\( A \\) is a \\( 64 \\times 17 \\) matrix of rank 11, how many independent vectors satisfy \\( Ax = 0 \\)? How many independent vectors satisfy \\( A^T y = 0 \\)?\n\n% Question 37"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for each of these subspaces of \\( 3 \\times 3 \\) matrices:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "All diagonal matrices."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All symmetric matrices (\\( A^T = A \\))."
    },
    {
        "chapter": "Vector Spaces",
        "question": "All skew-symmetric matrices (\\( A^T = -A \\))."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Problems about function spaces:}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find all functions that satisfy \\( \\frac{dy}{dx} = 0 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Choose a particular function that satisfies \\( \\frac{dy}{dx} = 3 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find all functions that satisfy \\( \\frac{dy}{dx} = 3 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The cosine space \\( F_3 \\) contains all combinations \\( y(x) = A\\cos x + B\\cos 2x + C\\cos 3x \\). Find a basis for the subspace that has \\( y(0) = 0 \\).\n\n% Question 40"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the space of functions that satisfy:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( \\frac{dy}{dx} - 2y = 0 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( \\frac{dy}{dx} - \\frac{y}{x} = 0 \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose \\( y_1(x), y_2(x), y_3(x) \\) are three different functions of \\( x \\). The vector space they span could have dimension 1, 2, or 3. Give an example of \\( y_1, y_2, y_3 \\) to show each possibility.\n\n% Question 42"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the space of polynomials \\( p(x) \\) of degree \\( \\leq 3 \\). Find a basis for the subspace with \\( p(1) = 0 \\).\n\n% Question 43"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Write the \\( 3 \\times 3 \\) identity matrix as a combination of the other five permutation matrices. Then show that those five matrices are linearly independent. (Assume a combination gives zero, and check entries to prove each term is zero.) The five permutations are a basis for the subspace of \\( 3 \\times 3 \\) matrices with row and column sums all equal.\n    % Question 44"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Review: Which of the following are bases for \\( \\mathbb{R}^3 \\)?}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( (1,2,0) \\) and \\( (0,1,-1) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( (1,1,-1) \\), \\( (2,3,4) \\), \\( (4,1,-1) \\), \\( (0,1,-1) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( (1,2,2) \\), \\( (-1,2,1) \\), \\( (0,8,0) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( (1,2,2) \\), \\( (-1,2,1) \\), \\( (0,8,6) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Review: Suppose \\( A \\) is \\( 5 \\times 4 \\) with rank 4.}  \nShow that \\( Ax = b \\) has no solution when the \\( 5 \\times 5 \\) matrix \\( [A \\; b] \\) is invertible.  \nShow that \\( Ax = b \\) is solvable when \\( [A \\; b] \\) is singular.\n\n    % Question 1"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{True or False:}  \nIf \\( m = n \\), then the row space of \\( A \\) equals the column space.  \nIf \\( m < n \\), then the null space has a larger dimension than \\(\\dots\\).\n\n% Question 2"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the dimension and construct a basis for the four subspaces associated with the matrices:}\n\\[\nA =\n\\begin{bmatrix}\n0 & 1 & 4 & 0 \\\\\n0 & 2 & 8 & 0\n\\end{bmatrix}\n\\]\n\\[\nU =\n\\begin{bmatrix}\n0 & 1 & 4 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{bmatrix}\n\\]\n\n% Question 3"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the dimension and a basis for the four fundamental subspaces for:}\n\\[\nA =\n\\begin{bmatrix}\n1 & 2 & 0 & 1 \\\\\n0 & 1 & 1 & 0 \\\\\n1 & 2 & 0 & 1\n\\end{bmatrix}\n\\]\n\\[\nU =\n\\begin{bmatrix}\n1 & 2 & 0 & 1 \\\\\n0 & 1 & 1 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{bmatrix}\n\\]\n\n% Question 4"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Describe the four subspaces in three-dimensional space associated with:}\n\\[\nA =\n\\begin{bmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix}\n\\]\n\n% Question 5"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If the product \\( AB \\) is the zero matrix, \\( AB = 0 \\), show that the column space of \\( B \\) is contained in the nullspace of \\( A \\).}  \n(Also, the row space of \\( A \\) is in the left nullspace of \\( B \\), since each row of \\( A \\) multiplies \\( B \\) to give a zero row.)\n\n% Question 6"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( A \\) is an \\( m \\times n \\) matrix of rank \\( r \\). Under what conditions do these hold?}\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( A \\) has a two-sided inverse: \\( AA^{-1} = A^{-1}A = I \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( Ax = b \\) has infinitely many solutions for every \\( b \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Why is there no matrix whose row space and nullspace both contain \\( (1,1,1) \\)?}\n\n% Question 8"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose the only solution to \\( Ax = 0 \\) (with \\( m \\) equations in \\( n \\) unknowns) is \\( x = 0 \\). What is the rank and why?}  \nThe columns of \\( A \\) are linearly \\(\\dots\\).\n\n% Question 9"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find a \\( 1 \\times 3 \\) matrix whose nullspace consists of all vectors in \\( \\mathbb{R}^3 \\) such that \\( x_1 + 2x_2 + 4x_3 = 0 \\).}  \nFind a \\( 3 \\times 3 \\) matrix with that same nullspace.\n\n% Question 10"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( Ax = b \\) always has at least one solution, show that the only solution to \\( A^T y = 0 \\) is \\( y = 0 \\).}  \n\\textit{Hint: What is the rank?}\n    % Question 11"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( Ax = 0 \\) has a nonzero solution, show that \\( A^T y = f \\) fails to be solvable for some right-hand sides \\( f \\).}  \nConstruct an example of \\( A \\) and \\( f \\).\n\n% Question 12"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the rank of \\( A \\) and write the matrix as \\( A = uv^T \\):}\n\\[\nA =\n\\begin{bmatrix}\n1 & 0 & 0 & 3 \\\\\n0 & 0 & 0 & 0 \\\\\n2 & 0 & 0 & 6\n\\end{bmatrix}\n\\]\n\\[\nA =\n\\begin{bmatrix}\n2 & -2 \\\\\n6 & -6\n\\end{bmatrix}\n\\]\n\n% Question 13"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( a, b, c \\) are given with \\( a \\neq 0 \\), choose \\( d \\) so that:}\n\\[\nA =\n\\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n= uv^T\n\\]\nhas rank 1. What are the pivots?\n\n% Question 14"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find a left-inverse and/or a right-inverse (when they exist) for:}\n\\[\nA =\n\\begin{bmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 1\n\\end{bmatrix}\n\\]\n\\[\nM =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n0 & 1\n\\end{bmatrix}\n\\]\n\\[\nT =\n\\begin{bmatrix}\na & b \\\\\n0 & a\n\\end{bmatrix}\n\\]\n\n% Question 15"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If the columns of \\( A \\) are linearly independent (\\( A \\) is \\( m \\times n \\)), then:}\n\\begin{itemize}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The rank is \\(\\dots\\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The nullspace is \\(\\dots\\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The row space is \\(\\dots\\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "There exists a \\(\\dots\\)-inverse.\n\\end{itemize}\n\n% Question 16"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{(A paradox) Suppose \\( A \\) has a right-inverse \\( B \\). Then \\( AB = I \\) leads to \\( A^T AB = A^T \\) or}\n\\[\nB (A^T A)^{-1} A^T\n\\]\nBut that satisfies \\( BA = I \\); it is a left-inverse. Which step is not justified?\n\n% Question 17"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find a matrix \\( A \\) that has \\( V \\) as its row space, and a matrix \\( B \\) that has \\( V \\) as its nullspace, if \\( V \\) is the subspace spanned by:}\n\\[\n\\begin{bmatrix}\n1 \\\\ 1 \\\\ 0\n\\end{bmatrix},\n\\quad\n\\begin{bmatrix}\n1 \\\\ 2 \\\\ 0\n\\end{bmatrix},\n\\quad\n\\begin{bmatrix}\n1 \\\\ 5 \\\\ 0\n\\end{bmatrix}\n\\]\n    % Question 18"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find a basis for each of the four subspaces of}\n\\[\nA =\n\\begin{bmatrix}\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 1 & 2 & 4 & 6 \\\\\n0 & 0 & 0 & 1 & 2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n1 & 1 & 0 \\\\\n0 & 1 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 0 & 0 & 1 & 2 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix}.\n\\]\n\n% Question 19"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( A \\) has the same four fundamental subspaces as \\( B \\), does \\( A = cB \\)?}\n\n% Question 20"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{(a) If a \\( 7 \\times 9 \\) matrix has rank 5, what are the dimensions of the four subspaces?}  \nWhat is the sum of all four dimensions?  \n\\textbf{(b) If a \\( 3 \\times 4 \\) matrix has rank 3, what are its column space and left nullspace?}\n\n% Question 21"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Construct a matrix with the required property, or explain why you can\u2019t.}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Column space contains \\( \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} \\), \\( \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\),\n    row space contains \\( \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\), \\( \\begin{bmatrix} 2 & 5 \\end{bmatrix} \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Column space has basis \\( \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix} \\), nullspace has basis \\( \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Dimension of nullspace = 1 + dimension of left nullspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Left nullspace contains \\( \\begin{bmatrix} 1 & 3 \\end{bmatrix} \\), row space contains \\( \\begin{bmatrix} 3 & 1 \\end{bmatrix} \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Row space = column space, nullspace \\( \\neq \\) left nullspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Without elimination, find dimensions and bases for the four subspaces for}\n\\[\nA =\n\\begin{bmatrix}\n0 & 3 & 3 & 3 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{bmatrix}\n\\quad \\text{and} \\quad\nB =\n\\begin{bmatrix}\n1 & 1 \\\\\n4 & 4 \\\\\n5 & 5\n\\end{bmatrix}.\n\\]\n\n% Question 23"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose the \\( 3 \\times 3 \\) matrix \\( A \\) is invertible. Write bases for the four subspaces for \\( A \\), and also for the \\( 3 \\times 6 \\) matrix \\( B = [A \\ A] \\).}\n\n% Question 24"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{What are the dimensions of the four subspaces for \\( A \\), \\( B \\), and \\( C \\), if \\( I \\) is the \\( 3 \\times 3 \\) identity matrix and 0 is the \\( 3 \\times 2 \\) zero matrix?}\n\\[\nA =\n\\begin{bmatrix}\nI & 0\n\\end{bmatrix}, \\quad\nB =\n\\begin{bmatrix}\nI & I \\\\\n0^T & 0^T\n\\end{bmatrix}, \\quad\nC =\n\\begin{bmatrix}\n0\n\\end{bmatrix}.\n\\]\n\n    % Question 25"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Which subspaces are the same for these matrices of different sizes?}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( A \\) and \\( \\begin{bmatrix} A \\\\ A \\end{bmatrix} \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( \\begin{bmatrix} A \\\\ A \\end{bmatrix} \\) and \\( \\begin{bmatrix} A & A \\\\ A & A \\end{bmatrix} \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If the entries of a \\( 3 \\times 3 \\) matrix are chosen randomly between 0 and 1, what are the most likely dimensions of the four subspaces?}  \nWhat if the matrix is \\( 3 \\times 5 \\)?\n\n% Question 27"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{(Important) A is an \\( m \\times n \\) matrix of rank \\( r \\). Suppose there are right-hand sides \\( b \\) for which \\( Ax = b \\) has no solution.}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What inequalities (\\(<\\) or \\(\\leq\\)) must be true between \\( m, n, \\) and \\( r \\)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "How do you know that \\( A^T y = 0 \\) has a nonzero solution?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Construct a matrix with \\( (1,0,1) \\) and \\( (1,2,0) \\) as a basis for its row space and its column space. Why can\u2019t this be a basis for the row space and nullspace?}\n\n% Question 29"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Without computing \\( A \\), find bases for the four fundamental subspaces:}\n\\[\nA =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n6 & 1 & 0 \\\\\n9 & 8 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n0 & 1 & 2 & 3 \\\\\n0 & 0 & 1 & 2\n\\end{bmatrix}.\n\\]\n\n% Question 30"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If you exchange the first two rows of a matrix \\( A \\), which of the four subspaces stay the same?}  \nIf \\( y = (1,2,3,4) \\) is in the left nullspace of \\( A \\), write down a vector in the left nullspace of the new matrix.\n    % Question 31"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Explain why \\( v = (1,0,-1) \\) cannot be a row of \\( A \\) and also be in the nullspace.}\n\n% Question 32"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Describe the four subspaces of \\( \\mathbb{R}^3 \\) associated with}\n\\[\nA =\n\\begin{bmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix}\n\\quad \\text{and} \\quad\nI + A =\n\\begin{bmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 1 \\\\\n0 & 0 & 1\n\\end{bmatrix}.\n\\]\n\n% Question 33"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{(Left nullspace) Add the extra column \\( b \\) and reduce \\( A \\) to echelon form:}\n\\[\n[A \\, | \\, b] =\n\\begin{bmatrix}\n1 & 2 & 3 & b_1 \\\\\n4 & 5 & 6 & b_2 \\\\\n7 & 8 & 9 & b_3\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n1 & 2 & 3 & b_1 \\\\\n0 & -3 & -6 & b_2 - 4b_1 \\\\\n0 & 0 & 0 & b_3 - 2b_2 + b_1\n\\end{bmatrix}.\n\\]\nA combination of the rows of \\( A \\) has produced the zero row. What combination is it?  \n(Look at \\( b_3 - 2b_2 + b_1 \\) on the right-hand side.)  \nWhich vectors are in the nullspace of \\( A^T \\) and which are in the nullspace of \\( A \\)?\n\n% Question 34"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Following the method of Problem 33, reduce \\( A \\) to echelon form and look at zero rows. The \\( b \\) column tells which combinations you have taken of the rows:}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\(\n    \\begin{bmatrix}\n    1 & 2 & b_1 \\\\\n    3 & 4 & b_2 \\\\\n    4 & 6 & b_3\n    \\end{bmatrix}\n    \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\(\n    \\begin{bmatrix}\n    1 & 2 & b_1 \\\\\n    2 & 3 & b_2 \\\\\n    2 & 4 & b_3 \\\\\n    2 & 5 & b_4\n    \\end{bmatrix}\n    \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( A \\) is the sum of two matrices of rank one: \\( A = uv^T + wz^T \\).}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which vectors span the column space of \\( A \\)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Which vectors span the row space of \\( A \\)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The rank is less than 2 if or if \\dots"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Compute \\( A \\) and its rank if \\( u = z = (1,0,0) \\) and \\( v = w = (0,0,1) \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Without multiplying matrices, find bases for the row and column spaces of \\( A \\):}\n\\[\nA =\n\\begin{bmatrix}\n1 & 2 \\\\\n4 & 5 \\\\\n2 & 7\n\\end{bmatrix}\n\\begin{bmatrix}\n3 & 0 & 3 \\\\\n1 & 1 & 2\n\\end{bmatrix}.\n\\]\nHow do you know from these shapes that \\( A \\) is not invertible?\n\n% Question 37"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{True or false (with a reason or a counterexample)?}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( A \\) and \\( A^T \\) have the same number of pivots."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\( A \\) and \\( A^T \\) have the same left nullspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the row space equals the column space, then \\( A^T = A \\)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If \\( A^T = -A \\), then the row space of \\( A \\) equals the column space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( AB = 0 \\), the columns of \\( B \\) are in the nullspace of \\( A \\). If those vectors are in \\( \\mathbb{R}^n \\), prove that}\n\\[\n\\text{rank}(A) + \\text{rank}(B) \\leq n.\n\\]\n\n% Question 39"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Can tic-tac-toe be completed (5 ones and 4 zeros in \\( A \\)) so that \\( \\text{rank}(A) = 2 \\) but neither side passed up a winning move?}\n\n% Question 40"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Construct any \\( 2 \\times 3 \\) matrix of rank 1. Copy Figure 2.5 and put one vector in each subspace (two in the nullspace). Which vectors are orthogonal?}\n\n% Question 41"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Redraw Figure 2.5 for a \\( 3 \\times 2 \\) matrix of rank \\( r = 2 \\). Which subspace is \\( Z \\) (zero vector only)? The nullspace part of any vector \\( x \\) in \\( \\mathbb{R}^2 \\) is \\( x_n = \\) \\dots}\n    % Question 1"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{For the 3-node triangular graph in the figure below, write the \\(3 \\times 3\\) incidence matrix \\( A \\).}  \nFind a solution to \\( Ax = 0 \\) and describe all other vectors in the nullspace of \\( A \\).  \nFind a solution to \\( A^T y = 0 \\) and describe all other vectors in the left nullspace of \\( A \\).\n\n\\begin{center}\n\\textbf{Graph Representation:}\\\\\n\\begin{tabular}{c}\n\\(\\bullet\\) \\hspace{0.5cm} --- edge 1 --- \\hspace{0.5cm} \\(\\bullet\\) \\\\\n| \\\\\n\\(\\bullet\\) --- edge 2 --- \\(\\bullet\\) --- edge 3 --- \\(\\bullet\\) \\\\\n\\end{tabular}\n\\end{center}\n\n% Question 2"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{For the same \\(3 \\times 3\\) matrix, show directly from the columns that every vector \\( b \\) in the column space will satisfy}  \n\\[\nb_1 + b_2 - b_3 = 0.\n\\]\nDerive the same thing from the three rows\u2014the equations in the system \\( Ax = b \\).  \nWhat does that mean about potential differences around a loop?\n\n% Question 3"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Show directly from the rows that every vector \\( f \\) in the row space will satisfy}  \n\\[\nf_1 + f_2 + f_3 = 0.\n\\]\nDerive the same thing from the three equations \\( A^T y = f \\).  \nWhat does that mean when the \\( f \\)'s are currents into the nodes?\n\n% Question 4"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Compute the \\( 3 \\times 3 \\) matrix \\( A^T A \\), and show that it is symmetric but singular.}  \nWhat vectors are in its nullspace?  \nRemoving the last column of \\( A \\) (and last row of \\( A^T \\)) leaves the \\( 2 \\times 2 \\) matrix in the upper left corner; show that it is not singular.\n\n% Question 5"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Put the diagonal matrix \\( C \\) with entries \\( c_1, c_2, c_3 \\) in the middle and compute \\( A^T C A \\).}  \nShow again that the \\( 2 \\times 2 \\) matrix in the upper left corner is invertible.\n\n% Question 6"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Write the \\( 6 \\times 4 \\) incidence matrix \\( A \\) for the second graph in the figure.}  \nThe vector \\( (1,1,1,1) \\) is in the nullspace of \\( A \\), but now there will be \\( m - n + 1 = 3 \\) independent vectors that satisfy \\( A^T y = 0 \\).  \nFind three vectors \\( y \\) and connect them to the loops in the graph.\n% Question 7"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If the second graph represents six games between four teams, and the score differences are \\( b_1, \\dots, b_6 \\), when is it possible to assign potentials \\( x_1, \\dots, x_4 \\) so that the potential differences agree with the \\( b \\)'s?}  \nYou are finding (from Kirchhoff or from elimination) the conditions that make \\( Ax = b \\) solvable.\n\n% Question 8"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Write down the dimensions of the four fundamental subspaces for this \\( 6 \\times 4 \\) incidence matrix, and a basis for each subspace.}\n\n% Question 9"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Compute \\( A^T A \\) and \\( A^T C A \\), where the \\( 6 \\times 6 \\) diagonal matrix \\( C \\) has entries \\( c_1, \\dots, c_6 \\).}  \nHow can you tell from the graph where the \\( c \\)'s will appear on the main diagonal of \\( A^T C A \\)?\n\n% Question 10"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Draw a graph with numbered and directed edges (and numbered nodes) whose incidence matrix is:}\n\\[\nA =\n\\begin{bmatrix}\n-1 & 1 & 0 & 0 \\\\\n-1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & -1 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}.\n\\]\nIs this graph a tree? (Are the rows of \\( A \\) independent?)  \nShow that removing the last edge produces a spanning tree. Then the remaining rows are a basis for which subspace?\n\n% Question 11"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{With the last column removed from the preceding \\( A \\), and with the numbers \\( 1, 2, 2, 1 \\) on the diagonal of \\( C \\), write out the \\( 7 \\times 7 \\) system:}\n\\[\nC^{-1} y + Ax = 0\n\\]\n\\[\nA^T y = f.\n\\]\nEliminating \\( y_1, y_2, y_3, y_4 \\) leaves three equations:\n\\[\nA^T C A x = -f.\n\\]\nSolve the equations when \\( f = (1,1,6) \\).  \nWith those currents entering nodes \\( 1,2,3 \\) of the network, what are the potentials at the nodes and currents on the edges?\n    % Question 12"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( A \\) is a \\( 12 \\times 7 \\) incidence matrix from a connected graph, what is its rank?}  \nHow many free variables are there in the solution to \\( Ax = b \\)?  \nHow many free variables are there in the solution to \\( A^T y = f \\)?  \nHow many edges must be removed to leave a spanning tree?\n\n% Question 13"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{In the graph above with 4 nodes and 6 edges, find all 16 spanning trees.}\n\n% Question 14"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If MIT beats Harvard 35-0, Yale ties Harvard, and Princeton beats Yale 7-6, what score differences in the other 3 games (H-P, MIT-P, MIT-Y) will allow potential differences that agree with the score differences?}  \nIf the score differences are known for the games in a spanning tree, they are known for all games.\n\n% Question 15"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{In our method for football rankings, should the strength of the opposition be considered \u2014 or is that already built in?}\n\n% Question 16"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If there is an edge between every pair of nodes (a complete graph), how many edges are there?}  \nThe graph has \\( n \\) nodes, and edges from a node to itself are not allowed.\n\n% Question 17"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{For both graphs drawn below, verify Euler\u2019s formula:}\n\\[\n\\text{(# of nodes)} - \\text{(# of edges)} + \\text{(# of loops)} = 1.\n\\]\n\n% Question 18"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Multiply matrices to find \\( A^T A \\), and guess how its entries come from the graph:}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Why does the nullspace of \\( A^T A \\) contain \\( (1,1,1,1) \\)? What is its rank?}\n\n% Question 20"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Why does a complete graph with \\( n = 6 \\) nodes have \\( m = 15 \\) edges?}  \nA spanning tree connecting all six nodes has \\( n-1 \\) edges.  \nThere are \n\\[\nT = n^{(n-2)} = 6^{(4)}\n\\]\nspanning trees!\n\n% Question 21"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The adjacency matrix of a graph has \\( M_{ij} = 1 \\) if nodes \\( i \\) and \\( j \\) are connected by an edge (otherwise \\( M_{ij} = 0 \\)).}  \nFor the graph in Problem 6 with 6 nodes and 4 edges, write down \\( M \\) and also \\( M^2 \\).  \nWhy does \\( (M^2)_{ij} \\) count the number of 2-step paths from node \\( i \\) to node \\( j \\)?\n    % Question 1"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{What matrix has the effect of rotating every vector through 90\u00b0 and then projecting the result onto the x-axis?}  \nWhat matrix represents projection onto the x-axis followed by projection onto the y-axis?\n\n% Question 2"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Does the product of 5 reflections and 8 rotations of the x-y plane produce a rotation or a reflection?}\n\n% Question 3"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The matrix}\n\\[\nA = \\begin{bmatrix} 2 & 0 \\\\ 0 & 1 \\end{bmatrix}\n\\]\n\\textbf{produces a stretching in the x-direction. Draw the circle \\(x^2 + y^2 = 1\\) and sketch around it the points \\((2x, y)\\) that result from multiplication by \\(A\\).}  \nWhat shape is that curve?\n\n% Question 4"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Every straight line remains straight after a linear transformation.}  \nIf \\( z \\) is halfway between \\( x \\) and \\( y \\), show that \\( Az \\) is halfway between \\( Ax \\) and \\( Ay \\).\n\n% Question 5"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The matrix}\n\\[\nA = \\begin{bmatrix} 1 & 0 \\\\ 3 & 1 \\end{bmatrix}\n\\]\n\\textbf{yields a shearing transformation, which leaves the y-axis unchanged. Sketch its effect on the x-axis, by indicating what happens to \\( (1,0) \\), \\( (2,0) \\), and \\( (-1,0) \\)\u2014and how the whole axis is transformed.}\n\n% Question 6"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{What \\( 3 \\times 3 \\) matrices represent the transformations that:}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{On the space \\( P_3 \\) of cubic polynomials, what matrix represents \\( \\frac{d^2}{dt^2} \\)?}  \nConstruct the \\( 4 \\times 4 \\) matrix from the standard basis \\( 1, t, t^2, t^3 \\).  \nFind its null space and column space. What do they mean in terms of polynomials?\n\n% Question 8"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{From the cubic polynomials \\( P_3 \\) to the fourth-degree polynomials \\( P_4 \\), what matrix represents multiplication by \\( 2 +3t \\)?}  \nThe columns of the \\( 5 \\times 4 \\) matrix \\( A \\) come from applying the transformation to \\( 1, t, t^2, t^3 \\).\n\n% Question 9"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The solutions to the linear differential equation \\( \\frac{d^2u}{dt^2} = u \\) form a vector space (since combinations of solutions are still solutions).}  \nFind two independent solutions to give a basis for that solution space.\n\n% Question 10"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{With initial values \\( u = x \\) and \\( \\frac{du}{dt} = y \\) at \\( t = 0 \\), what combination of basis vectors in Problem 9 solves \\( u'' = u \\)?}  \nThis transformation from initial values to solution is linear. What is its \\( 2 \\times 2 \\) matrix (using \\( x = 1, y = 0 \\) and \\( x = 0, y = 1 \\) as basis for \\( V \\), and your basis for \\( W \\))?\n\n% Question 11"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Verify directly from \\( c^2 + s^2 = 1 \\) that reflection matrices satisfy \\( H^2 = I \\).}\n\n% Question 12"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( A \\) is a linear transformation from the x-y plane to itself. Why does \\( A^{-1} (x + y) = A^{-1} x + A^{-1} y \\)?}  \nIf \\( A \\) is represented by the matrix \\( M \\), explain why \\( A^{-1} \\) is represented by \\( M^{-1} \\).\n\n% Question 13"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The product \\( (AB)C \\) of linear transformations starts with a vector \\( x \\) and produces \\( u = Cx \\). Then rule 2V applies \\( AB \\) to \\( u \\) and reaches \\( (AB)Cx \\).}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Prove that \\( T^2 \\) is a linear transformation if \\( T \\) is linear (from \\( \\mathbb{R}^3 \\) to \\( \\mathbb{R}^3 \\)).}\n\n% Question 15"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The space of all \\( 2 \\times 2 \\) matrices has the four basis ``vectors''}\n\\[\n\\begin{bmatrix}1 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad\n\\begin{bmatrix}0 & 1 \\\\ 0 & 0 \\end{bmatrix}, \\quad\n\\begin{bmatrix}0 & 0 \\\\ 1 & 0 \\end{bmatrix}, \\quad\n\\begin{bmatrix}0 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n\\]\nFor the linear transformation of transposing, find its matrix \\( A \\) with respect to this basis. Why is \\( A^2 = I \\)?\n\n% Question 16"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the \\( 4 \\times 4 \\) cyclic permutation matrix:}  \n\\[\n(x_1, x_2, x_3, x_4) \\text{ is transformed to } A x = (x_2, x_3, x_4, x_1).\n\\]\nWhat is the effect of \\( A^2 \\)? Show that \\( A^3 = A^{-1} \\).\n\n% Question 17"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the \\( 4 \\times 3 \\) matrix \\( A \\) that represents a right shift:}  \n\\[\n(x_1, x_2, x_3) \\text{ is transformed to } (0, x_1, x_2, x_3).\n\\]\nFind also the left shift matrix \\( B \\) from \\( \\mathbb{R}^4 \\) back to \\( \\mathbb{R}^3 \\), transforming  \n\\[\n(x_1, x_2, x_3, x_4) \\text{ to } (x_2, x_3, x_4).\n\\]\nWhat are the products \\( AB \\) and \\( BA \\)?\n\n% Question 18"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{In the vector space \\( P_3 \\) of all polynomials \\( p(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 \\), let \\( S \\) be the subset of polynomials satisfying:}  \n\\[\n\\int_0^1 p(x) \\, dx = 0.\n\\]\nVerify that \\( S \\) is a subspace and find a basis.\n\n% Question 19"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{A nonlinear transformation is invertible if \\( T(x) = b \\) has exactly one solution for every \\( b \\).}  \nThe example \\( T(x) = x^2 \\) is not invertible because \\( x^2 = b \\) has two solutions for positive \\( b \\) and no solution for negative \\( b \\).  \nWhich of the following transformations (from \\( \\mathbb{R} \\) to \\( \\mathbb{R} \\)) are invertible? None are linear, not even (c).\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{What is the axis and the rotation angle for the transformation that takes \\( (x_1, x_2, x_3) \\) into \\( (x_2, x_3, x_1) \\)?}\n\n% Question 21"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{A linear transformation must leave the zero vector fixed: \\( T(0) = 0 \\).}  \nProve this from \\( T(v+w) = T(v) + T(w) \\) by choosing \\( w = 0 \\).  \nProve it also from the requirement \\( T(cv) = cT(v) \\) by choosing \\( c = 0 \\).\n\n% Question 22"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Which of these transformations is not linear? The input is \\( v = (v_1, v_2) \\).}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{If \\( S \\) and \\( T \\) are linear with \\( S(v) = T(v) = v \\), then does \\( S(T(v)) = v \\) or \\( v^2 \\)?}\n\n% Question 24"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( T(v) = v \\), except that \\( T(0, v_2) = (0,0) \\).}  \nShow that this transformation satisfies \\( T(cv) = cT(v) \\) but not \\( T(v+w) = T(v) + T(w) \\).\n\n% Question 25"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Which of these transformations satisfy \\( T(v+w) = T(v) + T(w) \\), and which satisfy \\( T(cv) = cT(v) \\)?}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{For these transformations of \\( V = \\mathbb{R}^2 \\) to \\( W = \\mathbb{R}^2 \\), find \\( T(T(v)) \\).}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The ``cyclic'' transformation \\( T \\) is defined by}\n\\[\nT(v_1, v_2, v_3) = (v_2, v_3, v_1).\n\\]\nWhat is \\( T(T(T(v))) \\)? What is \\( T^{100}(v) \\)?\n\n% Question 27"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The ``cyclic'' transformation \\( T \\) is defined by}\n\\[\nT(v_1, v_2, v_3) = (v_2, v_3, v_1).\n\\]\nWhat is \\( T(T(T(v))) \\)? What is \\( T^{100}(v) \\)?\n\n% Question 28"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Find the range and kernel (these are the column space and null space) of \\( T \\).}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{A linear transformation from \\( V \\) to \\( W \\) has an inverse from \\( W \\) to \\( V \\) when the range is all of \\( W \\) and the kernel contains only \\( v = 0 \\). Why are these transformations not invertible?}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose a linear transformation \\( T \\) transforms \\( (1, 1) \\) to \\( (2, 2) \\) and \\( (2, 0) \\) to \\( (0, 0) \\). Find \\( T(v) \\) when:}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{M is any 2 by 2 matrix and \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\). The linear transformation \\( T \\) is defined by \\( T(M) = AM \\). What rules of matrix multiplication show that \\( T \\) is linear?}\n\n% Question 32"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 6 \\end{pmatrix} \\).}  \nShow that the identity matrix \\( I \\) is not in the range of \\( T \\). Find a nonzero matrix \\( M \\) such that \\( T(M) = AM \\) is zero.\n% Question 33"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( T \\) transposes every matrix \\( M \\). Try to find a matrix \\( A \\) that gives \\( AM = M^T \\) for every \\( M \\). Show that no matrix \\( A \\) will do it.}  \nTo professors: Is this a linear transformation that doesn\u2019t come from a matrix?\n\n% Question 34"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{The transformation \\( T \\) that transposes every matrix is definitely linear. Which of these extra properties are true?}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Suppose \\( T(M) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} M \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\).}  \nFind a matrix with \\( T(M) \\neq 0 \\). Describe all matrices with \\( T(M) = 0 \\) (the kernel of \\( T \\)) and all output matrices \\( T(M) \\) (the range of \\( T \\)).\n\n% Question 36"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{Problems 36\u201340 are about changing the basis.}\n\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "(a) What matrix $M$ transforms $(1,0)$ and $(0,1)$ to $(r,t)$ and $(s,u)$? \\\\\n    (b) What matrix $N$ transforms $(a,c)$ and $(b,d)$ to $(1,0)$ and $(0,1)$? \\\\\n    (c) What condition on $a$, $b$, $c$, $d$ will make part (b) impossible?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "(a) How do $M$ and $N$ in Problem 37 yield the matrix that transforms $(a,c)$ to $(r,t)$ and $(b,d)$ to $(s,u)$? \\\\\n    (b) What matrix transforms $(2,5)$ to $(1,1)$ and $(1,3)$ to $(0,2)$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If you keep the same basis vectors but put them in a different order, the change-of-basis matrix $M$ is a matrix. If you keep the basis vectors in order but change their lengths, $M$ is a matrix."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The matrix that transforms $(1,0)$ and $(0,1)$ to $(1,4)$ and $(1,5)$ is $M = \\cdots$. The combination $a(1,4) + b(1,5)$ that equals $(1,0)$ has $(a,b) = (\\cdots)$. How are those new coordinates of $(1,0)$ related to $M$ or $M^{-1}$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What are the three equations for $A$, $B$, $C$ if the parabola $Y = A + Bx + Cx^2$ equals $4$ at $x = a$, $5$ at $x = b$, and $6$ at $x = c$? Find the determinant of the $3 \\times 3$ matrix. For which numbers $a$, $b$, $c$ will it be impossible to find this parabola $Y$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $v_1$, $v_2$, $v_3$ are eigenvectors for $T$. This means $T(v_i) = \\lambda_i v_i$ for $i = 1,2,3$. What is the matrix for $T$ when the input and output bases are the $v_i$'s?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Every invertible linear transformation can have $I$ as its matrix. For the output basis just choose $w_i = T(v_i)$. Why must $T$ be invertible?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $T$ is reflection across the x-axis and $S$ is reflection across the y-axis. The domain $V$ is the x-y plane. If $v = (x,y)$ what is $S(T(v))$? Find a simpler description of the product $ST$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $T$ is reflection across the $45^\\circ$ line, and $S$ is reflection across the y-axis. If $v = (2,1)$ then $T(v) = (1,2)$. Find $S(T(v))$ and $T(S(v))$. This shows that generally $ST \\neq TS$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Show that the product $ST$ of two reflections is a rotation. Multiply these reflection matrices to find the rotation angle:\n    \\[\n    \\begin{bmatrix}\n    \\cos 2\\theta & \\sin 2\\theta \\\\\n    \\sin 2\\theta & -\\cos 2\\theta\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    \\cos 2\\alpha & \\sin 2\\alpha \\\\\n    \\sin 2\\alpha & -\\cos 2\\alpha\n    \\end{bmatrix}.\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The $4 \\times 4$ Hadamard matrix is entirely $+1$ and $-1$:\n    \\[\n    H = \\begin{bmatrix}\n    1 & 1 & 1 & 1 \\\\\n    1 & -1 & 1 & -1 \\\\\n    1 & 1 & -1 & -1 \\\\\n    1 & -1 & -1 & 1\n    \\end{bmatrix}.\n    \\]\n    Find $H^{-1}$ and write $v = (7,5,3,1)$ as a combination of the columns of $H$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose we have two bases $v_1, \\dots, v_n$ and $w_1, \\dots, w_n$ for $\\mathbb{R}^n$. If a vector has coefficients $b_i$ in one basis and $c_i$ in the other basis, what is the change-of-basis matrix in $b = Mc$? Start from:\n    \\[\n    b_1 v_1 + \\dots + b_n v_n = Vb = c_1 w_1 + \\dots + c_n w_n = Wc.\n    \\]\n    Your answer represents $T(v) = v$ with the input basis of $v$'s and output basis of $w$'s. Because of different bases, the matrix is not $I$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false: If we know $T(v)$ for $n$ different nonzero vectors in $\\mathbb{R}^2$, then we know $T(v)$ for every vector in $\\mathbb{R}^n$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "(Recommended) Suppose all vectors $x$ in the unit square $0 \\leq x_1 \\leq 1$, $0 \\leq x_2 \\leq 1$ are transformed to $Ax$ ($A$ is $2 \\times 2$).\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the shape of the transformed region (all $Ax$)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which matrices $A$ is that region a square?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which $A$ is it a line?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "For which $A$ is the new area still 1?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the following subspaces of $\\mathbb{R}^4$:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors for which $x_1 = 2x_4$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The vectors for which $x_1 + x_2 + x_3 = 0$ and $x_3 + x_4 = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The subspace spanned by $(1,1,1,1)$, $(1,2,3,4)$, and $(2,3,4,5)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{1.2} By giving a basis, describe a two-dimensional subspace of $\\mathbb{R}^3$ that contains none of the coordinate vectors $(1,0,0)$, $(0,1,0)$, $(0,0,1)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false, with counterexample if false:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the vectors $x_1, \\dots, x_m$ span a subspace $S$, then $\\dim S = m$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The intersection of two subspaces of a vector space cannot be empty."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $Ax = Ay$, then $x = y$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The row space of $A$ has a unique basis that can be computed by reducing $A$ to echelon form."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If a square matrix $A$ has independent columns, so does $A^2$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the echelon form $U$ of $A$?\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 0 & 2 & 1 \\\\\n    -1 & -2 & 1 & 1 & 0 \\\\\n    1 & 2 & -3 & -7 & -2\n    \\end{bmatrix}\n    \\]\n    What are the dimensions of its four fundamental subspaces?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the rank and the nullspace of\n    \\[\n    A = \\begin{bmatrix}\n    0 & 0 & 1 \\\\\n    0 & 0 & 1 \\\\\n    1 & 1 & 1\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    B = \\begin{bmatrix}\n    0 & 0 & 1 & 2 \\\\\n    0 & 0 & 1 & 2 \\\\\n    1 & 1 & 1 & 0\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find bases for the four fundamental subspaces associated with\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} 0 & 0 \\\\ 1 & 2 \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 1 \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\textbf{1.7} What is the most general solution to the system:\n    \\[\n    u + v + w = 1, \\quad u - w = 2?\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose nullspace contains the vector $x = (1,1,2)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose left nullspace contains $y = (1,5)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Construct a matrix whose column space is spanned by $(1,1,2)$ and whose row space is spanned by $(1,5)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If you are given any three vectors in $\\mathbb{R}^6$ and any three vectors in $\\mathbb{R}^5$, is there a $6 \\times 5$ matrix whose column space is spanned by the first three and whose row space is spanned by the second three?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "In the vector space of $2 \\times 2$ matrices:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Is the set of rank 1 matrices a subspace?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What subspace is spanned by the permutation matrices?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What subspace is spanned by the positive matrices (all $a_{ij} > 0$)?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What subspace is spanned by the invertible matrices?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Invent a vector space that contains all linear transformations from $\\mathbb{R}^n$ to $\\mathbb{R}^n$. You have to decide on a rule for addition. What is its dimension?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the rank of $A$, and give a basis for its nullspace.\n        \\[\n        A = LU = \\begin{bmatrix}\n        1 & 2 & 1 \\\\\n        2 & 1 & 2 \\\\\n        3 & 2 & 4 & 1\n        \\end{bmatrix}\n        \\begin{bmatrix}\n        1 & 2 & 0 & 1 & 2 & 1 \\\\\n        0 & 0 & 2 & 2 & 0 & 0 \\\\\n        0 & 0 & 0 & 0 & 0 & 1 \\\\\n        0 & 0 & 0 & 0 & 0 & 0\n        \\end{bmatrix}\n        \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The first 3 rows of $U$ are a basis for the row space of $A$\u2014true or false?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Columns 1, 3, 6 of $U$ are a basis for the column space of $A$\u2014true or false?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "The four rows of $A$ are a basis for the row space of $A$\u2014true or false?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find as many linearly independent vectors $b$ as possible for which $Ax = b$ has a solution."
    },
    {
        "chapter": "Vector Spaces",
        "question": "In elimination on $A$, what multiple of the third row is subtracted to knock out the fourth row?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is an $n \\times (n-1)$ matrix, and its rank is $n-2$, what is the dimension of its nullspace?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Use elimination to find the triangular factors in $A = LU$, if\n    \\[\n    A = \\begin{bmatrix}\n    a & a & a & a \\\\\n    a & b & b & b \\\\\n    a & b & c & c \\\\\n    a & b & c & d\n    \\end{bmatrix}\n    \\]\n    Under what conditions on the numbers $a$, $b$, $c$, $d$ are the columns linearly independent?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Do the vectors $(1,1,3)$, $(2,3,6)$, and $(1,4,3)$ form a basis for $\\mathbb{R}^3$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What do you know about $C(A)$ when the number of solutions to $Ax = b$ is:\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "0 or 1, depending on $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "$\\infty$, independent of $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "0 or $\\infty$, depending on $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "1, regardless of $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "In the previous exercise, how is $r$ related to $m$ and $n$ in each example?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $x$ is a vector in $\\mathbb{R}^n$, and $x^T y = 0$ for every $y$, prove that $x = 0$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is an $n \\times n$ matrix such that $A^2 = A$ and $\\text{rank}(A) = n$, prove that $A = I$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "What subspace of $3 \\times 3$ matrices is spanned by the elementary matrices $E_{ij}$, with 1s on the diagonal and at most one nonzero entry below?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "How many $5 \\times 5$ permutation matrices are there? Are they linearly independent? Do they span the space of all $5 \\times 5$ matrices? No need to write them all down."
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the rank of the $n \\times n$ matrix with every entry equal to 1? How about the \u201ccheckerboard matrix,\u201d with $a_{ij} = 0$ when $i + j$ is even, $a_{ij} = 1$ when $i + j$ is odd?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "$Ax = b$ has a solution under what conditions on $b$, for the following $A$ and $b$?\n        \\[\n        A = \\begin{bmatrix}\n        1 & 2 & 0 & 3 \\\\\n        0 & 0 & 0 & 0 \\\\\n        2 & 4 & 0 & 1\n        \\end{bmatrix}, \\quad b = \\begin{bmatrix}\n        b_1 \\\\\n        b_2 \\\\\n        b_3\n        \\end{bmatrix}\n        \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the nullspace of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find the general solution to $Ax = b$, when a solution exists."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the column space of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the rank of $A^T$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "How can you construct a matrix that transforms the coordinate vectors $e_1, e_2, e_3$ into three given vectors $v_1, v_2, v_3$? When will that matrix be invertible?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $e_1, e_2, e_3$ are in the column space of a $3 \\times 5$ matrix, does it have a left-inverse? Does it have a right-inverse?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose $T$ is the linear transformation on $\\mathbb{R}^3$ that takes each point $(u, v, w)$ to $(u+v+w, u+v, u)$. Describe what $T^{-1}$ does to the point $(x, y, z)$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false?\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Every subspace of $\\mathbb{R}^4$ is the nullspace of some matrix."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ has the same nullspace as $A^T$, the matrix must be square."
    },
    {
        "chapter": "Vector Spaces",
        "question": "The transformation that takes $x$ to $mx + b$ is linear (from $\\mathbb{R}^1$ to $\\mathbb{R}^1$)."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find bases for the four fundamental subspaces of\n    \\[\n    A_1 = \\begin{bmatrix}\n    1 & 2 & 0 & 3 \\\\\n    0 & 2 & 2 & 2 \\\\\n    0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 4\n    \\end{bmatrix}, \\quad A_2 = \\begin{bmatrix}\n    1 \\\\\n    1 \\\\\n    1\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If the rows of $A$ are linearly independent (where $A$ is $m \\times n$), then the rank is \\_, the column space is \\_, and the left nullspace is \\_."
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is $8 \\times 10$ with a two-dimensional nullspace, show that $Ax = b$ can be solved for every $b$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Describe the linear transformations of the $x$-$y$ plane that are represented with the standard basis $(1,0)$ and $(0,1)$ by the matrices\n    \\[\n    A_1 = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & -1\n    \\end{bmatrix}, \\quad A_2 = \\begin{bmatrix}\n    1 & 0 \\\\\n    2 & 1\n    \\end{bmatrix}, \\quad A_3 = \\begin{bmatrix}\n    0 & 1 \\\\\n    -1 & 0\n    \\end{bmatrix}\n    \\]"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "If $A$ is square, show that the nullspace of $A^2$ contains the nullspace of $A$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "When does the rank-1 matrix $A = uv^T$ have $A^2 = 0$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "\\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a basis for the space of all vectors in $\\mathbb{R}^6$ with $x_1 + x_2 = x_3 + x_4 = x_5 + x_6$."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a matrix with that subspace as its nullspace."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Find a matrix with that subspace as its column space."
    },
    {
        "chapter": "Vector Spaces",
        "question": "Suppose the matrices in $PA = LU$ are:\n    \\[\n    P = \\begin{bmatrix}\n    0 & 1 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 \\\\\n    0 & 0 & 1 & 0\n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix}\n    0 & 0 & 1 & -3 & 2 \\\\\n    2 & -1 & 4 & 2 & 1 \\\\\n    4 & -2 & 9 & 1 & 4 \\\\\n    2 & -1 & 5 & -1 & 5\n    \\end{bmatrix}\n    \\]\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1 & 1 & 1 & 0 \\\\\n    2 & 1 & 0 & 1\n    \\end{bmatrix}, \\quad\n    U = \\begin{bmatrix}\n    2 & -1 & 4 & 2 & 1 \\\\\n    0 & 0 & 1 & -3 & 2 \\\\\n    0 & 0 & 0 & 0 & 2 \\\\\n    0 & 0 & 0 & 0 & 0\n    \\end{bmatrix}\n    \\]\n    \\begin{enumerate}"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the rank of $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is a basis for the row space of $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "True or false: Rows 1, 2, 3 of $A$ are linearly independent."
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is a basis for the column space of $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the dimension of the left nullspace of $A$?"
    },
    {
        "chapter": "Vector Spaces",
        "question": "What is the general solution to $Ax = 0$?"
    }
]